{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sshar180/Machine-Learning-/blob/main/Linear_and_Neural_Net_Classifier_Comparison.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Assignment 2**\n",
        "\n",
        "\n",
        "**Name: Shubham Sharma**\n",
        "\n",
        "**SID: 862394567**"
      ],
      "metadata": {
        "id": "gaw31-j2iI-A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 1) (2 pts) Apply the normalization on the training and test data."
      ],
      "metadata": {
        "id": "HJSjkkiew4gp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "46nezxlnwdsZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import mnist\n",
        "\n",
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "\n",
        "def load_data():\n",
        "    \"\"\" LOading the data set\"\"\"\n",
        "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "    x_train = x_train.reshape(60000, 784)\n",
        "    x_test = x_test.reshape(10000, 784)\n",
        "\n",
        "    x_train = (x_train - np.mean(x_train)) / np.std(x_train)\n",
        "    x_test = (x_test - np.mean(x_train)) / np.std(x_train)\n",
        "\n",
        "    x_train = np.concatenate([x_train, np.ones((x_train.shape[0], 1))], axis=1)\n",
        "    x_test = np.concatenate([x_test, np.ones((x_test.shape[0], 1))], axis=1)\n",
        "\n",
        "    y_train = np.where(y_train <= 4, 0, 1)\n",
        "    y_test = np.where(y_test <= 4, 0, 1)\n",
        "\n",
        "    return x_train, y_train, x_test, y_test"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer1) In the above code we load the MNIST dataset from keras and performs the following steps:\n",
        "\n",
        "1) The data is reshaped from a 3D array of size (num_samples, 28, 28) to a 2D array of size (num_samples, 784) where each image is flattened into a 1D array.\n",
        "\n",
        "2)The data is normalized by subtracting the mean and dividing by the standard deviation. This helps to improve the performance of the model.\n",
        "\n",
        "3)  A column of ones is added to the data for the bias term. The bias term is a constant that is added to each neuron in the output layer.\n",
        "\n",
        "4) The target variable is converted to a binary classification problem by setting the label 0 for digits less than or equal to 4, and 1 for digits greater than 4. This is done because the MNIST dataset contains 10 classes, but we only want to classify digits as either less than or equal to 4, or greater than 4"
      ],
      "metadata": {
        "id": "FgXugqmk7kwY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Question 2) (2 pts) As a baseline, train a linear classifier yË† = v\n",
        "T x and quadratic loss. Report its test accuracy.***"
      ],
      "metadata": {
        "id": "qT6SFkK66hoR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import mnist\n",
        "\n",
        "x_train, y_train, x_test, y_test = load_data()\n",
        "\n",
        "\"\"\" Random weight initialization\"\"\"\n",
        "W = np.random.randn(x_train.shape[1])\n",
        "\n",
        "\"\"\" Setting up hyper-parameters \"\"\"\n",
        "lr = 0.001\n",
        "batch_size = 100\n",
        "n_epochs = 500\n",
        "training_loss = []\n",
        "training_accuracy = []\n",
        "\n",
        "\"\"\"Implementing Batch stochastic gradient descent\"\"\"\n",
        "for epoch in range(n_epochs):\n",
        "\n",
        "    indices = np.random.permutation(x_train.shape[0])\n",
        "    x_train = x_train[indices]\n",
        "    y_train = y_train[indices]\n",
        "\n",
        "    \"\"\"Getting data in batches\"\"\"\n",
        "    for i in range(0, x_train.shape[0], batch_size):\n",
        "        x_batch = x_train[i:i+batch_size]\n",
        "        y_batch = y_train[i:i+batch_size]\n",
        "\n",
        "        \"\"\"Performing predictions \"\"\"\n",
        "        predicted_val = x_batch.dot(W)\n",
        "        error = predicted_val - y_batch\n",
        "\n",
        "        \"\"\"Calculating Gradient\"\"\"\n",
        "        gra = x_batch.T.dot(error) / batch_size\n",
        "\n",
        "        \"\"\"Gradient Update\"\"\"\n",
        "        W -= lr * gra\n",
        "\n",
        "    \"\"\"Storing and calculating loss and accuracy\"\"\"\n",
        "    predicted_val = x_train.dot(W)\n",
        "    loss = np.mean((predicted_val - y_train) ** 2)\n",
        "\n",
        "    accuracy = np.mean((predicted_val > 0.5) == y_train)\n",
        "\n",
        "\n",
        "    training_loss.append(loss)\n",
        "    training_accuracy.append(accuracy*100)\n",
        "\n",
        "\n",
        "    print(f\"Epoch {epoch+1}: loss={loss:.4f}, accuracy={accuracy*100:.4f}\")\n",
        "\n",
        "\"\"\" Accuracy Calculation\"\"\"\n",
        "predicted_val = x_test.dot(W)\n",
        "accuracy = np.mean((predicted_val > 0.5) == y_test)\n",
        "print(f\"Test accuracy: {accuracy:.4f}\")\n",
        "\n",
        "\"\"\"Ploting Training and Accuracy\"\"\"\n",
        "plt.plot(range(1, n_epochs+1), training_loss, label=\"Training Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.plot(range(1, n_epochs+1), training_accuracy, label=\"Training Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Nc4_m-uOfTM5",
        "outputId": "97d0f16e-218c-46dd-a541-e527b26578df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 1s 0us/step\n",
            "Epoch 1: loss=59.0423, accuracy=49.8983\n",
            "Epoch 2: loss=35.2870, accuracy=50.2183\n",
            "Epoch 3: loss=25.2712, accuracy=51.4267\n",
            "Epoch 4: loss=19.7829, accuracy=52.1983\n",
            "Epoch 5: loss=16.1894, accuracy=52.2350\n",
            "Epoch 6: loss=13.6906, accuracy=52.1650\n",
            "Epoch 7: loss=11.8507, accuracy=52.8567\n",
            "Epoch 8: loss=10.3164, accuracy=53.2133\n",
            "Epoch 9: loss=9.1870, accuracy=53.8333\n",
            "Epoch 10: loss=8.1783, accuracy=53.6633\n",
            "Epoch 11: loss=7.3850, accuracy=53.8550\n",
            "Epoch 12: loss=6.6924, accuracy=54.0500\n",
            "Epoch 13: loss=6.1066, accuracy=54.4567\n",
            "Epoch 14: loss=5.6113, accuracy=54.2583\n",
            "Epoch 15: loss=5.1822, accuracy=54.7767\n",
            "Epoch 16: loss=4.7991, accuracy=55.1967\n",
            "Epoch 17: loss=4.4628, accuracy=55.6083\n",
            "Epoch 18: loss=4.1699, accuracy=55.4017\n",
            "Epoch 19: loss=3.9027, accuracy=55.5750\n",
            "Epoch 20: loss=3.6859, accuracy=56.7367\n",
            "Epoch 21: loss=3.4506, accuracy=56.7283\n",
            "Epoch 22: loss=3.2754, accuracy=56.8883\n",
            "Epoch 23: loss=3.0862, accuracy=57.1267\n",
            "Epoch 24: loss=2.9307, accuracy=57.8883\n",
            "Epoch 25: loss=2.7832, accuracy=58.1850\n",
            "Epoch 26: loss=2.6636, accuracy=57.9233\n",
            "Epoch 27: loss=2.5279, accuracy=58.1850\n",
            "Epoch 28: loss=2.4290, accuracy=58.6417\n",
            "Epoch 29: loss=2.3203, accuracy=58.2717\n",
            "Epoch 30: loss=2.2184, accuracy=58.8333\n",
            "Epoch 31: loss=2.1327, accuracy=59.4233\n",
            "Epoch 32: loss=2.0520, accuracy=59.2383\n",
            "Epoch 33: loss=1.9715, accuracy=59.8467\n",
            "Epoch 34: loss=1.8998, accuracy=59.7350\n",
            "Epoch 35: loss=1.8333, accuracy=59.9783\n",
            "Epoch 36: loss=1.7746, accuracy=60.3950\n",
            "Epoch 37: loss=1.7136, accuracy=60.7033\n",
            "Epoch 38: loss=1.6557, accuracy=61.1267\n",
            "Epoch 39: loss=1.6110, accuracy=61.5583\n",
            "Epoch 40: loss=1.5597, accuracy=62.1433\n",
            "Epoch 41: loss=1.5100, accuracy=61.6850\n",
            "Epoch 42: loss=1.4668, accuracy=61.9333\n",
            "Epoch 43: loss=1.4241, accuracy=62.2833\n",
            "Epoch 44: loss=1.3857, accuracy=62.5950\n",
            "Epoch 45: loss=1.3478, accuracy=62.7283\n",
            "Epoch 46: loss=1.3130, accuracy=63.3300\n",
            "Epoch 47: loss=1.2804, accuracy=63.4717\n",
            "Epoch 48: loss=1.2485, accuracy=63.7750\n",
            "Epoch 49: loss=1.2182, accuracy=63.5883\n",
            "Epoch 50: loss=1.1893, accuracy=64.0333\n",
            "Epoch 51: loss=1.1628, accuracy=64.2583\n",
            "Epoch 52: loss=1.1380, accuracy=64.3400\n",
            "Epoch 53: loss=1.1125, accuracy=64.7250\n",
            "Epoch 54: loss=1.0868, accuracy=64.5683\n",
            "Epoch 55: loss=1.0624, accuracy=65.1383\n",
            "Epoch 56: loss=1.0420, accuracy=65.1183\n",
            "Epoch 57: loss=1.0197, accuracy=65.2783\n",
            "Epoch 58: loss=0.9996, accuracy=65.4517\n",
            "Epoch 59: loss=0.9799, accuracy=65.8183\n",
            "Epoch 60: loss=0.9606, accuracy=65.6950\n",
            "Epoch 61: loss=0.9458, accuracy=66.0000\n",
            "Epoch 62: loss=0.9305, accuracy=65.9517\n",
            "Epoch 63: loss=0.9100, accuracy=66.6033\n",
            "Epoch 64: loss=0.8922, accuracy=67.0917\n",
            "Epoch 65: loss=0.8785, accuracy=67.0883\n",
            "Epoch 66: loss=0.8621, accuracy=67.0400\n",
            "Epoch 67: loss=0.8510, accuracy=67.5733\n",
            "Epoch 68: loss=0.8406, accuracy=67.0600\n",
            "Epoch 69: loss=0.8210, accuracy=67.2067\n",
            "Epoch 70: loss=0.8079, accuracy=67.4550\n",
            "Epoch 71: loss=0.7962, accuracy=67.5850\n",
            "Epoch 72: loss=0.7848, accuracy=67.9300\n",
            "Epoch 73: loss=0.7729, accuracy=68.0417\n",
            "Epoch 74: loss=0.7620, accuracy=68.2233\n",
            "Epoch 75: loss=0.7501, accuracy=68.7533\n",
            "Epoch 76: loss=0.7416, accuracy=68.7900\n",
            "Epoch 77: loss=0.7280, accuracy=69.0900\n",
            "Epoch 78: loss=0.7184, accuracy=69.3400\n",
            "Epoch 79: loss=0.7075, accuracy=69.5767\n",
            "Epoch 80: loss=0.6982, accuracy=69.5250\n",
            "Epoch 81: loss=0.6893, accuracy=69.8683\n",
            "Epoch 82: loss=0.6826, accuracy=70.0983\n",
            "Epoch 83: loss=0.6728, accuracy=70.3750\n",
            "Epoch 84: loss=0.6641, accuracy=70.2783\n",
            "Epoch 85: loss=0.6547, accuracy=70.3283\n",
            "Epoch 86: loss=0.6472, accuracy=70.2300\n",
            "Epoch 87: loss=0.6397, accuracy=70.3933\n",
            "Epoch 88: loss=0.6326, accuracy=71.0600\n",
            "Epoch 89: loss=0.6248, accuracy=71.1533\n",
            "Epoch 90: loss=0.6168, accuracy=71.0450\n",
            "Epoch 91: loss=0.6107, accuracy=71.6000\n",
            "Epoch 92: loss=0.6085, accuracy=70.9600\n",
            "Epoch 93: loss=0.5984, accuracy=71.7450\n",
            "Epoch 94: loss=0.5906, accuracy=71.5150\n",
            "Epoch 95: loss=0.5855, accuracy=71.8017\n",
            "Epoch 96: loss=0.5783, accuracy=71.8400\n",
            "Epoch 97: loss=0.5733, accuracy=71.7483\n",
            "Epoch 98: loss=0.5667, accuracy=72.2950\n",
            "Epoch 99: loss=0.5601, accuracy=72.4217\n",
            "Epoch 100: loss=0.5551, accuracy=72.4400\n",
            "Epoch 101: loss=0.5489, accuracy=72.5717\n",
            "Epoch 102: loss=0.5452, accuracy=72.3300\n",
            "Epoch 103: loss=0.5401, accuracy=72.6350\n",
            "Epoch 104: loss=0.5332, accuracy=73.0533\n",
            "Epoch 105: loss=0.5303, accuracy=72.5583\n",
            "Epoch 106: loss=0.5240, accuracy=73.3483\n",
            "Epoch 107: loss=0.5185, accuracy=73.6300\n",
            "Epoch 108: loss=0.5136, accuracy=73.1800\n",
            "Epoch 109: loss=0.5111, accuracy=73.2133\n",
            "Epoch 110: loss=0.5061, accuracy=73.3783\n",
            "Epoch 111: loss=0.5004, accuracy=73.5817\n",
            "Epoch 112: loss=0.4963, accuracy=73.9983\n",
            "Epoch 113: loss=0.4924, accuracy=73.7183\n",
            "Epoch 114: loss=0.4883, accuracy=74.2017\n",
            "Epoch 115: loss=0.4840, accuracy=73.9533\n",
            "Epoch 116: loss=0.4802, accuracy=74.3167\n",
            "Epoch 117: loss=0.4762, accuracy=74.7183\n",
            "Epoch 118: loss=0.4729, accuracy=74.3350\n",
            "Epoch 119: loss=0.4705, accuracy=74.3767\n",
            "Epoch 120: loss=0.4649, accuracy=74.2767\n",
            "Epoch 121: loss=0.4617, accuracy=74.9950\n",
            "Epoch 122: loss=0.4585, accuracy=74.9950\n",
            "Epoch 123: loss=0.4549, accuracy=74.9567\n",
            "Epoch 124: loss=0.4511, accuracy=74.7967\n",
            "Epoch 125: loss=0.4483, accuracy=75.3417\n",
            "Epoch 126: loss=0.4446, accuracy=75.2817\n",
            "Epoch 127: loss=0.4412, accuracy=75.0467\n",
            "Epoch 128: loss=0.4384, accuracy=75.2317\n",
            "Epoch 129: loss=0.4351, accuracy=75.3050\n",
            "Epoch 130: loss=0.4321, accuracy=75.4383\n",
            "Epoch 131: loss=0.4290, accuracy=75.7600\n",
            "Epoch 132: loss=0.4299, accuracy=75.2633\n",
            "Epoch 133: loss=0.4230, accuracy=75.9633\n",
            "Epoch 134: loss=0.4217, accuracy=75.8817\n",
            "Epoch 135: loss=0.4176, accuracy=76.0433\n",
            "Epoch 136: loss=0.4150, accuracy=76.1517\n",
            "Epoch 137: loss=0.4123, accuracy=76.1283\n",
            "Epoch 138: loss=0.4097, accuracy=75.9683\n",
            "Epoch 139: loss=0.4070, accuracy=76.2667\n",
            "Epoch 140: loss=0.4044, accuracy=76.5583\n",
            "Epoch 141: loss=0.4022, accuracy=76.6317\n",
            "Epoch 142: loss=0.3996, accuracy=76.6017\n",
            "Epoch 143: loss=0.3973, accuracy=76.7950\n",
            "Epoch 144: loss=0.3946, accuracy=76.6883\n",
            "Epoch 145: loss=0.3920, accuracy=76.8533\n",
            "Epoch 146: loss=0.3903, accuracy=76.5500\n",
            "Epoch 147: loss=0.3918, accuracy=76.4600\n",
            "Epoch 148: loss=0.3855, accuracy=77.0467\n",
            "Epoch 149: loss=0.3853, accuracy=76.9050\n",
            "Epoch 150: loss=0.3816, accuracy=77.2900\n",
            "Epoch 151: loss=0.3794, accuracy=77.0850\n",
            "Epoch 152: loss=0.3768, accuracy=77.2900\n",
            "Epoch 153: loss=0.3748, accuracy=77.4100\n",
            "Epoch 154: loss=0.3740, accuracy=77.5683\n",
            "Epoch 155: loss=0.3707, accuracy=77.4850\n",
            "Epoch 156: loss=0.3693, accuracy=77.3883\n",
            "Epoch 157: loss=0.3668, accuracy=77.5317\n",
            "Epoch 158: loss=0.3680, accuracy=77.0317\n",
            "Epoch 159: loss=0.3630, accuracy=77.7283\n",
            "Epoch 160: loss=0.3623, accuracy=77.5333\n",
            "Epoch 161: loss=0.3596, accuracy=77.6567\n",
            "Epoch 162: loss=0.3578, accuracy=77.9250\n",
            "Epoch 163: loss=0.3582, accuracy=77.5283\n",
            "Epoch 164: loss=0.3537, accuracy=78.1450\n",
            "Epoch 165: loss=0.3537, accuracy=77.9717\n",
            "Epoch 166: loss=0.3508, accuracy=78.1433\n",
            "Epoch 167: loss=0.3487, accuracy=78.3083\n",
            "Epoch 168: loss=0.3470, accuracy=78.2617\n",
            "Epoch 169: loss=0.3469, accuracy=78.1417\n",
            "Epoch 170: loss=0.3439, accuracy=78.2350\n",
            "Epoch 171: loss=0.3421, accuracy=78.3217\n",
            "Epoch 172: loss=0.3408, accuracy=78.1833\n",
            "Epoch 173: loss=0.3389, accuracy=78.6067\n",
            "Epoch 174: loss=0.3382, accuracy=78.2400\n",
            "Epoch 175: loss=0.3358, accuracy=78.7067\n",
            "Epoch 176: loss=0.3347, accuracy=78.4100\n",
            "Epoch 177: loss=0.3328, accuracy=78.6417\n",
            "Epoch 178: loss=0.3320, accuracy=78.5167\n",
            "Epoch 179: loss=0.3300, accuracy=78.8100\n",
            "Epoch 180: loss=0.3289, accuracy=78.8017\n",
            "Epoch 181: loss=0.3270, accuracy=78.7717\n",
            "Epoch 182: loss=0.3259, accuracy=78.8067\n",
            "Epoch 183: loss=0.3244, accuracy=79.0200\n",
            "Epoch 184: loss=0.3230, accuracy=79.0600\n",
            "Epoch 185: loss=0.3216, accuracy=79.1083\n",
            "Epoch 186: loss=0.3204, accuracy=79.2867\n",
            "Epoch 187: loss=0.3210, accuracy=78.8567\n",
            "Epoch 188: loss=0.3192, accuracy=79.0517\n",
            "Epoch 189: loss=0.3175, accuracy=79.1700\n",
            "Epoch 190: loss=0.3156, accuracy=79.0250\n",
            "Epoch 191: loss=0.3142, accuracy=79.1083\n",
            "Epoch 192: loss=0.3128, accuracy=79.3067\n",
            "Epoch 193: loss=0.3121, accuracy=79.2683\n",
            "Epoch 194: loss=0.3123, accuracy=79.0467\n",
            "Epoch 195: loss=0.3094, accuracy=79.4450\n",
            "Epoch 196: loss=0.3078, accuracy=79.5133\n",
            "Epoch 197: loss=0.3067, accuracy=79.4883\n",
            "Epoch 198: loss=0.3056, accuracy=79.5250\n",
            "Epoch 199: loss=0.3044, accuracy=79.5483\n",
            "Epoch 200: loss=0.3039, accuracy=79.3850\n",
            "Epoch 201: loss=0.3020, accuracy=79.7233\n",
            "Epoch 202: loss=0.3013, accuracy=79.6150\n",
            "Epoch 203: loss=0.3004, accuracy=79.4433\n",
            "Epoch 204: loss=0.2986, accuracy=79.7367\n",
            "Epoch 205: loss=0.2999, accuracy=79.5850\n",
            "Epoch 206: loss=0.2967, accuracy=79.9683\n",
            "Epoch 207: loss=0.2954, accuracy=79.8150\n",
            "Epoch 208: loss=0.2945, accuracy=79.8517\n",
            "Epoch 209: loss=0.2942, accuracy=79.6367\n",
            "Epoch 210: loss=0.2928, accuracy=79.8517\n",
            "Epoch 211: loss=0.2916, accuracy=80.0150\n",
            "Epoch 212: loss=0.2904, accuracy=80.0150\n",
            "Epoch 213: loss=0.2910, accuracy=79.7983\n",
            "Epoch 214: loss=0.2890, accuracy=79.9833\n",
            "Epoch 215: loss=0.2876, accuracy=80.0267\n",
            "Epoch 216: loss=0.2866, accuracy=80.2150\n",
            "Epoch 217: loss=0.2857, accuracy=80.0833\n",
            "Epoch 218: loss=0.2848, accuracy=80.1050\n",
            "Epoch 219: loss=0.2840, accuracy=80.2400\n",
            "Epoch 220: loss=0.2827, accuracy=80.2783\n",
            "Epoch 221: loss=0.2819, accuracy=80.4217\n",
            "Epoch 222: loss=0.2811, accuracy=80.1767\n",
            "Epoch 223: loss=0.2800, accuracy=80.4033\n",
            "Epoch 224: loss=0.2816, accuracy=80.1617\n",
            "Epoch 225: loss=0.2790, accuracy=80.2800\n",
            "Epoch 226: loss=0.2775, accuracy=80.2483\n",
            "Epoch 227: loss=0.2771, accuracy=80.3967\n",
            "Epoch 228: loss=0.2769, accuracy=80.3917\n",
            "Epoch 229: loss=0.2748, accuracy=80.6717\n",
            "Epoch 230: loss=0.2765, accuracy=80.1567\n",
            "Epoch 231: loss=0.2742, accuracy=80.4783\n",
            "Epoch 232: loss=0.2729, accuracy=80.4733\n",
            "Epoch 233: loss=0.2722, accuracy=80.4917\n",
            "Epoch 234: loss=0.2710, accuracy=80.5833\n",
            "Epoch 235: loss=0.2706, accuracy=80.8150\n",
            "Epoch 236: loss=0.2696, accuracy=80.6433\n",
            "Epoch 237: loss=0.2687, accuracy=80.7783\n",
            "Epoch 238: loss=0.2679, accuracy=80.7200\n",
            "Epoch 239: loss=0.2669, accuracy=80.7067\n",
            "Epoch 240: loss=0.2662, accuracy=80.8217\n",
            "Epoch 241: loss=0.2658, accuracy=80.7250\n",
            "Epoch 242: loss=0.2658, accuracy=80.6750\n",
            "Epoch 243: loss=0.2642, accuracy=80.8850\n",
            "Epoch 244: loss=0.2636, accuracy=80.8667\n",
            "Epoch 245: loss=0.2631, accuracy=80.7100\n",
            "Epoch 246: loss=0.2622, accuracy=80.9350\n",
            "Epoch 247: loss=0.2612, accuracy=80.8200\n",
            "Epoch 248: loss=0.2607, accuracy=81.1417\n",
            "Epoch 249: loss=0.2596, accuracy=81.1900\n",
            "Epoch 250: loss=0.2590, accuracy=80.9300\n",
            "Epoch 251: loss=0.2584, accuracy=81.0483\n",
            "Epoch 252: loss=0.2577, accuracy=81.1100\n",
            "Epoch 253: loss=0.2571, accuracy=81.1683\n",
            "Epoch 254: loss=0.2563, accuracy=81.1533\n",
            "Epoch 255: loss=0.2563, accuracy=81.0950\n",
            "Epoch 256: loss=0.2552, accuracy=81.1983\n",
            "Epoch 257: loss=0.2547, accuracy=81.1950\n",
            "Epoch 258: loss=0.2540, accuracy=81.1733\n",
            "Epoch 259: loss=0.2540, accuracy=81.0800\n",
            "Epoch 260: loss=0.2528, accuracy=81.1983\n",
            "Epoch 261: loss=0.2519, accuracy=81.1933\n",
            "Epoch 262: loss=0.2524, accuracy=81.0783\n",
            "Epoch 263: loss=0.2505, accuracy=81.4117\n",
            "Epoch 264: loss=0.2501, accuracy=81.4367\n",
            "Epoch 265: loss=0.2503, accuracy=81.1800\n",
            "Epoch 266: loss=0.2488, accuracy=81.3317\n",
            "Epoch 267: loss=0.2484, accuracy=81.5650\n",
            "Epoch 268: loss=0.2480, accuracy=81.4150\n",
            "Epoch 269: loss=0.2474, accuracy=81.2617\n",
            "Epoch 270: loss=0.2467, accuracy=81.6067\n",
            "Epoch 271: loss=0.2455, accuracy=81.6417\n",
            "Epoch 272: loss=0.2454, accuracy=81.4533\n",
            "Epoch 273: loss=0.2448, accuracy=81.4167\n",
            "Epoch 274: loss=0.2441, accuracy=81.5117\n",
            "Epoch 275: loss=0.2436, accuracy=81.6917\n",
            "Epoch 276: loss=0.2428, accuracy=81.6300\n",
            "Epoch 277: loss=0.2425, accuracy=81.6917\n",
            "Epoch 278: loss=0.2417, accuracy=81.6583\n",
            "Epoch 279: loss=0.2415, accuracy=81.6567\n",
            "Epoch 280: loss=0.2408, accuracy=81.7750\n",
            "Epoch 281: loss=0.2401, accuracy=81.8750\n",
            "Epoch 282: loss=0.2400, accuracy=81.6117\n",
            "Epoch 283: loss=0.2392, accuracy=81.7400\n",
            "Epoch 284: loss=0.2390, accuracy=81.7467\n",
            "Epoch 285: loss=0.2381, accuracy=81.7117\n",
            "Epoch 286: loss=0.2376, accuracy=81.7783\n",
            "Epoch 287: loss=0.2371, accuracy=81.9017\n",
            "Epoch 288: loss=0.2363, accuracy=81.7850\n",
            "Epoch 289: loss=0.2362, accuracy=81.8650\n",
            "Epoch 290: loss=0.2354, accuracy=82.0233\n",
            "Epoch 291: loss=0.2351, accuracy=81.6733\n",
            "Epoch 292: loss=0.2346, accuracy=81.9383\n",
            "Epoch 293: loss=0.2350, accuracy=81.8050\n",
            "Epoch 294: loss=0.2335, accuracy=81.9983\n",
            "Epoch 295: loss=0.2330, accuracy=81.9633\n",
            "Epoch 296: loss=0.2326, accuracy=81.7500\n",
            "Epoch 297: loss=0.2320, accuracy=82.1950\n",
            "Epoch 298: loss=0.2318, accuracy=81.9383\n",
            "Epoch 299: loss=0.2319, accuracy=82.0417\n",
            "Epoch 300: loss=0.2307, accuracy=82.0950\n",
            "Epoch 301: loss=0.2300, accuracy=82.0683\n",
            "Epoch 302: loss=0.2299, accuracy=82.1317\n",
            "Epoch 303: loss=0.2291, accuracy=82.1033\n",
            "Epoch 304: loss=0.2286, accuracy=82.1700\n",
            "Epoch 305: loss=0.2286, accuracy=82.0433\n",
            "Epoch 306: loss=0.2279, accuracy=82.1150\n",
            "Epoch 307: loss=0.2275, accuracy=82.1483\n",
            "Epoch 308: loss=0.2268, accuracy=82.2567\n",
            "Epoch 309: loss=0.2268, accuracy=82.2433\n",
            "Epoch 310: loss=0.2259, accuracy=82.2983\n",
            "Epoch 311: loss=0.2256, accuracy=82.2400\n",
            "Epoch 312: loss=0.2266, accuracy=82.1300\n",
            "Epoch 313: loss=0.2251, accuracy=82.1817\n",
            "Epoch 314: loss=0.2243, accuracy=82.2483\n",
            "Epoch 315: loss=0.2244, accuracy=82.1483\n",
            "Epoch 316: loss=0.2238, accuracy=82.3983\n",
            "Epoch 317: loss=0.2238, accuracy=82.2983\n",
            "Epoch 318: loss=0.2225, accuracy=82.4233\n",
            "Epoch 319: loss=0.2222, accuracy=82.3100\n",
            "Epoch 320: loss=0.2226, accuracy=82.1533\n",
            "Epoch 321: loss=0.2215, accuracy=82.3000\n",
            "Epoch 322: loss=0.2210, accuracy=82.4933\n",
            "Epoch 323: loss=0.2207, accuracy=82.4450\n",
            "Epoch 324: loss=0.2202, accuracy=82.3700\n",
            "Epoch 325: loss=0.2208, accuracy=82.3400\n",
            "Epoch 326: loss=0.2199, accuracy=82.3783\n",
            "Epoch 327: loss=0.2203, accuracy=82.4283\n",
            "Epoch 328: loss=0.2194, accuracy=82.4400\n",
            "Epoch 329: loss=0.2186, accuracy=82.5983\n",
            "Epoch 330: loss=0.2181, accuracy=82.6150\n",
            "Epoch 331: loss=0.2175, accuracy=82.5950\n",
            "Epoch 332: loss=0.2170, accuracy=82.4733\n",
            "Epoch 333: loss=0.2166, accuracy=82.5600\n",
            "Epoch 334: loss=0.2166, accuracy=82.4500\n",
            "Epoch 335: loss=0.2167, accuracy=82.5950\n",
            "Epoch 336: loss=0.2154, accuracy=82.5417\n",
            "Epoch 337: loss=0.2153, accuracy=82.6650\n",
            "Epoch 338: loss=0.2149, accuracy=82.6383\n",
            "Epoch 339: loss=0.2149, accuracy=82.5550\n",
            "Epoch 340: loss=0.2141, accuracy=82.6367\n",
            "Epoch 341: loss=0.2139, accuracy=82.6117\n",
            "Epoch 342: loss=0.2138, accuracy=82.6383\n",
            "Epoch 343: loss=0.2136, accuracy=82.8117\n",
            "Epoch 344: loss=0.2131, accuracy=82.6733\n",
            "Epoch 345: loss=0.2123, accuracy=82.7000\n",
            "Epoch 346: loss=0.2122, accuracy=82.7183\n",
            "Epoch 347: loss=0.2119, accuracy=82.7200\n",
            "Epoch 348: loss=0.2112, accuracy=82.8850\n",
            "Epoch 349: loss=0.2111, accuracy=82.5783\n",
            "Epoch 350: loss=0.2108, accuracy=82.5650\n",
            "Epoch 351: loss=0.2104, accuracy=82.7567\n",
            "Epoch 352: loss=0.2100, accuracy=82.7300\n",
            "Epoch 353: loss=0.2103, accuracy=82.7483\n",
            "Epoch 354: loss=0.2094, accuracy=82.8500\n",
            "Epoch 355: loss=0.2091, accuracy=82.7467\n",
            "Epoch 356: loss=0.2085, accuracy=82.8950\n",
            "Epoch 357: loss=0.2086, accuracy=82.8417\n",
            "Epoch 358: loss=0.2078, accuracy=82.9083\n",
            "Epoch 359: loss=0.2079, accuracy=82.8900\n",
            "Epoch 360: loss=0.2074, accuracy=82.8833\n",
            "Epoch 361: loss=0.2071, accuracy=82.9383\n",
            "Epoch 362: loss=0.2071, accuracy=82.9017\n",
            "Epoch 363: loss=0.2063, accuracy=82.9267\n",
            "Epoch 364: loss=0.2060, accuracy=82.9367\n",
            "Epoch 365: loss=0.2059, accuracy=83.0333\n",
            "Epoch 366: loss=0.2054, accuracy=83.0067\n",
            "Epoch 367: loss=0.2055, accuracy=83.0633\n",
            "Epoch 368: loss=0.2050, accuracy=82.7900\n",
            "Epoch 369: loss=0.2045, accuracy=82.9483\n",
            "Epoch 370: loss=0.2042, accuracy=82.8550\n",
            "Epoch 371: loss=0.2038, accuracy=83.1100\n",
            "Epoch 372: loss=0.2039, accuracy=83.0300\n",
            "Epoch 373: loss=0.2032, accuracy=83.0367\n",
            "Epoch 374: loss=0.2034, accuracy=82.9833\n",
            "Epoch 375: loss=0.2027, accuracy=83.0383\n",
            "Epoch 376: loss=0.2026, accuracy=83.0833\n",
            "Epoch 377: loss=0.2022, accuracy=83.0667\n",
            "Epoch 378: loss=0.2018, accuracy=83.0967\n",
            "Epoch 379: loss=0.2016, accuracy=83.0350\n",
            "Epoch 380: loss=0.2020, accuracy=83.1167\n",
            "Epoch 381: loss=0.2009, accuracy=83.2650\n",
            "Epoch 382: loss=0.2012, accuracy=82.9883\n",
            "Epoch 383: loss=0.2004, accuracy=83.2950\n",
            "Epoch 384: loss=0.2021, accuracy=82.9100\n",
            "Epoch 385: loss=0.2003, accuracy=82.9317\n",
            "Epoch 386: loss=0.2001, accuracy=83.1717\n",
            "Epoch 387: loss=0.1994, accuracy=83.1050\n",
            "Epoch 388: loss=0.1993, accuracy=83.0183\n",
            "Epoch 389: loss=0.1989, accuracy=83.1967\n",
            "Epoch 390: loss=0.1988, accuracy=83.1233\n",
            "Epoch 391: loss=0.1984, accuracy=83.1867\n",
            "Epoch 392: loss=0.1978, accuracy=83.3050\n",
            "Epoch 393: loss=0.1982, accuracy=83.2550\n",
            "Epoch 394: loss=0.1986, accuracy=83.1150\n",
            "Epoch 395: loss=0.1974, accuracy=83.1083\n",
            "Epoch 396: loss=0.1975, accuracy=83.0233\n",
            "Epoch 397: loss=0.1982, accuracy=83.1033\n",
            "Epoch 398: loss=0.1969, accuracy=83.2517\n",
            "Epoch 399: loss=0.1960, accuracy=83.3050\n",
            "Epoch 400: loss=0.1960, accuracy=83.2333\n",
            "Epoch 401: loss=0.1956, accuracy=83.3250\n",
            "Epoch 402: loss=0.1958, accuracy=83.3033\n",
            "Epoch 403: loss=0.1952, accuracy=83.3400\n",
            "Epoch 404: loss=0.1948, accuracy=83.3417\n",
            "Epoch 405: loss=0.1948, accuracy=83.3667\n",
            "Epoch 406: loss=0.1942, accuracy=83.4517\n",
            "Epoch 407: loss=0.1945, accuracy=83.4183\n",
            "Epoch 408: loss=0.1945, accuracy=83.1917\n",
            "Epoch 409: loss=0.1937, accuracy=83.3250\n",
            "Epoch 410: loss=0.1940, accuracy=83.3633\n",
            "Epoch 411: loss=0.1931, accuracy=83.3933\n",
            "Epoch 412: loss=0.1930, accuracy=83.4267\n",
            "Epoch 413: loss=0.1930, accuracy=83.2317\n",
            "Epoch 414: loss=0.1924, accuracy=83.5033\n",
            "Epoch 415: loss=0.1923, accuracy=83.3733\n",
            "Epoch 416: loss=0.1922, accuracy=83.5217\n",
            "Epoch 417: loss=0.1916, accuracy=83.4517\n",
            "Epoch 418: loss=0.1919, accuracy=83.3583\n",
            "Epoch 419: loss=0.1915, accuracy=83.5267\n",
            "Epoch 420: loss=0.1910, accuracy=83.5167\n",
            "Epoch 421: loss=0.1911, accuracy=83.4583\n",
            "Epoch 422: loss=0.1905, accuracy=83.5767\n",
            "Epoch 423: loss=0.1905, accuracy=83.5567\n",
            "Epoch 424: loss=0.1904, accuracy=83.3400\n",
            "Epoch 425: loss=0.1899, accuracy=83.5867\n",
            "Epoch 426: loss=0.1899, accuracy=83.4017\n",
            "Epoch 427: loss=0.1894, accuracy=83.5300\n",
            "Epoch 428: loss=0.1894, accuracy=83.5083\n",
            "Epoch 429: loss=0.1897, accuracy=83.4967\n",
            "Epoch 430: loss=0.1895, accuracy=83.4317\n",
            "Epoch 431: loss=0.1886, accuracy=83.6900\n",
            "Epoch 432: loss=0.1883, accuracy=83.5600\n",
            "Epoch 433: loss=0.1880, accuracy=83.6500\n",
            "Epoch 434: loss=0.1879, accuracy=83.6650\n",
            "Epoch 435: loss=0.1878, accuracy=83.5700\n",
            "Epoch 436: loss=0.1874, accuracy=83.6183\n",
            "Epoch 437: loss=0.1872, accuracy=83.6600\n",
            "Epoch 438: loss=0.1871, accuracy=83.7133\n",
            "Epoch 439: loss=0.1870, accuracy=83.6550\n",
            "Epoch 440: loss=0.1866, accuracy=83.5967\n",
            "Epoch 441: loss=0.1864, accuracy=83.7617\n",
            "Epoch 442: loss=0.1863, accuracy=83.5850\n",
            "Epoch 443: loss=0.1859, accuracy=83.6283\n",
            "Epoch 444: loss=0.1857, accuracy=83.6583\n",
            "Epoch 445: loss=0.1858, accuracy=83.8017\n",
            "Epoch 446: loss=0.1858, accuracy=83.7050\n",
            "Epoch 447: loss=0.1852, accuracy=83.6767\n",
            "Epoch 448: loss=0.1851, accuracy=83.7800\n",
            "Epoch 449: loss=0.1848, accuracy=83.7267\n",
            "Epoch 450: loss=0.1851, accuracy=83.7817\n",
            "Epoch 451: loss=0.1844, accuracy=83.7767\n",
            "Epoch 452: loss=0.1842, accuracy=83.7317\n",
            "Epoch 453: loss=0.1840, accuracy=83.6533\n",
            "Epoch 454: loss=0.1851, accuracy=83.6417\n",
            "Epoch 455: loss=0.1837, accuracy=83.7567\n",
            "Epoch 456: loss=0.1833, accuracy=83.8167\n",
            "Epoch 457: loss=0.1838, accuracy=83.7167\n",
            "Epoch 458: loss=0.1832, accuracy=83.6067\n",
            "Epoch 459: loss=0.1832, accuracy=83.7300\n",
            "Epoch 460: loss=0.1828, accuracy=83.7283\n",
            "Epoch 461: loss=0.1824, accuracy=83.8433\n",
            "Epoch 462: loss=0.1822, accuracy=83.8033\n",
            "Epoch 463: loss=0.1826, accuracy=83.6367\n",
            "Epoch 464: loss=0.1824, accuracy=83.6850\n",
            "Epoch 465: loss=0.1818, accuracy=83.8067\n",
            "Epoch 466: loss=0.1821, accuracy=83.6850\n",
            "Epoch 467: loss=0.1815, accuracy=83.6817\n",
            "Epoch 468: loss=0.1813, accuracy=83.8300\n",
            "Epoch 469: loss=0.1815, accuracy=83.6650\n",
            "Epoch 470: loss=0.1807, accuracy=83.8700\n",
            "Epoch 471: loss=0.1806, accuracy=83.8667\n",
            "Epoch 472: loss=0.1804, accuracy=83.8917\n",
            "Epoch 473: loss=0.1802, accuracy=83.8000\n",
            "Epoch 474: loss=0.1825, accuracy=83.4283\n",
            "Epoch 475: loss=0.1800, accuracy=83.9117\n",
            "Epoch 476: loss=0.1798, accuracy=83.8050\n",
            "Epoch 477: loss=0.1795, accuracy=83.8733\n",
            "Epoch 478: loss=0.1793, accuracy=83.9300\n",
            "Epoch 479: loss=0.1792, accuracy=83.9567\n",
            "Epoch 480: loss=0.1795, accuracy=83.8500\n",
            "Epoch 481: loss=0.1789, accuracy=83.9667\n",
            "Epoch 482: loss=0.1791, accuracy=83.8750\n",
            "Epoch 483: loss=0.1786, accuracy=83.9033\n",
            "Epoch 484: loss=0.1782, accuracy=84.0700\n",
            "Epoch 485: loss=0.1781, accuracy=83.8333\n",
            "Epoch 486: loss=0.1784, accuracy=84.0367\n",
            "Epoch 487: loss=0.1790, accuracy=83.6800\n",
            "Epoch 488: loss=0.1776, accuracy=84.0233\n",
            "Epoch 489: loss=0.1783, accuracy=83.8050\n",
            "Epoch 490: loss=0.1773, accuracy=83.9817\n",
            "Epoch 491: loss=0.1771, accuracy=84.0250\n",
            "Epoch 492: loss=0.1776, accuracy=84.0117\n",
            "Epoch 493: loss=0.1768, accuracy=84.1017\n",
            "Epoch 494: loss=0.1767, accuracy=84.0283\n",
            "Epoch 495: loss=0.1770, accuracy=83.7750\n",
            "Epoch 496: loss=0.1770, accuracy=84.0150\n",
            "Epoch 497: loss=0.1763, accuracy=83.9350\n",
            "Epoch 498: loss=0.1761, accuracy=83.9950\n",
            "Epoch 499: loss=0.1760, accuracy=84.0317\n",
            "Epoch 500: loss=0.1758, accuracy=83.9517\n",
            "Test accuracy: 0.8222\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer2)\n",
        "In the above linear classifier, we are getting a test accuracy of 82.22% after 500 epochs. Linear classifiers are simple models that perform well for data that can be separated by a linear decision boundary. However, they do not perform well for data that cannot be separated by a linear decision boundary.\n",
        "\n",
        "We can observe that with each epoch, the loss is reducing and the accuracy is increasing. This is because the model is learning to better fit the data. However, it is important to note that the model may not be able to learn to fit the data perfectly, especially if the data is not linearly separable."
      ],
      "metadata": {
        "id": "0zM-SSHx8-DC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Question 3) (7 pts) Train a neural network classifier with quadratic loss â„“(y, f(x)) = (y âˆ’ f(x))2\n",
        ". Plot the progress\n",
        "of the test and training accuracy (y-axis) as a function of the iteration counter t (x-axis)2\n",
        ". Report the\n",
        "final test accuracy for the following choices\n",
        "â€¢ k=5\n",
        "â€¢ k=40\n",
        "â€¢ k=200\n",
        "â€¢ Comment on the role of hidden units k on the ease of optimization and accuracy***"
      ],
      "metadata": {
        "id": "z6BNcfBw6rwW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\"\"\"Relu Function\"\"\"\n",
        "def relu(x):\n",
        "    return np.maximum(x,0)\n",
        "\n",
        "\"\"\"Feed Forward\"\"\"\n",
        "def feed_forward(x, W, v):\n",
        "    h= relu(np.dot(W,x))\n",
        "    return np.dot(v.T,h)\n",
        "\n",
        "\"\"\"Calculating Gradient\"\"\"\n",
        "def get_gradients(x_b, y_b, W, v):\n",
        "    gradient_v = np.zeros_like(v)\n",
        "    gradient_W = np.zeros_like(W)\n",
        "\n",
        "    for x, y in zip(x_b, y_b):\n",
        "        h = relu(np.dot(W,x))\n",
        "        f_x = np.dot(v.T,h)\n",
        "        error = y - f_x\n",
        "        gradient_v += -2*(error)*(h)\n",
        "        gradient_W += -2*(error)*(np.outer(v * (h > 0), x))\n",
        "    return gradient_v, gradient_W\n",
        "\n",
        "def xavier_initialization(d, k):\n",
        "    W =np.random.normal(0, 1/d, (k, d))\n",
        "    v =np.random.normal(0, 1/k, k)\n",
        "    return W, v\n",
        "\n",
        "\n",
        "\"\"\" Updating Weights\"\"\"\n",
        "def set_weights(W, v, gradient_W, gradient_v, lr, b_size):\n",
        "    v =v -lr*(gradient_v / b_size)\n",
        "    W = W -lr*(gradient_W / b_size)\n",
        "    return W,v\n",
        "\n",
        "def get_accuracyandloss(x, y, W, v):\n",
        "    y_pred = np.array([feed_forward(i, W, v) for i in x])\n",
        "    accuracy = np.mean((y_pred > 0) == y)\n",
        "    loss = np.mean((y - y_pred) ** 2)\n",
        "    return accuracy, loss\n",
        "\n",
        "def train(x_train, y_train, x_test, y_test, k, epochs, b_size, lr, output_index):\n",
        "\n",
        "    \"\"\"Initalizing the weights\"\"\"\n",
        "    d = x_train.shape[1]\n",
        "    W, v = xavier_initialization(d, k)\n",
        "\n",
        "    train_accuracy = []\n",
        "    test_accuracy = []\n",
        "    train_loss = []\n",
        "    test_loss = []\n",
        "    itr = 0\n",
        "    \"\"\" Calculating initial accuracy\"\"\"\n",
        "    train_acc, train_epoch_loss = get_accuracyandloss(x_train,y_train, W,v)\n",
        "    test_acc, test_epoch_loss =get_accuracyandloss(x_test,y_test, W,v)\n",
        "\n",
        "    print(f\"Iteration {itr}: Training accuracy {train_acc}, Test accuracy {test_acc} and Training loss {train_epoch_loss}\")\n",
        "    train_accuracy.append(train_acc)\n",
        "    test_accuracy.append(test_acc)\n",
        "    train_loss.append(train_epoch_loss)\n",
        "    test_loss.append(test_epoch_loss)\n",
        "\n",
        "    \"\"\"Training Loop for Each epoch \"\"\"\n",
        "    for epoch in range(epochs):\n",
        "        indices = np.random.permutation(x_train.shape[0])\n",
        "        n = x_train.shape[0]\n",
        "        \"\"\" Iterating Batch By Batch\"\"\"\n",
        "        for t in range(0, n, b_size):\n",
        "\n",
        "            \"\"\"Getting Batch Data\"\"\"\n",
        "            batch_indices = indices[t:t+b_size]\n",
        "            x_b = x_train[batch_indices]\n",
        "            y_b = y_train[batch_indices]\n",
        "\n",
        "            \"\"\"Calculating Gradient\"\"\"\n",
        "            gradient_v, gradient_W = get_gradients(x_b, y_b, W, v)\n",
        "\n",
        "            \"\"\"Updating Weight\"\"\"\n",
        "            W, v = set_weights(W, v, gradient_W, gradient_v, lr, b_size)\n",
        "\n",
        "            itr += 1\n",
        "\n",
        "            if itr % output_index == 0:\n",
        "                \"\"\"Ccalculating Accuracy and Loss\"\"\"\n",
        "                train_acc, train_epoch_loss = get_accuracyandloss(x_train, y_train, W, v)\n",
        "                test_acc, test_epoch_loss = get_accuracyandloss(x_test, y_test, W, v)\n",
        "\n",
        "                print(f\"Iteration {itr}: Training Accuracy {train_acc}, Test Accuracy {test_acc} and Training loss {train_epoch_loss}\")\n",
        "                train_accuracy.append(train_acc)\n",
        "                test_accuracy.append(test_acc)\n",
        "                train_loss.append(train_epoch_loss)\n",
        "                test_loss.append(test_epoch_loss)\n",
        "\n",
        "    return train_accuracy, test_accuracy, train_loss, test_loss, W, v\n",
        "\n",
        "def plot_accuracy(train_acc, test_acc, k):\n",
        "    fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(10,4))\n",
        "    ax[0].plot(range(len(train_acc)), train_acc, label=\"Train Accuracy\")\n",
        "    ax[0].set_title(f\"Training Accuracy (K'={k})\")\n",
        "    ax[0].set_xlabel(\"Iteration\")\n",
        "    ax[0].set_ylabel(\"Accuracy\")\n",
        "    ax[0].legend()\n",
        "    ax[1].plot(range(len(test_acc)), test_acc, label=\"Test Accuracy\")\n",
        "    ax[1].set_title(f\"Test Accuracy (K={k})\")\n",
        "    ax[1].set_xlabel(\"Iteration\")\n",
        "    ax[1].set_ylabel(\"Accuracy\")\n",
        "    ax[1].legend()\n",
        "    plt.show()\n",
        "\n",
        "def solution3():\n",
        "    x_train, y_train, x_test, y_test = load_data()\n",
        "    k_values = [5, 40, 200]\n",
        "    learning_rate = 0.0005\n",
        "    epochs = 10\n",
        "    b_size = 10\n",
        "    output_index = 100\n",
        "\n",
        "    for k in k_values:\n",
        "        print(f\"\\nTraining with k = {k}\")\n",
        "        train_accuracy, test_accuracy, train_loss, test_loss, W, v = train(x_train, y_train, x_test, y_test, k, epochs, b_size, learning_rate, output_index)\n",
        "\n",
        "        print(f\"Final test accuracy for k = {k}: {test_accuracy[-1]}\")\n",
        "        plot_accuracy(train_accuracy, test_accuracy, k)\n",
        "\n",
        "solution3()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Mui9VLZEwhWu",
        "outputId": "7a527964-b5e9-49a6-d5b6-a91b7b6d2928"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training with k = 5\n",
            "Iteration 0: Training accuracy 0.39566666666666667, Test accuracy 0.3824 and Training loss 0.4892526635997046\n",
            "Iteration 100: Training Accuracy 0.4900833333333333, Test Accuracy 0.4861 and Training loss 0.23425192206130357\n",
            "Iteration 200: Training Accuracy 0.49038333333333334, Test Accuracy 0.488 and Training loss 0.20541647540259222\n",
            "Iteration 300: Training Accuracy 0.4909833333333333, Test Accuracy 0.4927 and Training loss 0.19230351444647473\n",
            "Iteration 400: Training Accuracy 0.49475, Test Accuracy 0.5133 and Training loss 0.18127601984474986\n",
            "Iteration 500: Training Accuracy 0.5045166666666666, Test Accuracy 0.5609 and Training loss 0.17082811808378537\n",
            "Iteration 600: Training Accuracy 0.5174833333333333, Test Accuracy 0.617 and Training loss 0.16365201024812284\n",
            "Iteration 700: Training Accuracy 0.5140666666666667, Test Accuracy 0.6173 and Training loss 0.15910407274984567\n",
            "Iteration 800: Training Accuracy 0.5233, Test Accuracy 0.6577 and Training loss 0.15353800786377764\n",
            "Iteration 900: Training Accuracy 0.5292666666666667, Test Accuracy 0.6847 and Training loss 0.1492966947863707\n",
            "Iteration 1000: Training Accuracy 0.5344166666666667, Test Accuracy 0.7168 and Training loss 0.14600786908469449\n",
            "Iteration 1100: Training Accuracy 0.5511666666666667, Test Accuracy 0.7448 and Training loss 0.1434093047286216\n",
            "Iteration 1200: Training Accuracy 0.5255666666666666, Test Accuracy 0.7095 and Training loss 0.14152015613761226\n",
            "Iteration 1300: Training Accuracy 0.52505, Test Accuracy 0.7195 and Training loss 0.13989501369472498\n",
            "Iteration 1400: Training Accuracy 0.5343833333333333, Test Accuracy 0.7459 and Training loss 0.13570613831972747\n",
            "Iteration 1500: Training Accuracy 0.5493833333333333, Test Accuracy 0.7701 and Training loss 0.13344721897677336\n",
            "Iteration 1600: Training Accuracy 0.5372333333333333, Test Accuracy 0.7585 and Training loss 0.13267888381418513\n",
            "Iteration 1700: Training Accuracy 0.5682833333333334, Test Accuracy 0.7939 and Training loss 0.13101517308505128\n",
            "Iteration 1800: Training Accuracy 0.55365, Test Accuracy 0.7919 and Training loss 0.12822026468073203\n",
            "Iteration 1900: Training Accuracy 0.5499, Test Accuracy 0.7923 and Training loss 0.1273394279746498\n",
            "Iteration 2000: Training Accuracy 0.5724, Test Accuracy 0.8089 and Training loss 0.12660824442116891\n",
            "Iteration 2100: Training Accuracy 0.5684833333333333, Test Accuracy 0.8113 and Training loss 0.12514569934503306\n",
            "Iteration 2200: Training Accuracy 0.5562666666666667, Test Accuracy 0.809 and Training loss 0.1238805235046812\n",
            "Iteration 2300: Training Accuracy 0.55825, Test Accuracy 0.8081 and Training loss 0.12297751000011993\n",
            "Iteration 2400: Training Accuracy 0.5495666666666666, Test Accuracy 0.8047 and Training loss 0.12246869391490962\n",
            "Iteration 2500: Training Accuracy 0.55815, Test Accuracy 0.8122 and Training loss 0.12167391504473654\n",
            "Iteration 2600: Training Accuracy 0.5732333333333334, Test Accuracy 0.8357 and Training loss 0.1207702911999622\n",
            "Iteration 2700: Training Accuracy 0.5700833333333334, Test Accuracy 0.8385 and Training loss 0.11987133933704645\n",
            "Iteration 2800: Training Accuracy 0.5611833333333334, Test Accuracy 0.8313 and Training loss 0.11894963861570042\n",
            "Iteration 2900: Training Accuracy 0.5816833333333333, Test Accuracy 0.8455 and Training loss 0.11866731429648814\n",
            "Iteration 3000: Training Accuracy 0.5755166666666667, Test Accuracy 0.8487 and Training loss 0.11796820227910111\n",
            "Iteration 3100: Training Accuracy 0.58535, Test Accuracy 0.8432 and Training loss 0.11712830224071165\n",
            "Iteration 3200: Training Accuracy 0.5645166666666667, Test Accuracy 0.846 and Training loss 0.11623422919430255\n",
            "Iteration 3300: Training Accuracy 0.5750666666666666, Test Accuracy 0.8482 and Training loss 0.11549123509158672\n",
            "Iteration 3400: Training Accuracy 0.5670333333333333, Test Accuracy 0.8493 and Training loss 0.1148339130557726\n",
            "Iteration 3500: Training Accuracy 0.5874, Test Accuracy 0.8569 and Training loss 0.11513010591169492\n",
            "Iteration 3600: Training Accuracy 0.57035, Test Accuracy 0.8538 and Training loss 0.1137147840149276\n",
            "Iteration 3700: Training Accuracy 0.5702166666666667, Test Accuracy 0.857 and Training loss 0.11302856473315498\n",
            "Iteration 3800: Training Accuracy 0.5768333333333333, Test Accuracy 0.8598 and Training loss 0.1123691491940199\n",
            "Iteration 3900: Training Accuracy 0.5810666666666666, Test Accuracy 0.8616 and Training loss 0.11172815814007135\n",
            "Iteration 4000: Training Accuracy 0.5628, Test Accuracy 0.8556 and Training loss 0.11167667237038167\n",
            "Iteration 4100: Training Accuracy 0.5633833333333333, Test Accuracy 0.8581 and Training loss 0.11079733812720217\n",
            "Iteration 4200: Training Accuracy 0.5688833333333333, Test Accuracy 0.8607 and Training loss 0.11038032563737192\n",
            "Iteration 4300: Training Accuracy 0.5635166666666667, Test Accuracy 0.8614 and Training loss 0.11045520786515249\n",
            "Iteration 4400: Training Accuracy 0.5774166666666667, Test Accuracy 0.8629 and Training loss 0.10978812485468903\n",
            "Iteration 4500: Training Accuracy 0.5843833333333334, Test Accuracy 0.8659 and Training loss 0.10903547665302081\n",
            "Iteration 4600: Training Accuracy 0.5991333333333333, Test Accuracy 0.8649 and Training loss 0.10915394648091949\n",
            "Iteration 4700: Training Accuracy 0.5760666666666666, Test Accuracy 0.8681 and Training loss 0.10819512668304071\n",
            "Iteration 4800: Training Accuracy 0.5730166666666666, Test Accuracy 0.8632 and Training loss 0.10792812935918654\n",
            "Iteration 4900: Training Accuracy 0.5937833333333333, Test Accuracy 0.8712 and Training loss 0.1077333996368621\n",
            "Iteration 5000: Training Accuracy 0.5908666666666667, Test Accuracy 0.8725 and Training loss 0.1073558623398028\n",
            "Iteration 5100: Training Accuracy 0.6045166666666667, Test Accuracy 0.8719 and Training loss 0.10804497771183799\n",
            "Iteration 5200: Training Accuracy 0.58275, Test Accuracy 0.8699 and Training loss 0.106417818042613\n",
            "Iteration 5300: Training Accuracy 0.5851666666666666, Test Accuracy 0.8707 and Training loss 0.10624527566258388\n",
            "Iteration 5400: Training Accuracy 0.5826, Test Accuracy 0.874 and Training loss 0.10567296631263075\n",
            "Iteration 5500: Training Accuracy 0.5818, Test Accuracy 0.8723 and Training loss 0.10583272893672652\n",
            "Iteration 5600: Training Accuracy 0.59, Test Accuracy 0.8733 and Training loss 0.10535468505593235\n",
            "Iteration 5700: Training Accuracy 0.5965666666666667, Test Accuracy 0.8757 and Training loss 0.10541367371457756\n",
            "Iteration 5800: Training Accuracy 0.5711333333333334, Test Accuracy 0.872 and Training loss 0.10485421410662635\n",
            "Iteration 5900: Training Accuracy 0.5664, Test Accuracy 0.8693 and Training loss 0.1055183557862165\n",
            "Iteration 6000: Training Accuracy 0.58625, Test Accuracy 0.8763 and Training loss 0.10396868543502161\n",
            "Iteration 6100: Training Accuracy 0.5735333333333333, Test Accuracy 0.8738 and Training loss 0.1042441963574317\n",
            "Iteration 6200: Training Accuracy 0.5826333333333333, Test Accuracy 0.8766 and Training loss 0.10365546726416794\n",
            "Iteration 6300: Training Accuracy 0.58335, Test Accuracy 0.8774 and Training loss 0.1033135754512965\n",
            "Iteration 6400: Training Accuracy 0.58355, Test Accuracy 0.8768 and Training loss 0.10316472714306225\n",
            "Iteration 6500: Training Accuracy 0.5853166666666667, Test Accuracy 0.8763 and Training loss 0.10272068911119625\n",
            "Iteration 6600: Training Accuracy 0.5985666666666667, Test Accuracy 0.8806 and Training loss 0.10266706813720043\n",
            "Iteration 6700: Training Accuracy 0.6266166666666667, Test Accuracy 0.8796 and Training loss 0.10337555190566826\n",
            "Iteration 6800: Training Accuracy 0.5799333333333333, Test Accuracy 0.8769 and Training loss 0.10228142870359988\n",
            "Iteration 6900: Training Accuracy 0.59145, Test Accuracy 0.882 and Training loss 0.10176334483869892\n",
            "Iteration 7000: Training Accuracy 0.5806, Test Accuracy 0.88 and Training loss 0.10120268787376216\n",
            "Iteration 7100: Training Accuracy 0.5965333333333334, Test Accuracy 0.8795 and Training loss 0.10157251791174025\n",
            "Iteration 7200: Training Accuracy 0.56315, Test Accuracy 0.8781 and Training loss 0.10248391412875191\n",
            "Iteration 7300: Training Accuracy 0.5973166666666667, Test Accuracy 0.8821 and Training loss 0.1008264913218633\n",
            "Iteration 7400: Training Accuracy 0.5948, Test Accuracy 0.8822 and Training loss 0.10017687240126784\n",
            "Iteration 7500: Training Accuracy 0.5928833333333333, Test Accuracy 0.8809 and Training loss 0.10021610502691125\n",
            "Iteration 7600: Training Accuracy 0.6077333333333333, Test Accuracy 0.8774 and Training loss 0.1009757658032045\n",
            "Iteration 7700: Training Accuracy 0.5897166666666667, Test Accuracy 0.8815 and Training loss 0.09989847091012788\n",
            "Iteration 7800: Training Accuracy 0.58085, Test Accuracy 0.8795 and Training loss 0.09988857112567379\n",
            "Iteration 7900: Training Accuracy 0.5849666666666666, Test Accuracy 0.883 and Training loss 0.09941633672892136\n",
            "Iteration 8000: Training Accuracy 0.58525, Test Accuracy 0.8841 and Training loss 0.09928911770299824\n",
            "Iteration 8100: Training Accuracy 0.6135166666666667, Test Accuracy 0.8854 and Training loss 0.0998882362659168\n",
            "Iteration 8200: Training Accuracy 0.5979, Test Accuracy 0.8843 and Training loss 0.09882018417510802\n",
            "Iteration 8300: Training Accuracy 0.5992, Test Accuracy 0.8842 and Training loss 0.09865251377387871\n",
            "Iteration 8400: Training Accuracy 0.5953833333333334, Test Accuracy 0.8835 and Training loss 0.09853581088246016\n",
            "Iteration 8500: Training Accuracy 0.5981, Test Accuracy 0.8833 and Training loss 0.09866038597640645\n",
            "Iteration 8600: Training Accuracy 0.6140333333333333, Test Accuracy 0.8857 and Training loss 0.0987208396321511\n",
            "Iteration 8700: Training Accuracy 0.6117666666666667, Test Accuracy 0.8837 and Training loss 0.09901078374792349\n",
            "Iteration 8800: Training Accuracy 0.5819833333333333, Test Accuracy 0.886 and Training loss 0.0978421366316979\n",
            "Iteration 8900: Training Accuracy 0.6023, Test Accuracy 0.8846 and Training loss 0.09783365254332475\n",
            "Iteration 9000: Training Accuracy 0.5831333333333333, Test Accuracy 0.8829 and Training loss 0.09777607815544628\n",
            "Iteration 9100: Training Accuracy 0.5878, Test Accuracy 0.8854 and Training loss 0.09757569341930718\n",
            "Iteration 9200: Training Accuracy 0.5857166666666667, Test Accuracy 0.8867 and Training loss 0.09722725103154226\n",
            "Iteration 9300: Training Accuracy 0.6065666666666667, Test Accuracy 0.8872 and Training loss 0.09720883348333256\n",
            "Iteration 9400: Training Accuracy 0.6056333333333334, Test Accuracy 0.8859 and Training loss 0.09716679246832685\n",
            "Iteration 9500: Training Accuracy 0.5822, Test Accuracy 0.8876 and Training loss 0.09735155321385784\n",
            "Iteration 9600: Training Accuracy 0.6001166666666666, Test Accuracy 0.8894 and Training loss 0.09649847283241612\n",
            "Iteration 9700: Training Accuracy 0.5905166666666667, Test Accuracy 0.8885 and Training loss 0.09646925048804263\n",
            "Iteration 9800: Training Accuracy 0.5950833333333333, Test Accuracy 0.8893 and Training loss 0.09633184248964083\n",
            "Iteration 9900: Training Accuracy 0.59405, Test Accuracy 0.8905 and Training loss 0.09630609985129783\n",
            "Iteration 10000: Training Accuracy 0.61155, Test Accuracy 0.8908 and Training loss 0.09691264223926348\n",
            "Iteration 10100: Training Accuracy 0.6070333333333333, Test Accuracy 0.8894 and Training loss 0.09603605514246114\n",
            "Iteration 10200: Training Accuracy 0.6143166666666666, Test Accuracy 0.8896 and Training loss 0.09661261104061089\n",
            "Iteration 10300: Training Accuracy 0.5845, Test Accuracy 0.8859 and Training loss 0.09708779674881543\n",
            "Iteration 10400: Training Accuracy 0.5973333333333334, Test Accuracy 0.8873 and Training loss 0.09578980975850579\n",
            "Iteration 10500: Training Accuracy 0.5886666666666667, Test Accuracy 0.8863 and Training loss 0.09586346147806055\n",
            "Iteration 10600: Training Accuracy 0.5994833333333334, Test Accuracy 0.8869 and Training loss 0.09547755115565572\n",
            "Iteration 10700: Training Accuracy 0.6152666666666666, Test Accuracy 0.8876 and Training loss 0.09626411962998142\n",
            "Iteration 10800: Training Accuracy 0.5907166666666667, Test Accuracy 0.8888 and Training loss 0.09560059015513678\n",
            "Iteration 10900: Training Accuracy 0.61015, Test Accuracy 0.891 and Training loss 0.09506063039865636\n",
            "Iteration 11000: Training Accuracy 0.5842333333333334, Test Accuracy 0.8876 and Training loss 0.09561202639803168\n",
            "Iteration 11100: Training Accuracy 0.5808833333333333, Test Accuracy 0.8872 and Training loss 0.09582149970593365\n",
            "Iteration 11200: Training Accuracy 0.5839333333333333, Test Accuracy 0.8848 and Training loss 0.09584354277969506\n",
            "Iteration 11300: Training Accuracy 0.5860666666666666, Test Accuracy 0.8872 and Training loss 0.09559142846667423\n",
            "Iteration 11400: Training Accuracy 0.6057333333333333, Test Accuracy 0.8891 and Training loss 0.0947633283752628\n",
            "Iteration 11500: Training Accuracy 0.5933166666666667, Test Accuracy 0.89 and Training loss 0.0949988580964206\n",
            "Iteration 11600: Training Accuracy 0.6140666666666666, Test Accuracy 0.8881 and Training loss 0.09478489798544454\n",
            "Iteration 11700: Training Accuracy 0.59405, Test Accuracy 0.8887 and Training loss 0.09436541674111326\n",
            "Iteration 11800: Training Accuracy 0.62205, Test Accuracy 0.8826 and Training loss 0.09464642532998277\n",
            "Iteration 11900: Training Accuracy 0.6199666666666667, Test Accuracy 0.8838 and Training loss 0.09494002577672468\n",
            "Iteration 12000: Training Accuracy 0.5957166666666667, Test Accuracy 0.8895 and Training loss 0.09451586002064287\n",
            "Iteration 12100: Training Accuracy 0.6279, Test Accuracy 0.8884 and Training loss 0.09477329610980284\n",
            "Iteration 12200: Training Accuracy 0.5869333333333333, Test Accuracy 0.8894 and Training loss 0.09462944835231853\n",
            "Iteration 12300: Training Accuracy 0.5916333333333333, Test Accuracy 0.8902 and Training loss 0.09419397066061706\n",
            "Iteration 12400: Training Accuracy 0.59945, Test Accuracy 0.8852 and Training loss 0.09403297599009355\n",
            "Iteration 12500: Training Accuracy 0.5945333333333334, Test Accuracy 0.8915 and Training loss 0.09402915880480954\n",
            "Iteration 12600: Training Accuracy 0.5842333333333334, Test Accuracy 0.8905 and Training loss 0.09437726931555794\n",
            "Iteration 12700: Training Accuracy 0.622, Test Accuracy 0.8885 and Training loss 0.09386100874155673\n",
            "Iteration 12800: Training Accuracy 0.6149666666666667, Test Accuracy 0.8862 and Training loss 0.09354819024076391\n",
            "Iteration 12900: Training Accuracy 0.6069666666666667, Test Accuracy 0.8897 and Training loss 0.0933411402337805\n",
            "Iteration 13000: Training Accuracy 0.5982333333333333, Test Accuracy 0.8869 and Training loss 0.09343085154722242\n",
            "Iteration 13100: Training Accuracy 0.6095, Test Accuracy 0.89 and Training loss 0.0931899078917771\n",
            "Iteration 13200: Training Accuracy 0.5921, Test Accuracy 0.8882 and Training loss 0.09322485343294373\n",
            "Iteration 13300: Training Accuracy 0.5836833333333333, Test Accuracy 0.8891 and Training loss 0.0942627900400682\n",
            "Iteration 13400: Training Accuracy 0.6008166666666667, Test Accuracy 0.8928 and Training loss 0.0928823513703929\n",
            "Iteration 13500: Training Accuracy 0.6023666666666667, Test Accuracy 0.8897 and Training loss 0.09299062886688232\n",
            "Iteration 13600: Training Accuracy 0.5961166666666666, Test Accuracy 0.8892 and Training loss 0.09288025748355681\n",
            "Iteration 13700: Training Accuracy 0.5998666666666667, Test Accuracy 0.8909 and Training loss 0.09290633562411271\n",
            "Iteration 13800: Training Accuracy 0.6071666666666666, Test Accuracy 0.8883 and Training loss 0.09286345586293601\n",
            "Iteration 13900: Training Accuracy 0.6068333333333333, Test Accuracy 0.8921 and Training loss 0.0924945845508886\n",
            "Iteration 14000: Training Accuracy 0.6102166666666666, Test Accuracy 0.8909 and Training loss 0.09239753973824814\n",
            "Iteration 14100: Training Accuracy 0.61095, Test Accuracy 0.8912 and Training loss 0.09259692139963355\n",
            "Iteration 14200: Training Accuracy 0.6022666666666666, Test Accuracy 0.8904 and Training loss 0.09240257484724936\n",
            "Iteration 14300: Training Accuracy 0.6145166666666667, Test Accuracy 0.888 and Training loss 0.09269061806693499\n",
            "Iteration 14400: Training Accuracy 0.6126333333333334, Test Accuracy 0.8891 and Training loss 0.09235814849462094\n",
            "Iteration 14500: Training Accuracy 0.5944, Test Accuracy 0.8894 and Training loss 0.09196064371394032\n",
            "Iteration 14600: Training Accuracy 0.5914666666666667, Test Accuracy 0.8888 and Training loss 0.09223597490197243\n",
            "Iteration 14700: Training Accuracy 0.5989833333333333, Test Accuracy 0.8869 and Training loss 0.09204200103043024\n",
            "Iteration 14800: Training Accuracy 0.6162166666666666, Test Accuracy 0.8875 and Training loss 0.09202227919778767\n",
            "Iteration 14900: Training Accuracy 0.59895, Test Accuracy 0.8901 and Training loss 0.09212620007286718\n",
            "Iteration 15000: Training Accuracy 0.59835, Test Accuracy 0.8914 and Training loss 0.09177720598628933\n",
            "Iteration 15100: Training Accuracy 0.6003833333333334, Test Accuracy 0.8921 and Training loss 0.09173413220581782\n",
            "Iteration 15200: Training Accuracy 0.6207333333333334, Test Accuracy 0.8917 and Training loss 0.09137034200029835\n",
            "Iteration 15300: Training Accuracy 0.6086833333333334, Test Accuracy 0.8913 and Training loss 0.09116470085615597\n",
            "Iteration 15400: Training Accuracy 0.5881166666666666, Test Accuracy 0.8884 and Training loss 0.09184071728462188\n",
            "Iteration 15500: Training Accuracy 0.6109333333333333, Test Accuracy 0.8923 and Training loss 0.09118342238851677\n",
            "Iteration 15600: Training Accuracy 0.6086666666666667, Test Accuracy 0.889 and Training loss 0.09115114146557064\n",
            "Iteration 15700: Training Accuracy 0.6178833333333333, Test Accuracy 0.8911 and Training loss 0.09097591849459019\n",
            "Iteration 15800: Training Accuracy 0.6035333333333334, Test Accuracy 0.8891 and Training loss 0.09102451921978293\n",
            "Iteration 15900: Training Accuracy 0.6027333333333333, Test Accuracy 0.8896 and Training loss 0.09085919306644989\n",
            "Iteration 16000: Training Accuracy 0.6038666666666667, Test Accuracy 0.8881 and Training loss 0.09109009502039636\n",
            "Iteration 16100: Training Accuracy 0.61125, Test Accuracy 0.8923 and Training loss 0.09081907219516479\n",
            "Iteration 16200: Training Accuracy 0.6178666666666667, Test Accuracy 0.8901 and Training loss 0.09063522569647364\n",
            "Iteration 16300: Training Accuracy 0.6089, Test Accuracy 0.8904 and Training loss 0.09064553407341186\n",
            "Iteration 16400: Training Accuracy 0.5977, Test Accuracy 0.8923 and Training loss 0.09044044185882065\n",
            "Iteration 16500: Training Accuracy 0.5889666666666666, Test Accuracy 0.8903 and Training loss 0.09082558814347806\n",
            "Iteration 16600: Training Accuracy 0.5965166666666667, Test Accuracy 0.8876 and Training loss 0.0903015650759979\n",
            "Iteration 16700: Training Accuracy 0.60375, Test Accuracy 0.8912 and Training loss 0.08978387142169751\n",
            "Iteration 16800: Training Accuracy 0.6109166666666667, Test Accuracy 0.8918 and Training loss 0.08974767555191102\n",
            "Iteration 16900: Training Accuracy 0.6339333333333333, Test Accuracy 0.8924 and Training loss 0.09058247931474275\n",
            "Iteration 17000: Training Accuracy 0.6081, Test Accuracy 0.8891 and Training loss 0.08954458296055344\n",
            "Iteration 17100: Training Accuracy 0.6249, Test Accuracy 0.8944 and Training loss 0.08989385109666982\n",
            "Iteration 17200: Training Accuracy 0.6083166666666666, Test Accuracy 0.8893 and Training loss 0.08953400232892057\n",
            "Iteration 17300: Training Accuracy 0.6172, Test Accuracy 0.8929 and Training loss 0.08968403097571663\n",
            "Iteration 17400: Training Accuracy 0.58175, Test Accuracy 0.8912 and Training loss 0.09061427716468858\n",
            "Iteration 17500: Training Accuracy 0.6106333333333334, Test Accuracy 0.8912 and Training loss 0.08960939149126934\n",
            "Iteration 17600: Training Accuracy 0.5828833333333333, Test Accuracy 0.8931 and Training loss 0.08975173186168571\n",
            "Iteration 17700: Training Accuracy 0.6170833333333333, Test Accuracy 0.8924 and Training loss 0.0892731276210056\n",
            "Iteration 17800: Training Accuracy 0.60315, Test Accuracy 0.8905 and Training loss 0.0889259446907982\n",
            "Iteration 17900: Training Accuracy 0.5851833333333334, Test Accuracy 0.8899 and Training loss 0.08922144677095178\n",
            "Iteration 18000: Training Accuracy 0.6, Test Accuracy 0.8945 and Training loss 0.08874049029844479\n",
            "Iteration 18100: Training Accuracy 0.5984666666666667, Test Accuracy 0.8894 and Training loss 0.08941451381110459\n",
            "Iteration 18200: Training Accuracy 0.59665, Test Accuracy 0.8931 and Training loss 0.08857233833007773\n",
            "Iteration 18300: Training Accuracy 0.6109833333333333, Test Accuracy 0.8926 and Training loss 0.08837918789497709\n",
            "Iteration 18400: Training Accuracy 0.61385, Test Accuracy 0.8918 and Training loss 0.08832991305882469\n",
            "Iteration 18500: Training Accuracy 0.6201, Test Accuracy 0.8958 and Training loss 0.0885957023663931\n",
            "Iteration 18600: Training Accuracy 0.6215166666666667, Test Accuracy 0.8964 and Training loss 0.08846761976781609\n",
            "Iteration 18700: Training Accuracy 0.6172, Test Accuracy 0.8955 and Training loss 0.0880244872807958\n",
            "Iteration 18800: Training Accuracy 0.6184666666666667, Test Accuracy 0.8953 and Training loss 0.0881342486962854\n",
            "Iteration 18900: Training Accuracy 0.6149833333333333, Test Accuracy 0.8942 and Training loss 0.08795285609982416\n",
            "Iteration 19000: Training Accuracy 0.6061, Test Accuracy 0.8945 and Training loss 0.08781344830001206\n",
            "Iteration 19100: Training Accuracy 0.6100666666666666, Test Accuracy 0.8914 and Training loss 0.0880775273918062\n",
            "Iteration 19200: Training Accuracy 0.5845833333333333, Test Accuracy 0.8865 and Training loss 0.08953390479515097\n",
            "Iteration 19300: Training Accuracy 0.62225, Test Accuracy 0.8955 and Training loss 0.08789891946372706\n",
            "Iteration 19400: Training Accuracy 0.5982333333333333, Test Accuracy 0.8897 and Training loss 0.08750681725429156\n",
            "Iteration 19500: Training Accuracy 0.5984833333333334, Test Accuracy 0.8915 and Training loss 0.08749236293616346\n",
            "Iteration 19600: Training Accuracy 0.6070166666666666, Test Accuracy 0.8894 and Training loss 0.0874507996302721\n",
            "Iteration 19700: Training Accuracy 0.6118, Test Accuracy 0.8929 and Training loss 0.08701748977908924\n",
            "Iteration 19800: Training Accuracy 0.5915166666666667, Test Accuracy 0.8923 and Training loss 0.08708008549851001\n",
            "Iteration 19900: Training Accuracy 0.6015833333333334, Test Accuracy 0.8958 and Training loss 0.08705583891540916\n",
            "Iteration 20000: Training Accuracy 0.60625, Test Accuracy 0.8971 and Training loss 0.08700612457130959\n",
            "Iteration 20100: Training Accuracy 0.6208333333333333, Test Accuracy 0.8958 and Training loss 0.08753089562927632\n",
            "Iteration 20200: Training Accuracy 0.5897666666666667, Test Accuracy 0.8944 and Training loss 0.0865778945539497\n",
            "Iteration 20300: Training Accuracy 0.5944333333333334, Test Accuracy 0.8934 and Training loss 0.08645158460979688\n",
            "Iteration 20400: Training Accuracy 0.61185, Test Accuracy 0.8943 and Training loss 0.08669042617915272\n",
            "Iteration 20500: Training Accuracy 0.5949333333333333, Test Accuracy 0.8845 and Training loss 0.08711525494136325\n",
            "Iteration 20600: Training Accuracy 0.6181, Test Accuracy 0.894 and Training loss 0.08659758886250765\n",
            "Iteration 20700: Training Accuracy 0.6126666666666667, Test Accuracy 0.8937 and Training loss 0.08605141283876055\n",
            "Iteration 20800: Training Accuracy 0.6246, Test Accuracy 0.8959 and Training loss 0.08634272994814604\n",
            "Iteration 20900: Training Accuracy 0.6179833333333333, Test Accuracy 0.8957 and Training loss 0.08636358839230103\n",
            "Iteration 21000: Training Accuracy 0.6175833333333334, Test Accuracy 0.9002 and Training loss 0.08592717086530192\n",
            "Iteration 21100: Training Accuracy 0.6131333333333333, Test Accuracy 0.8998 and Training loss 0.08564619346301598\n",
            "Iteration 21200: Training Accuracy 0.6239333333333333, Test Accuracy 0.896 and Training loss 0.08644107253810356\n",
            "Iteration 21300: Training Accuracy 0.60835, Test Accuracy 0.9012 and Training loss 0.08543995490263435\n",
            "Iteration 21400: Training Accuracy 0.6182, Test Accuracy 0.8947 and Training loss 0.0856195305230763\n",
            "Iteration 21500: Training Accuracy 0.5963333333333334, Test Accuracy 0.8943 and Training loss 0.08537154043351455\n",
            "Iteration 21600: Training Accuracy 0.6133, Test Accuracy 0.8941 and Training loss 0.08512086258213859\n",
            "Iteration 21700: Training Accuracy 0.6436333333333333, Test Accuracy 0.899 and Training loss 0.08667670895312295\n",
            "Iteration 21800: Training Accuracy 0.5845166666666667, Test Accuracy 0.8907 and Training loss 0.08572979783973064\n",
            "Iteration 21900: Training Accuracy 0.5882666666666667, Test Accuracy 0.8934 and Training loss 0.08563817970385765\n",
            "Iteration 22000: Training Accuracy 0.6082833333333333, Test Accuracy 0.8967 and Training loss 0.08482325239170856\n",
            "Iteration 22100: Training Accuracy 0.6114, Test Accuracy 0.8998 and Training loss 0.08492137896328854\n",
            "Iteration 22200: Training Accuracy 0.5958833333333333, Test Accuracy 0.8924 and Training loss 0.08478341697088815\n",
            "Iteration 22300: Training Accuracy 0.6105166666666667, Test Accuracy 0.8985 and Training loss 0.08464344036692108\n",
            "Iteration 22400: Training Accuracy 0.59915, Test Accuracy 0.8929 and Training loss 0.08531848439390395\n",
            "Iteration 22500: Training Accuracy 0.6361666666666667, Test Accuracy 0.8992 and Training loss 0.08514392098642216\n",
            "Iteration 22600: Training Accuracy 0.5925666666666667, Test Accuracy 0.8871 and Training loss 0.08570805706303368\n",
            "Iteration 22700: Training Accuracy 0.6310333333333333, Test Accuracy 0.8952 and Training loss 0.08453417263334816\n",
            "Iteration 22800: Training Accuracy 0.6003333333333334, Test Accuracy 0.895 and Training loss 0.08432279697557196\n",
            "Iteration 22900: Training Accuracy 0.59915, Test Accuracy 0.8949 and Training loss 0.08414448829745706\n",
            "Iteration 23000: Training Accuracy 0.6379, Test Accuracy 0.899 and Training loss 0.0845808220059187\n",
            "Iteration 23100: Training Accuracy 0.64395, Test Accuracy 0.9044 and Training loss 0.08571729602833159\n",
            "Iteration 23200: Training Accuracy 0.5997, Test Accuracy 0.8976 and Training loss 0.08377596610751539\n",
            "Iteration 23300: Training Accuracy 0.6342833333333333, Test Accuracy 0.9009 and Training loss 0.08478526244187837\n",
            "Iteration 23400: Training Accuracy 0.5999833333333333, Test Accuracy 0.8972 and Training loss 0.08345921976712566\n",
            "Iteration 23500: Training Accuracy 0.5998666666666667, Test Accuracy 0.8966 and Training loss 0.08333959631822511\n",
            "Iteration 23600: Training Accuracy 0.5886666666666667, Test Accuracy 0.8925 and Training loss 0.08402099322544794\n",
            "Iteration 23700: Training Accuracy 0.62465, Test Accuracy 0.9011 and Training loss 0.08366832232043338\n",
            "Iteration 23800: Training Accuracy 0.6109833333333333, Test Accuracy 0.8982 and Training loss 0.08305105545222846\n",
            "Iteration 23900: Training Accuracy 0.5871833333333333, Test Accuracy 0.8876 and Training loss 0.08348132244638902\n",
            "Iteration 24000: Training Accuracy 0.6205833333333334, Test Accuracy 0.8971 and Training loss 0.08329539233932134\n",
            "Iteration 24100: Training Accuracy 0.6223833333333333, Test Accuracy 0.8952 and Training loss 0.08311835021102273\n",
            "Iteration 24200: Training Accuracy 0.60305, Test Accuracy 0.8921 and Training loss 0.08282169457713234\n",
            "Iteration 24300: Training Accuracy 0.6168166666666667, Test Accuracy 0.8973 and Training loss 0.08297747100999968\n",
            "Iteration 24400: Training Accuracy 0.5994166666666667, Test Accuracy 0.8884 and Training loss 0.08291339212017089\n",
            "Iteration 24500: Training Accuracy 0.6017666666666667, Test Accuracy 0.8904 and Training loss 0.08285862075671167\n",
            "Iteration 24600: Training Accuracy 0.595, Test Accuracy 0.8889 and Training loss 0.08305476214984985\n",
            "Iteration 24700: Training Accuracy 0.5934333333333334, Test Accuracy 0.8972 and Training loss 0.08276296011081678\n",
            "Iteration 24800: Training Accuracy 0.6076666666666667, Test Accuracy 0.9006 and Training loss 0.08202786627174541\n",
            "Iteration 24900: Training Accuracy 0.6400166666666667, Test Accuracy 0.9046 and Training loss 0.0832085341041025\n",
            "Iteration 25000: Training Accuracy 0.5790333333333333, Test Accuracy 0.8883 and Training loss 0.08287952634063604\n",
            "Iteration 25100: Training Accuracy 0.6129666666666667, Test Accuracy 0.8963 and Training loss 0.0818600150758393\n",
            "Iteration 25200: Training Accuracy 0.6313166666666666, Test Accuracy 0.8973 and Training loss 0.08276452761434372\n",
            "Iteration 25300: Training Accuracy 0.5929333333333333, Test Accuracy 0.8936 and Training loss 0.08187459371529256\n",
            "Iteration 25400: Training Accuracy 0.58945, Test Accuracy 0.8923 and Training loss 0.08184642589842539\n",
            "Iteration 25500: Training Accuracy 0.6194666666666667, Test Accuracy 0.8982 and Training loss 0.08176603568321136\n",
            "Iteration 25600: Training Accuracy 0.6079, Test Accuracy 0.8866 and Training loss 0.08151201690147306\n",
            "Iteration 25700: Training Accuracy 0.6121166666666666, Test Accuracy 0.8948 and Training loss 0.08140965665721896\n",
            "Iteration 25800: Training Accuracy 0.5895333333333334, Test Accuracy 0.8871 and Training loss 0.08178950774381198\n",
            "Iteration 25900: Training Accuracy 0.61065, Test Accuracy 0.8973 and Training loss 0.08129025473369314\n",
            "Iteration 26000: Training Accuracy 0.5984, Test Accuracy 0.8925 and Training loss 0.08109069460645185\n",
            "Iteration 26100: Training Accuracy 0.5851, Test Accuracy 0.8886 and Training loss 0.08152735440113341\n",
            "Iteration 26200: Training Accuracy 0.5929333333333333, Test Accuracy 0.8911 and Training loss 0.08139415649940858\n",
            "Iteration 26300: Training Accuracy 0.582, Test Accuracy 0.8921 and Training loss 0.0821970848505138\n",
            "Iteration 26400: Training Accuracy 0.6292333333333333, Test Accuracy 0.9051 and Training loss 0.0813427016355415\n",
            "Iteration 26500: Training Accuracy 0.5958833333333333, Test Accuracy 0.8978 and Training loss 0.08088408065616104\n",
            "Iteration 26600: Training Accuracy 0.62315, Test Accuracy 0.8979 and Training loss 0.08077620866459737\n",
            "Iteration 26700: Training Accuracy 0.6070833333333333, Test Accuracy 0.8922 and Training loss 0.08065183879114983\n",
            "Iteration 26800: Training Accuracy 0.5862, Test Accuracy 0.886 and Training loss 0.08116910410253662\n",
            "Iteration 26900: Training Accuracy 0.60085, Test Accuracy 0.8972 and Training loss 0.08087114906590573\n",
            "Iteration 27000: Training Accuracy 0.6088833333333333, Test Accuracy 0.8879 and Training loss 0.08064153720674999\n",
            "Iteration 27100: Training Accuracy 0.6098833333333333, Test Accuracy 0.892 and Training loss 0.08031852691786703\n",
            "Iteration 27200: Training Accuracy 0.60805, Test Accuracy 0.895 and Training loss 0.08011491535517659\n",
            "Iteration 27300: Training Accuracy 0.6142833333333333, Test Accuracy 0.897 and Training loss 0.08009178662048098\n",
            "Iteration 27400: Training Accuracy 0.58785, Test Accuracy 0.8846 and Training loss 0.08043942756217354\n",
            "Iteration 27500: Training Accuracy 0.5949833333333333, Test Accuracy 0.8876 and Training loss 0.0801895117126595\n",
            "Iteration 27600: Training Accuracy 0.62885, Test Accuracy 0.8975 and Training loss 0.08038868597713414\n",
            "Iteration 27700: Training Accuracy 0.60945, Test Accuracy 0.8971 and Training loss 0.0801015199588616\n",
            "Iteration 27800: Training Accuracy 0.6204666666666667, Test Accuracy 0.9012 and Training loss 0.08035432557755219\n",
            "Iteration 27900: Training Accuracy 0.60505, Test Accuracy 0.8905 and Training loss 0.07972236023106415\n",
            "Iteration 28000: Training Accuracy 0.6036833333333333, Test Accuracy 0.8931 and Training loss 0.07954594547739645\n",
            "Iteration 28100: Training Accuracy 0.6322833333333333, Test Accuracy 0.902 and Training loss 0.08001282821339137\n",
            "Iteration 28200: Training Accuracy 0.6163333333333333, Test Accuracy 0.8937 and Training loss 0.07939659466126682\n",
            "Iteration 28300: Training Accuracy 0.6217, Test Accuracy 0.8967 and Training loss 0.07922990799209216\n",
            "Iteration 28400: Training Accuracy 0.6618333333333334, Test Accuracy 0.9034 and Training loss 0.08171331913957651\n",
            "Iteration 28500: Training Accuracy 0.6055666666666667, Test Accuracy 0.885 and Training loss 0.0794091359040715\n",
            "Iteration 28600: Training Accuracy 0.6041333333333333, Test Accuracy 0.8889 and Training loss 0.07909445282674837\n",
            "Iteration 28700: Training Accuracy 0.6047166666666667, Test Accuracy 0.8914 and Training loss 0.07915314811388958\n",
            "Iteration 28800: Training Accuracy 0.6506833333333333, Test Accuracy 0.9022 and Training loss 0.08036225865753528\n",
            "Iteration 28900: Training Accuracy 0.62465, Test Accuracy 0.8975 and Training loss 0.0791565238045815\n",
            "Iteration 29000: Training Accuracy 0.5912833333333334, Test Accuracy 0.8872 and Training loss 0.07922497938292146\n",
            "Iteration 29100: Training Accuracy 0.6060666666666666, Test Accuracy 0.8915 and Training loss 0.07846581682194863\n",
            "Iteration 29200: Training Accuracy 0.5974666666666667, Test Accuracy 0.8816 and Training loss 0.07945114554741674\n",
            "Iteration 29300: Training Accuracy 0.6158333333333333, Test Accuracy 0.8912 and Training loss 0.07842106020104647\n",
            "Iteration 29400: Training Accuracy 0.6100333333333333, Test Accuracy 0.891 and Training loss 0.07847391848758459\n",
            "Iteration 29500: Training Accuracy 0.6230833333333333, Test Accuracy 0.894 and Training loss 0.0784861671987823\n",
            "Iteration 29600: Training Accuracy 0.59105, Test Accuracy 0.8804 and Training loss 0.08010512558015326\n",
            "Iteration 29700: Training Accuracy 0.6115166666666667, Test Accuracy 0.8875 and Training loss 0.0787871209403466\n",
            "Iteration 29800: Training Accuracy 0.6258166666666667, Test Accuracy 0.8838 and Training loss 0.07821396769251569\n",
            "Iteration 29900: Training Accuracy 0.6303666666666666, Test Accuracy 0.8877 and Training loss 0.07825373176529359\n",
            "Iteration 30000: Training Accuracy 0.6381833333333333, Test Accuracy 0.891 and Training loss 0.07839134914119131\n",
            "Iteration 30100: Training Accuracy 0.6177833333333334, Test Accuracy 0.8901 and Training loss 0.0778852041811392\n",
            "Iteration 30200: Training Accuracy 0.5986166666666667, Test Accuracy 0.8864 and Training loss 0.07782983386891726\n",
            "Iteration 30300: Training Accuracy 0.6291166666666667, Test Accuracy 0.8971 and Training loss 0.0787083922885569\n",
            "Iteration 30400: Training Accuracy 0.6172833333333333, Test Accuracy 0.8889 and Training loss 0.0778026201668834\n",
            "Iteration 30500: Training Accuracy 0.6159, Test Accuracy 0.8852 and Training loss 0.07763745256713085\n",
            "Iteration 30600: Training Accuracy 0.6153166666666666, Test Accuracy 0.8889 and Training loss 0.07768304275646055\n",
            "Iteration 30700: Training Accuracy 0.6134333333333334, Test Accuracy 0.8888 and Training loss 0.07741680956764777\n",
            "Iteration 30800: Training Accuracy 0.6195, Test Accuracy 0.8915 and Training loss 0.07772094875091534\n",
            "Iteration 30900: Training Accuracy 0.60265, Test Accuracy 0.8844 and Training loss 0.07722450995020054\n",
            "Iteration 31000: Training Accuracy 0.6172666666666666, Test Accuracy 0.8913 and Training loss 0.07738297055142335\n",
            "Iteration 31100: Training Accuracy 0.5994666666666667, Test Accuracy 0.8872 and Training loss 0.07720926693668248\n",
            "Iteration 31200: Training Accuracy 0.5890833333333333, Test Accuracy 0.8846 and Training loss 0.07752965175722079\n",
            "Iteration 31300: Training Accuracy 0.6031333333333333, Test Accuracy 0.8823 and Training loss 0.07708698397951827\n",
            "Iteration 31400: Training Accuracy 0.6258333333333334, Test Accuracy 0.8902 and Training loss 0.07817859228239617\n",
            "Iteration 31500: Training Accuracy 0.5944333333333334, Test Accuracy 0.8713 and Training loss 0.07704727801482554\n",
            "Iteration 31600: Training Accuracy 0.59855, Test Accuracy 0.878 and Training loss 0.07661249218858987\n",
            "Iteration 31700: Training Accuracy 0.5823666666666667, Test Accuracy 0.8756 and Training loss 0.0775109163088012\n",
            "Iteration 31800: Training Accuracy 0.6027, Test Accuracy 0.8839 and Training loss 0.07662753834047532\n",
            "Iteration 31900: Training Accuracy 0.60425, Test Accuracy 0.8799 and Training loss 0.07660284976052224\n",
            "Iteration 32000: Training Accuracy 0.59445, Test Accuracy 0.8632 and Training loss 0.07680345479675894\n",
            "Iteration 32100: Training Accuracy 0.6182333333333333, Test Accuracy 0.8793 and Training loss 0.07685983295764608\n",
            "Iteration 32200: Training Accuracy 0.6143833333333333, Test Accuracy 0.8845 and Training loss 0.07699571544958965\n",
            "Iteration 32300: Training Accuracy 0.5911833333333333, Test Accuracy 0.8736 and Training loss 0.07635941206829985\n",
            "Iteration 32400: Training Accuracy 0.5843166666666667, Test Accuracy 0.8604 and Training loss 0.07728048381412725\n",
            "Iteration 32500: Training Accuracy 0.5905833333333333, Test Accuracy 0.8665 and Training loss 0.07632461180938892\n",
            "Iteration 32600: Training Accuracy 0.5879, Test Accuracy 0.8749 and Training loss 0.07616735569513347\n",
            "Iteration 32700: Training Accuracy 0.59475, Test Accuracy 0.8752 and Training loss 0.07657636925270891\n",
            "Iteration 32800: Training Accuracy 0.6318333333333334, Test Accuracy 0.8892 and Training loss 0.07660679003426128\n",
            "Iteration 32900: Training Accuracy 0.6178666666666667, Test Accuracy 0.8925 and Training loss 0.07618142180725192\n",
            "Iteration 33000: Training Accuracy 0.6107333333333334, Test Accuracy 0.8842 and Training loss 0.07570121598575931\n",
            "Iteration 33100: Training Accuracy 0.6193833333333333, Test Accuracy 0.8837 and Training loss 0.07588957429692812\n",
            "Iteration 33200: Training Accuracy 0.5986833333333333, Test Accuracy 0.8713 and Training loss 0.0759546011263162\n",
            "Iteration 33300: Training Accuracy 0.6130166666666667, Test Accuracy 0.8834 and Training loss 0.07592173043193547\n",
            "Iteration 33400: Training Accuracy 0.61285, Test Accuracy 0.8735 and Training loss 0.07608330297802739\n",
            "Iteration 33500: Training Accuracy 0.5954833333333334, Test Accuracy 0.8697 and Training loss 0.07600105442701224\n",
            "Iteration 33600: Training Accuracy 0.63225, Test Accuracy 0.8756 and Training loss 0.0760455770244259\n",
            "Iteration 33700: Training Accuracy 0.6119666666666667, Test Accuracy 0.8826 and Training loss 0.07556966154579997\n",
            "Iteration 33800: Training Accuracy 0.60475, Test Accuracy 0.8791 and Training loss 0.075912524117887\n",
            "Iteration 33900: Training Accuracy 0.61775, Test Accuracy 0.8813 and Training loss 0.07552190132053296\n",
            "Iteration 34000: Training Accuracy 0.6086, Test Accuracy 0.8763 and Training loss 0.07550141699723537\n",
            "Iteration 34100: Training Accuracy 0.6116833333333334, Test Accuracy 0.8838 and Training loss 0.07523722792755\n",
            "Iteration 34200: Training Accuracy 0.6460166666666667, Test Accuracy 0.8994 and Training loss 0.07685480919371031\n",
            "Iteration 34300: Training Accuracy 0.6245, Test Accuracy 0.8937 and Training loss 0.07553812902611877\n",
            "Iteration 34400: Training Accuracy 0.6368833333333334, Test Accuracy 0.8959 and Training loss 0.0761760013168688\n",
            "Iteration 34500: Training Accuracy 0.6283833333333333, Test Accuracy 0.8938 and Training loss 0.07532281224921045\n",
            "Iteration 34600: Training Accuracy 0.62105, Test Accuracy 0.8905 and Training loss 0.07534583109401313\n",
            "Iteration 34700: Training Accuracy 0.6073166666666666, Test Accuracy 0.8793 and Training loss 0.07489060502958163\n",
            "Iteration 34800: Training Accuracy 0.6026833333333333, Test Accuracy 0.8762 and Training loss 0.07541959271895733\n",
            "Iteration 34900: Training Accuracy 0.6374, Test Accuracy 0.8848 and Training loss 0.07521710428729962\n",
            "Iteration 35000: Training Accuracy 0.5945833333333334, Test Accuracy 0.8703 and Training loss 0.07509654303948352\n",
            "Iteration 35100: Training Accuracy 0.6001666666666666, Test Accuracy 0.8721 and Training loss 0.07520128470336906\n",
            "Iteration 35200: Training Accuracy 0.62355, Test Accuracy 0.874 and Training loss 0.07465713696696158\n",
            "Iteration 35300: Training Accuracy 0.6395833333333333, Test Accuracy 0.8845 and Training loss 0.07569356496123579\n",
            "Iteration 35400: Training Accuracy 0.6122666666666666, Test Accuracy 0.8777 and Training loss 0.07494181310939704\n",
            "Iteration 35500: Training Accuracy 0.5917833333333333, Test Accuracy 0.8694 and Training loss 0.07496970555816773\n",
            "Iteration 35600: Training Accuracy 0.60245, Test Accuracy 0.8713 and Training loss 0.07437383408973049\n",
            "Iteration 35700: Training Accuracy 0.6168166666666667, Test Accuracy 0.8772 and Training loss 0.0743751329012493\n",
            "Iteration 35800: Training Accuracy 0.6207166666666667, Test Accuracy 0.868 and Training loss 0.07432165681283626\n",
            "Iteration 35900: Training Accuracy 0.6000166666666666, Test Accuracy 0.8672 and Training loss 0.07438138751415646\n",
            "Iteration 36000: Training Accuracy 0.6073, Test Accuracy 0.8796 and Training loss 0.07429457518266476\n",
            "Iteration 36100: Training Accuracy 0.61175, Test Accuracy 0.8774 and Training loss 0.07424939252635374\n",
            "Iteration 36200: Training Accuracy 0.5824166666666667, Test Accuracy 0.86 and Training loss 0.07593699823238935\n",
            "Iteration 36300: Training Accuracy 0.62165, Test Accuracy 0.8718 and Training loss 0.07409946137877729\n",
            "Iteration 36400: Training Accuracy 0.6113, Test Accuracy 0.8652 and Training loss 0.07409588061692533\n",
            "Iteration 36500: Training Accuracy 0.6156333333333334, Test Accuracy 0.8681 and Training loss 0.07392203502006821\n",
            "Iteration 36600: Training Accuracy 0.5896333333333333, Test Accuracy 0.8517 and Training loss 0.07477965332675506\n",
            "Iteration 36700: Training Accuracy 0.6041333333333333, Test Accuracy 0.8601 and Training loss 0.07431095547556602\n",
            "Iteration 36800: Training Accuracy 0.62035, Test Accuracy 0.8706 and Training loss 0.07379379830155414\n",
            "Iteration 36900: Training Accuracy 0.6078, Test Accuracy 0.8657 and Training loss 0.07394435442645485\n",
            "Iteration 37000: Training Accuracy 0.6051333333333333, Test Accuracy 0.8672 and Training loss 0.07394077452357249\n",
            "Iteration 37100: Training Accuracy 0.6033333333333334, Test Accuracy 0.8713 and Training loss 0.07387233466921053\n",
            "Iteration 37200: Training Accuracy 0.6063666666666667, Test Accuracy 0.869 and Training loss 0.07405005981475601\n",
            "Iteration 37300: Training Accuracy 0.6209166666666667, Test Accuracy 0.873 and Training loss 0.07369883292849792\n",
            "Iteration 37400: Training Accuracy 0.6120333333333333, Test Accuracy 0.8622 and Training loss 0.07379813032792314\n",
            "Iteration 37500: Training Accuracy 0.6073666666666667, Test Accuracy 0.8584 and Training loss 0.07428821459315074\n",
            "Iteration 37600: Training Accuracy 0.6204, Test Accuracy 0.8757 and Training loss 0.07383986004581646\n",
            "Iteration 37700: Training Accuracy 0.6253, Test Accuracy 0.8789 and Training loss 0.07381166200719239\n",
            "Iteration 37800: Training Accuracy 0.5930333333333333, Test Accuracy 0.8655 and Training loss 0.0740558114768205\n",
            "Iteration 37900: Training Accuracy 0.6222166666666666, Test Accuracy 0.8817 and Training loss 0.07396647640886841\n",
            "Iteration 38000: Training Accuracy 0.6069833333333333, Test Accuracy 0.8728 and Training loss 0.07343742436813805\n",
            "Iteration 38100: Training Accuracy 0.62465, Test Accuracy 0.8745 and Training loss 0.07405010146322423\n",
            "Iteration 38200: Training Accuracy 0.6163333333333333, Test Accuracy 0.8715 and Training loss 0.07315461888936405\n",
            "Iteration 38300: Training Accuracy 0.6040166666666666, Test Accuracy 0.8754 and Training loss 0.07337995065863344\n",
            "Iteration 38400: Training Accuracy 0.5972833333333334, Test Accuracy 0.8565 and Training loss 0.07355655123845126\n",
            "Iteration 38500: Training Accuracy 0.60045, Test Accuracy 0.869 and Training loss 0.07327736070263773\n",
            "Iteration 38600: Training Accuracy 0.64665, Test Accuracy 0.8849 and Training loss 0.07470694993368582\n",
            "Iteration 38700: Training Accuracy 0.6035666666666667, Test Accuracy 0.8703 and Training loss 0.07318551092102694\n",
            "Iteration 38800: Training Accuracy 0.6316, Test Accuracy 0.8682 and Training loss 0.0733621166268067\n",
            "Iteration 38900: Training Accuracy 0.63515, Test Accuracy 0.8737 and Training loss 0.07334686791711192\n",
            "Iteration 39000: Training Accuracy 0.60585, Test Accuracy 0.864 and Training loss 0.07313398841776471\n",
            "Iteration 39100: Training Accuracy 0.6163666666666666, Test Accuracy 0.8674 and Training loss 0.07281099058984856\n",
            "Iteration 39200: Training Accuracy 0.61685, Test Accuracy 0.8686 and Training loss 0.07294031825642391\n",
            "Iteration 39300: Training Accuracy 0.6087666666666667, Test Accuracy 0.8638 and Training loss 0.07327273891271127\n",
            "Iteration 39400: Training Accuracy 0.6485, Test Accuracy 0.8796 and Training loss 0.07356287303297292\n",
            "Iteration 39500: Training Accuracy 0.63435, Test Accuracy 0.879 and Training loss 0.07313200587578095\n",
            "Iteration 39600: Training Accuracy 0.6209333333333333, Test Accuracy 0.8728 and Training loss 0.07273773752880368\n",
            "Iteration 39700: Training Accuracy 0.6260166666666667, Test Accuracy 0.8748 and Training loss 0.07263166814395423\n",
            "Iteration 39800: Training Accuracy 0.6122833333333333, Test Accuracy 0.8731 and Training loss 0.07288522097490976\n",
            "Iteration 39900: Training Accuracy 0.61355, Test Accuracy 0.8726 and Training loss 0.07280630092216248\n",
            "Iteration 40000: Training Accuracy 0.6203666666666666, Test Accuracy 0.866 and Training loss 0.07265699326165358\n",
            "Iteration 40100: Training Accuracy 0.6406666666666667, Test Accuracy 0.8754 and Training loss 0.07299563786396299\n",
            "Iteration 40200: Training Accuracy 0.6287, Test Accuracy 0.8775 and Training loss 0.07267240145017402\n",
            "Iteration 40300: Training Accuracy 0.6152166666666666, Test Accuracy 0.8776 and Training loss 0.07227803914206163\n",
            "Iteration 40400: Training Accuracy 0.6350333333333333, Test Accuracy 0.8847 and Training loss 0.07291459082865466\n",
            "Iteration 40500: Training Accuracy 0.5918, Test Accuracy 0.8694 and Training loss 0.07298893374429918\n",
            "Iteration 40600: Training Accuracy 0.60245, Test Accuracy 0.8784 and Training loss 0.07275304679113168\n",
            "Iteration 40700: Training Accuracy 0.58985, Test Accuracy 0.8697 and Training loss 0.07293026952252545\n",
            "Iteration 40800: Training Accuracy 0.6303333333333333, Test Accuracy 0.8844 and Training loss 0.07220281490611882\n",
            "Iteration 40900: Training Accuracy 0.6020666666666666, Test Accuracy 0.8816 and Training loss 0.07246397233359236\n",
            "Iteration 41000: Training Accuracy 0.61465, Test Accuracy 0.8841 and Training loss 0.0720206768150855\n",
            "Iteration 41100: Training Accuracy 0.6219833333333333, Test Accuracy 0.8891 and Training loss 0.07219613373348648\n",
            "Iteration 41200: Training Accuracy 0.63235, Test Accuracy 0.8865 and Training loss 0.07251389725387797\n",
            "Iteration 41300: Training Accuracy 0.6169166666666667, Test Accuracy 0.8741 and Training loss 0.0720983370277664\n",
            "Iteration 41400: Training Accuracy 0.6037166666666667, Test Accuracy 0.8759 and Training loss 0.07222414315291348\n",
            "Iteration 41500: Training Accuracy 0.6172333333333333, Test Accuracy 0.8717 and Training loss 0.07236612311626717\n",
            "Iteration 41600: Training Accuracy 0.6543333333333333, Test Accuracy 0.889 and Training loss 0.07341817821513161\n",
            "Iteration 41700: Training Accuracy 0.6014333333333334, Test Accuracy 0.8802 and Training loss 0.07249124210536312\n",
            "Iteration 41800: Training Accuracy 0.6338166666666667, Test Accuracy 0.883 and Training loss 0.07223698133102745\n",
            "Iteration 41900: Training Accuracy 0.6290666666666667, Test Accuracy 0.8784 and Training loss 0.07195087340746904\n",
            "Iteration 42000: Training Accuracy 0.6269666666666667, Test Accuracy 0.873 and Training loss 0.07175264174997317\n",
            "Iteration 42100: Training Accuracy 0.6123833333333333, Test Accuracy 0.8623 and Training loss 0.07215531958700347\n",
            "Iteration 42200: Training Accuracy 0.6171666666666666, Test Accuracy 0.8728 and Training loss 0.07186097464363088\n",
            "Iteration 42300: Training Accuracy 0.6324166666666666, Test Accuracy 0.8765 and Training loss 0.07200183315132938\n",
            "Iteration 42400: Training Accuracy 0.6233333333333333, Test Accuracy 0.8658 and Training loss 0.07182917293287781\n",
            "Iteration 42500: Training Accuracy 0.6195333333333334, Test Accuracy 0.8658 and Training loss 0.07173690669619942\n",
            "Iteration 42600: Training Accuracy 0.5861333333333333, Test Accuracy 0.85 and Training loss 0.07281042109917256\n",
            "Iteration 42700: Training Accuracy 0.6210833333333333, Test Accuracy 0.87 and Training loss 0.07187889406565544\n",
            "Iteration 42800: Training Accuracy 0.6245333333333334, Test Accuracy 0.8755 and Training loss 0.07170661595922152\n",
            "Iteration 42900: Training Accuracy 0.6209833333333333, Test Accuracy 0.8827 and Training loss 0.07166905207347588\n",
            "Iteration 43000: Training Accuracy 0.6209833333333333, Test Accuracy 0.875 and Training loss 0.07174792340573019\n",
            "Iteration 43100: Training Accuracy 0.61005, Test Accuracy 0.872 and Training loss 0.07150851336464019\n",
            "Iteration 43200: Training Accuracy 0.5973166666666667, Test Accuracy 0.8724 and Training loss 0.07174813066729278\n",
            "Iteration 43300: Training Accuracy 0.6538, Test Accuracy 0.8896 and Training loss 0.07368261928816619\n",
            "Iteration 43400: Training Accuracy 0.6164333333333334, Test Accuracy 0.8768 and Training loss 0.07139195007429287\n",
            "Iteration 43500: Training Accuracy 0.6084166666666667, Test Accuracy 0.8651 and Training loss 0.07147257918123881\n",
            "Iteration 43600: Training Accuracy 0.6379, Test Accuracy 0.8757 and Training loss 0.07151492701055423\n",
            "Iteration 43700: Training Accuracy 0.6303166666666666, Test Accuracy 0.8629 and Training loss 0.0713390719749265\n",
            "Iteration 43800: Training Accuracy 0.6066, Test Accuracy 0.8593 and Training loss 0.07160784901533793\n",
            "Iteration 43900: Training Accuracy 0.6110166666666667, Test Accuracy 0.8489 and Training loss 0.07186501263934546\n",
            "Iteration 44000: Training Accuracy 0.6218333333333333, Test Accuracy 0.8643 and Training loss 0.07121344145746278\n",
            "Iteration 44100: Training Accuracy 0.6106, Test Accuracy 0.8574 and Training loss 0.07128893874719844\n",
            "Iteration 44200: Training Accuracy 0.6020666666666666, Test Accuracy 0.8578 and Training loss 0.07120078169163883\n",
            "Iteration 44300: Training Accuracy 0.6217166666666667, Test Accuracy 0.8707 and Training loss 0.07129370587771369\n",
            "Iteration 44400: Training Accuracy 0.6322666666666666, Test Accuracy 0.8688 and Training loss 0.07112618339649572\n",
            "Iteration 44500: Training Accuracy 0.6267833333333334, Test Accuracy 0.8763 and Training loss 0.07112492151262367\n",
            "Iteration 44600: Training Accuracy 0.5973666666666667, Test Accuracy 0.863 and Training loss 0.07164090636151947\n",
            "Iteration 44700: Training Accuracy 0.6159666666666667, Test Accuracy 0.8706 and Training loss 0.07082669608252073\n",
            "Iteration 44800: Training Accuracy 0.6135166666666667, Test Accuracy 0.8754 and Training loss 0.0712496086360366\n",
            "Iteration 44900: Training Accuracy 0.63475, Test Accuracy 0.8802 and Training loss 0.07097087563203867\n",
            "Iteration 45000: Training Accuracy 0.6426666666666667, Test Accuracy 0.8857 and Training loss 0.0714173066444913\n",
            "Iteration 45100: Training Accuracy 0.6232333333333333, Test Accuracy 0.8746 and Training loss 0.07070270680660942\n",
            "Iteration 45200: Training Accuracy 0.6232833333333333, Test Accuracy 0.8708 and Training loss 0.07063917372807005\n",
            "Iteration 45300: Training Accuracy 0.6125, Test Accuracy 0.8691 and Training loss 0.07064547625953803\n",
            "Iteration 45400: Training Accuracy 0.6076333333333334, Test Accuracy 0.8684 and Training loss 0.07075786546998399\n",
            "Iteration 45500: Training Accuracy 0.64235, Test Accuracy 0.8797 and Training loss 0.0711065192301484\n",
            "Iteration 45600: Training Accuracy 0.6187, Test Accuracy 0.866 and Training loss 0.0706038108226771\n",
            "Iteration 45700: Training Accuracy 0.6184666666666667, Test Accuracy 0.8721 and Training loss 0.07044330718856294\n",
            "Iteration 45800: Training Accuracy 0.6041666666666666, Test Accuracy 0.8571 and Training loss 0.07071617139110754\n",
            "Iteration 45900: Training Accuracy 0.6164, Test Accuracy 0.8665 and Training loss 0.07025222479254879\n",
            "Iteration 46000: Training Accuracy 0.6346833333333334, Test Accuracy 0.8693 and Training loss 0.07041074478529534\n",
            "Iteration 46100: Training Accuracy 0.6447666666666667, Test Accuracy 0.8769 and Training loss 0.07086936890991517\n",
            "Iteration 46200: Training Accuracy 0.63315, Test Accuracy 0.8749 and Training loss 0.07022934064603466\n",
            "Iteration 46300: Training Accuracy 0.6390333333333333, Test Accuracy 0.8778 and Training loss 0.07036431265923768\n",
            "Iteration 46400: Training Accuracy 0.6118333333333333, Test Accuracy 0.859 and Training loss 0.07052072420275553\n",
            "Iteration 46500: Training Accuracy 0.6367166666666667, Test Accuracy 0.8654 and Training loss 0.07010520158077295\n",
            "Iteration 46600: Training Accuracy 0.6209666666666667, Test Accuracy 0.8535 and Training loss 0.07051632013904988\n",
            "Iteration 46700: Training Accuracy 0.6121666666666666, Test Accuracy 0.8536 and Training loss 0.07037465198183632\n",
            "Iteration 46800: Training Accuracy 0.6217, Test Accuracy 0.861 and Training loss 0.07010024750233287\n",
            "Iteration 46900: Training Accuracy 0.5995333333333334, Test Accuracy 0.8573 and Training loss 0.07035866338385081\n",
            "Iteration 47000: Training Accuracy 0.6196833333333334, Test Accuracy 0.8615 and Training loss 0.06999501827516759\n",
            "Iteration 47100: Training Accuracy 0.6276333333333334, Test Accuracy 0.8722 and Training loss 0.06986782691676534\n",
            "Iteration 47200: Training Accuracy 0.6154666666666667, Test Accuracy 0.8661 and Training loss 0.0699539921624298\n",
            "Iteration 47300: Training Accuracy 0.5982666666666666, Test Accuracy 0.8501 and Training loss 0.07070105275093169\n",
            "Iteration 47400: Training Accuracy 0.6139166666666667, Test Accuracy 0.869 and Training loss 0.06975837830980826\n",
            "Iteration 47500: Training Accuracy 0.6084, Test Accuracy 0.8609 and Training loss 0.06979627655309945\n",
            "Iteration 47600: Training Accuracy 0.6102833333333333, Test Accuracy 0.86 and Training loss 0.0697434257662385\n",
            "Iteration 47700: Training Accuracy 0.6136, Test Accuracy 0.8665 and Training loss 0.0696088364792942\n",
            "Iteration 47800: Training Accuracy 0.6064833333333334, Test Accuracy 0.8598 and Training loss 0.06961060069505323\n",
            "Iteration 47900: Training Accuracy 0.6234833333333333, Test Accuracy 0.8675 and Training loss 0.06944033183835331\n",
            "Iteration 48000: Training Accuracy 0.6273, Test Accuracy 0.8741 and Training loss 0.06976793547177848\n",
            "Iteration 48100: Training Accuracy 0.6318666666666667, Test Accuracy 0.8718 and Training loss 0.06961886196185284\n",
            "Iteration 48200: Training Accuracy 0.6185, Test Accuracy 0.859 and Training loss 0.06968614658738824\n",
            "Iteration 48300: Training Accuracy 0.6259333333333333, Test Accuracy 0.8612 and Training loss 0.06946977757267099\n",
            "Iteration 48400: Training Accuracy 0.6127333333333334, Test Accuracy 0.8676 and Training loss 0.06955693381699507\n",
            "Iteration 48500: Training Accuracy 0.6482333333333333, Test Accuracy 0.8789 and Training loss 0.06975511251901727\n",
            "Iteration 48600: Training Accuracy 0.6564666666666666, Test Accuracy 0.8854 and Training loss 0.07032138355868037\n",
            "Iteration 48700: Training Accuracy 0.6061166666666666, Test Accuracy 0.8726 and Training loss 0.0696544619185491\n",
            "Iteration 48800: Training Accuracy 0.6215833333333334, Test Accuracy 0.8703 and Training loss 0.06928854581564883\n",
            "Iteration 48900: Training Accuracy 0.6298833333333334, Test Accuracy 0.8684 and Training loss 0.06931133089907383\n",
            "Iteration 49000: Training Accuracy 0.6281, Test Accuracy 0.862 and Training loss 0.06944796714172267\n",
            "Iteration 49100: Training Accuracy 0.60995, Test Accuracy 0.8511 and Training loss 0.06983970071272981\n",
            "Iteration 49200: Training Accuracy 0.6343, Test Accuracy 0.8682 and Training loss 0.0697059782973664\n",
            "Iteration 49300: Training Accuracy 0.6192, Test Accuracy 0.8617 and Training loss 0.06918363431255564\n",
            "Iteration 49400: Training Accuracy 0.6520666666666667, Test Accuracy 0.8785 and Training loss 0.07018131707944175\n",
            "Iteration 49500: Training Accuracy 0.62295, Test Accuracy 0.8662 and Training loss 0.06915549904528033\n",
            "Iteration 49600: Training Accuracy 0.6267833333333334, Test Accuracy 0.8677 and Training loss 0.06906224947269467\n",
            "Iteration 49700: Training Accuracy 0.6446833333333334, Test Accuracy 0.8683 and Training loss 0.069767748480488\n",
            "Iteration 49800: Training Accuracy 0.6065166666666667, Test Accuracy 0.8539 and Training loss 0.06950144230172753\n",
            "Iteration 49900: Training Accuracy 0.62005, Test Accuracy 0.8596 and Training loss 0.0693059226456234\n",
            "Iteration 50000: Training Accuracy 0.618, Test Accuracy 0.8476 and Training loss 0.06924441144238154\n",
            "Iteration 50100: Training Accuracy 0.6038333333333333, Test Accuracy 0.8533 and Training loss 0.06937443126417098\n",
            "Iteration 50200: Training Accuracy 0.6179666666666667, Test Accuracy 0.8693 and Training loss 0.06880362406459054\n",
            "Iteration 50300: Training Accuracy 0.6135833333333334, Test Accuracy 0.8687 and Training loss 0.06881571768005351\n",
            "Iteration 50400: Training Accuracy 0.6122333333333333, Test Accuracy 0.8674 and Training loss 0.06883164497330795\n",
            "Iteration 50500: Training Accuracy 0.59955, Test Accuracy 0.8499 and Training loss 0.06928502062467883\n",
            "Iteration 50600: Training Accuracy 0.6266, Test Accuracy 0.8631 and Training loss 0.06876690767973713\n",
            "Iteration 50700: Training Accuracy 0.5963, Test Accuracy 0.8445 and Training loss 0.0696021431839848\n",
            "Iteration 50800: Training Accuracy 0.6370833333333333, Test Accuracy 0.8658 and Training loss 0.0693255641857511\n",
            "Iteration 50900: Training Accuracy 0.6104666666666667, Test Accuracy 0.8587 and Training loss 0.06840891565421062\n",
            "Iteration 51000: Training Accuracy 0.5929666666666666, Test Accuracy 0.8492 and Training loss 0.06922642453173453\n",
            "Iteration 51100: Training Accuracy 0.6319166666666667, Test Accuracy 0.8741 and Training loss 0.06877109039847469\n",
            "Iteration 51200: Training Accuracy 0.6509333333333334, Test Accuracy 0.8807 and Training loss 0.06966874615353713\n",
            "Iteration 51300: Training Accuracy 0.6196833333333334, Test Accuracy 0.8672 and Training loss 0.06870780880941625\n",
            "Iteration 51400: Training Accuracy 0.6063333333333333, Test Accuracy 0.8568 and Training loss 0.06854318701081819\n",
            "Iteration 51500: Training Accuracy 0.6224, Test Accuracy 0.8648 and Training loss 0.06850024101659445\n",
            "Iteration 51600: Training Accuracy 0.6356833333333334, Test Accuracy 0.8676 and Training loss 0.06852739427038869\n",
            "Iteration 51700: Training Accuracy 0.5867666666666667, Test Accuracy 0.8444 and Training loss 0.0697248052826714\n",
            "Iteration 51800: Training Accuracy 0.6300333333333333, Test Accuracy 0.8667 and Training loss 0.06949520606317848\n",
            "Iteration 51900: Training Accuracy 0.62165, Test Accuracy 0.8604 and Training loss 0.06836477992016518\n",
            "Iteration 52000: Training Accuracy 0.6208333333333333, Test Accuracy 0.8703 and Training loss 0.0686022755416749\n",
            "Iteration 52100: Training Accuracy 0.6239666666666667, Test Accuracy 0.8647 and Training loss 0.0681170539577821\n",
            "Iteration 52200: Training Accuracy 0.6373166666666666, Test Accuracy 0.8662 and Training loss 0.06832193703903862\n",
            "Iteration 52300: Training Accuracy 0.6091833333333333, Test Accuracy 0.8533 and Training loss 0.06827270225918983\n",
            "Iteration 52400: Training Accuracy 0.60885, Test Accuracy 0.8527 and Training loss 0.06826536389798397\n",
            "Iteration 52500: Training Accuracy 0.6501166666666667, Test Accuracy 0.8711 and Training loss 0.06911230320940746\n",
            "Iteration 52600: Training Accuracy 0.5953333333333334, Test Accuracy 0.8415 and Training loss 0.06872336235536532\n",
            "Iteration 52700: Training Accuracy 0.6266666666666667, Test Accuracy 0.8586 and Training loss 0.0679600689843513\n",
            "Iteration 52800: Training Accuracy 0.6187, Test Accuracy 0.8593 and Training loss 0.06783178941755018\n",
            "Iteration 52900: Training Accuracy 0.6268, Test Accuracy 0.8578 and Training loss 0.06810723724369026\n",
            "Iteration 53000: Training Accuracy 0.6287333333333334, Test Accuracy 0.8564 and Training loss 0.06792312852208755\n",
            "Iteration 53100: Training Accuracy 0.6497833333333334, Test Accuracy 0.8601 and Training loss 0.06832925587638401\n",
            "Iteration 53200: Training Accuracy 0.6327, Test Accuracy 0.8477 and Training loss 0.06838103219002993\n",
            "Iteration 53300: Training Accuracy 0.63365, Test Accuracy 0.861 and Training loss 0.06803728825364284\n",
            "Iteration 53400: Training Accuracy 0.63495, Test Accuracy 0.8557 and Training loss 0.06801101961120774\n",
            "Iteration 53500: Training Accuracy 0.63255, Test Accuracy 0.8552 and Training loss 0.0677928191645408\n",
            "Iteration 53600: Training Accuracy 0.6205, Test Accuracy 0.8559 and Training loss 0.06754764848557049\n",
            "Iteration 53700: Training Accuracy 0.6323, Test Accuracy 0.8581 and Training loss 0.06758903094338459\n",
            "Iteration 53800: Training Accuracy 0.6404, Test Accuracy 0.8657 and Training loss 0.06757894986093568\n",
            "Iteration 53900: Training Accuracy 0.6061, Test Accuracy 0.8487 and Training loss 0.06795225965974533\n",
            "Iteration 54000: Training Accuracy 0.639, Test Accuracy 0.8629 and Training loss 0.06745686498022375\n",
            "Iteration 54100: Training Accuracy 0.6248, Test Accuracy 0.8612 and Training loss 0.06721702302591559\n",
            "Iteration 54200: Training Accuracy 0.6236, Test Accuracy 0.8572 and Training loss 0.06730706349456489\n",
            "Iteration 54300: Training Accuracy 0.6345, Test Accuracy 0.8501 and Training loss 0.0675343436460314\n",
            "Iteration 54400: Training Accuracy 0.65375, Test Accuracy 0.8609 and Training loss 0.0683544712403763\n",
            "Iteration 54500: Training Accuracy 0.6171833333333333, Test Accuracy 0.8522 and Training loss 0.06720907821292477\n",
            "Iteration 54600: Training Accuracy 0.6359666666666667, Test Accuracy 0.8556 and Training loss 0.06759730580008107\n",
            "Iteration 54700: Training Accuracy 0.63815, Test Accuracy 0.8651 and Training loss 0.06765980153181536\n",
            "Iteration 54800: Training Accuracy 0.6167166666666667, Test Accuracy 0.8545 and Training loss 0.06725283297118304\n",
            "Iteration 54900: Training Accuracy 0.6515833333333333, Test Accuracy 0.8639 and Training loss 0.06767528886722912\n",
            "Iteration 55000: Training Accuracy 0.61965, Test Accuracy 0.848 and Training loss 0.06706958034228544\n",
            "Iteration 55100: Training Accuracy 0.62755, Test Accuracy 0.8561 and Training loss 0.06724076352510518\n",
            "Iteration 55200: Training Accuracy 0.622, Test Accuracy 0.8368 and Training loss 0.06704169656259089\n",
            "Iteration 55300: Training Accuracy 0.6375333333333333, Test Accuracy 0.8533 and Training loss 0.06699173788623684\n",
            "Iteration 55400: Training Accuracy 0.6569833333333334, Test Accuracy 0.8637 and Training loss 0.06783754738370452\n",
            "Iteration 55500: Training Accuracy 0.6231, Test Accuracy 0.8438 and Training loss 0.067049870013644\n",
            "Iteration 55600: Training Accuracy 0.6280333333333333, Test Accuracy 0.8494 and Training loss 0.06711897234306698\n",
            "Iteration 55700: Training Accuracy 0.64195, Test Accuracy 0.8564 and Training loss 0.06713812925170752\n",
            "Iteration 55800: Training Accuracy 0.63805, Test Accuracy 0.8536 and Training loss 0.06699066652564123\n",
            "Iteration 55900: Training Accuracy 0.6217333333333334, Test Accuracy 0.8414 and Training loss 0.06682753195501814\n",
            "Iteration 56000: Training Accuracy 0.6261333333333333, Test Accuracy 0.8536 and Training loss 0.06705880117001996\n",
            "Iteration 56100: Training Accuracy 0.6135333333333334, Test Accuracy 0.8507 and Training loss 0.06713272005473751\n",
            "Iteration 56200: Training Accuracy 0.6128833333333333, Test Accuracy 0.8494 and Training loss 0.06693661622853835\n",
            "Iteration 56300: Training Accuracy 0.6155833333333334, Test Accuracy 0.8421 and Training loss 0.06744706520419644\n",
            "Iteration 56400: Training Accuracy 0.6314833333333333, Test Accuracy 0.8619 and Training loss 0.0670528697967312\n",
            "Iteration 56500: Training Accuracy 0.6108666666666667, Test Accuracy 0.8475 and Training loss 0.06703871133285393\n",
            "Iteration 56600: Training Accuracy 0.6122166666666666, Test Accuracy 0.8459 and Training loss 0.06681322653192347\n",
            "Iteration 56700: Training Accuracy 0.6254166666666666, Test Accuracy 0.8485 and Training loss 0.06680050331099535\n",
            "Iteration 56800: Training Accuracy 0.6045833333333334, Test Accuracy 0.8427 and Training loss 0.06678301004491395\n",
            "Iteration 56900: Training Accuracy 0.6182333333333333, Test Accuracy 0.8512 and Training loss 0.06662209327929153\n",
            "Iteration 57000: Training Accuracy 0.6339666666666667, Test Accuracy 0.8537 and Training loss 0.06682010637173348\n",
            "Iteration 57100: Training Accuracy 0.6174333333333333, Test Accuracy 0.8493 and Training loss 0.06655690715614578\n",
            "Iteration 57200: Training Accuracy 0.6334666666666666, Test Accuracy 0.8483 and Training loss 0.0664549853578702\n",
            "Iteration 57300: Training Accuracy 0.6376666666666667, Test Accuracy 0.8564 and Training loss 0.0664269020134441\n",
            "Iteration 57400: Training Accuracy 0.63245, Test Accuracy 0.8597 and Training loss 0.06648038163007171\n",
            "Iteration 57500: Training Accuracy 0.6305833333333334, Test Accuracy 0.8505 and Training loss 0.06625710495084271\n",
            "Iteration 57600: Training Accuracy 0.6107166666666667, Test Accuracy 0.846 and Training loss 0.06685935263838366\n",
            "Iteration 57700: Training Accuracy 0.6443833333333333, Test Accuracy 0.8573 and Training loss 0.06628022719069832\n",
            "Iteration 57800: Training Accuracy 0.6499833333333334, Test Accuracy 0.8672 and Training loss 0.0665460638576259\n",
            "Iteration 57900: Training Accuracy 0.6188166666666667, Test Accuracy 0.8503 and Training loss 0.06621988849018738\n",
            "Iteration 58000: Training Accuracy 0.6121166666666666, Test Accuracy 0.8402 and Training loss 0.06621261366360823\n",
            "Iteration 58100: Training Accuracy 0.5921333333333333, Test Accuracy 0.8269 and Training loss 0.06784648650967084\n",
            "Iteration 58200: Training Accuracy 0.6431833333333333, Test Accuracy 0.8714 and Training loss 0.06643823672493522\n",
            "Iteration 58300: Training Accuracy 0.6116333333333334, Test Accuracy 0.8535 and Training loss 0.06647657307930614\n",
            "Iteration 58400: Training Accuracy 0.6525, Test Accuracy 0.8641 and Training loss 0.06623774881676084\n",
            "Iteration 58500: Training Accuracy 0.5989, Test Accuracy 0.8421 and Training loss 0.06689749655343206\n",
            "Iteration 58600: Training Accuracy 0.6208, Test Accuracy 0.857 and Training loss 0.06604404250086363\n",
            "Iteration 58700: Training Accuracy 0.6165666666666667, Test Accuracy 0.853 and Training loss 0.06600826638204113\n",
            "Iteration 58800: Training Accuracy 0.63655, Test Accuracy 0.8647 and Training loss 0.06594361406967172\n",
            "Iteration 58900: Training Accuracy 0.61615, Test Accuracy 0.8472 and Training loss 0.06603162632854324\n",
            "Iteration 59000: Training Accuracy 0.6295833333333334, Test Accuracy 0.8578 and Training loss 0.06579788482541597\n",
            "Iteration 59100: Training Accuracy 0.6321666666666667, Test Accuracy 0.8672 and Training loss 0.0660193472282814\n",
            "Iteration 59200: Training Accuracy 0.6373166666666666, Test Accuracy 0.8601 and Training loss 0.06632960779367475\n",
            "Iteration 59300: Training Accuracy 0.6037166666666667, Test Accuracy 0.838 and Training loss 0.06631086036359174\n",
            "Iteration 59400: Training Accuracy 0.6216666666666667, Test Accuracy 0.836 and Training loss 0.06576617550209113\n",
            "Iteration 59500: Training Accuracy 0.6293666666666666, Test Accuracy 0.8377 and Training loss 0.06600145558534108\n",
            "Iteration 59600: Training Accuracy 0.6008666666666667, Test Accuracy 0.8283 and Training loss 0.06663022447428853\n",
            "Iteration 59700: Training Accuracy 0.616, Test Accuracy 0.8443 and Training loss 0.06590489059826114\n",
            "Iteration 59800: Training Accuracy 0.6133666666666666, Test Accuracy 0.8369 and Training loss 0.06609111235098253\n",
            "Iteration 59900: Training Accuracy 0.6497333333333334, Test Accuracy 0.8579 and Training loss 0.06628650636335688\n",
            "Iteration 60000: Training Accuracy 0.6299166666666667, Test Accuracy 0.8382 and Training loss 0.06543609306191137\n",
            "Final test accuracy for k = 5: 0.8382\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training with k = 40\n",
            "Iteration 0: Training accuracy 0.48941666666666667, Test accuracy 0.4864 and Training loss 0.48229410962038555\n",
            "Iteration 100: Training Accuracy 0.49006666666666665, Test Accuracy 0.4861 and Training loss 0.28526575467479814\n",
            "Iteration 200: Training Accuracy 0.49006666666666665, Test Accuracy 0.4861 and Training loss 0.2279295232907365\n",
            "Iteration 300: Training Accuracy 0.4901333333333333, Test Accuracy 0.4863 and Training loss 0.21037833048181293\n",
            "Iteration 400: Training Accuracy 0.49065, Test Accuracy 0.4894 and Training loss 0.20011831792999912\n",
            "Iteration 500: Training Accuracy 0.4917666666666667, Test Accuracy 0.4944 and Training loss 0.19160721398880412\n",
            "Iteration 600: Training Accuracy 0.49438333333333334, Test Accuracy 0.5064 and Training loss 0.18488034241022\n",
            "Iteration 700: Training Accuracy 0.49546666666666667, Test Accuracy 0.513 and Training loss 0.17895969783883675\n",
            "Iteration 800: Training Accuracy 0.49833333333333335, Test Accuracy 0.5268 and Training loss 0.1734560958851813\n",
            "Iteration 900: Training Accuracy 0.5035833333333334, Test Accuracy 0.549 and Training loss 0.16903622404006768\n",
            "Iteration 1000: Training Accuracy 0.50465, Test Accuracy 0.5538 and Training loss 0.16613432073031428\n",
            "Iteration 1100: Training Accuracy 0.5146166666666666, Test Accuracy 0.5936 and Training loss 0.16299672384303113\n",
            "Iteration 1200: Training Accuracy 0.5134, Test Accuracy 0.5943 and Training loss 0.1592465259083\n",
            "Iteration 1300: Training Accuracy 0.5221333333333333, Test Accuracy 0.6278 and Training loss 0.15643690390744577\n",
            "Iteration 1400: Training Accuracy 0.5195333333333333, Test Accuracy 0.6311 and Training loss 0.15456465359620308\n",
            "Iteration 1500: Training Accuracy 0.5260666666666667, Test Accuracy 0.6633 and Training loss 0.15197114395403932\n",
            "Iteration 1600: Training Accuracy 0.53795, Test Accuracy 0.6989 and Training loss 0.15105861525509398\n",
            "Iteration 1700: Training Accuracy 0.5320666666666667, Test Accuracy 0.685 and Training loss 0.14791659889881772\n",
            "Iteration 1800: Training Accuracy 0.5440833333333334, Test Accuracy 0.7156 and Training loss 0.1468907650703953\n",
            "Iteration 1900: Training Accuracy 0.5371333333333334, Test Accuracy 0.7048 and Training loss 0.14494761338948378\n",
            "Iteration 2000: Training Accuracy 0.5414, Test Accuracy 0.7168 and Training loss 0.14351032807811948\n",
            "Iteration 2100: Training Accuracy 0.5406166666666666, Test Accuracy 0.7247 and Training loss 0.14264030892158308\n",
            "Iteration 2200: Training Accuracy 0.5435, Test Accuracy 0.7372 and Training loss 0.14126272616662264\n",
            "Iteration 2300: Training Accuracy 0.5418833333333334, Test Accuracy 0.7363 and Training loss 0.14053799768631464\n",
            "Iteration 2400: Training Accuracy 0.5425833333333333, Test Accuracy 0.7424 and Training loss 0.1394044449293003\n",
            "Iteration 2500: Training Accuracy 0.5491833333333334, Test Accuracy 0.7603 and Training loss 0.1384000843994376\n",
            "Iteration 2600: Training Accuracy 0.5430833333333334, Test Accuracy 0.7578 and Training loss 0.1373997242520892\n",
            "Iteration 2700: Training Accuracy 0.5582333333333334, Test Accuracy 0.7802 and Training loss 0.13648553908205166\n",
            "Iteration 2800: Training Accuracy 0.5584833333333333, Test Accuracy 0.781 and Training loss 0.13539053206327895\n",
            "Iteration 2900: Training Accuracy 0.55705, Test Accuracy 0.7824 and Training loss 0.13448203719587273\n",
            "Iteration 3000: Training Accuracy 0.5517666666666666, Test Accuracy 0.776 and Training loss 0.13380068060834455\n",
            "Iteration 3100: Training Accuracy 0.5581666666666667, Test Accuracy 0.7863 and Training loss 0.13337503155352576\n",
            "Iteration 3200: Training Accuracy 0.5505, Test Accuracy 0.7806 and Training loss 0.1328577182318933\n",
            "Iteration 3300: Training Accuracy 0.55, Test Accuracy 0.7839 and Training loss 0.13243928656103904\n",
            "Iteration 3400: Training Accuracy 0.5653666666666667, Test Accuracy 0.8024 and Training loss 0.13169116813618106\n",
            "Iteration 3500: Training Accuracy 0.5594333333333333, Test Accuracy 0.7977 and Training loss 0.1311079658999033\n",
            "Iteration 3600: Training Accuracy 0.5608166666666666, Test Accuracy 0.8005 and Training loss 0.13059359479366608\n",
            "Iteration 3700: Training Accuracy 0.5540333333333334, Test Accuracy 0.7946 and Training loss 0.13021750474563892\n",
            "Iteration 3800: Training Accuracy 0.5694666666666667, Test Accuracy 0.8139 and Training loss 0.1303825785595509\n",
            "Iteration 3900: Training Accuracy 0.5596333333333333, Test Accuracy 0.8073 and Training loss 0.1292666768889829\n",
            "Iteration 4000: Training Accuracy 0.5553333333333333, Test Accuracy 0.8055 and Training loss 0.1286591825705078\n",
            "Iteration 4100: Training Accuracy 0.5497666666666666, Test Accuracy 0.7939 and Training loss 0.12816890820984442\n",
            "Iteration 4200: Training Accuracy 0.5466, Test Accuracy 0.7906 and Training loss 0.12785539938051185\n",
            "Iteration 4300: Training Accuracy 0.54645, Test Accuracy 0.7914 and Training loss 0.12745176906378244\n",
            "Iteration 4400: Training Accuracy 0.5494833333333333, Test Accuracy 0.7981 and Training loss 0.12714227824248311\n",
            "Iteration 4500: Training Accuracy 0.5567666666666666, Test Accuracy 0.8036 and Training loss 0.12684883120966864\n",
            "Iteration 4600: Training Accuracy 0.5528333333333333, Test Accuracy 0.8033 and Training loss 0.12625668835798762\n",
            "Iteration 4700: Training Accuracy 0.5562666666666667, Test Accuracy 0.808 and Training loss 0.12618723623605113\n",
            "Iteration 4800: Training Accuracy 0.5441833333333334, Test Accuracy 0.7911 and Training loss 0.12574512885909542\n",
            "Iteration 4900: Training Accuracy 0.5471333333333334, Test Accuracy 0.7965 and Training loss 0.12506453887903385\n",
            "Iteration 5000: Training Accuracy 0.5496166666666666, Test Accuracy 0.8 and Training loss 0.12475468807456375\n",
            "Iteration 5100: Training Accuracy 0.5460166666666667, Test Accuracy 0.7914 and Training loss 0.12449950111466121\n",
            "Iteration 5200: Training Accuracy 0.5581166666666667, Test Accuracy 0.8091 and Training loss 0.12458223639331445\n",
            "Iteration 5300: Training Accuracy 0.5443833333333333, Test Accuracy 0.7897 and Training loss 0.12432635562197304\n",
            "Iteration 5400: Training Accuracy 0.5399833333333334, Test Accuracy 0.7844 and Training loss 0.124166597576218\n",
            "Iteration 5500: Training Accuracy 0.54495, Test Accuracy 0.796 and Training loss 0.12336273292896212\n",
            "Iteration 5600: Training Accuracy 0.5546833333333333, Test Accuracy 0.8077 and Training loss 0.12278573123776396\n",
            "Iteration 5700: Training Accuracy 0.5541333333333334, Test Accuracy 0.8089 and Training loss 0.12234672337083707\n",
            "Iteration 5800: Training Accuracy 0.5478666666666666, Test Accuracy 0.7957 and Training loss 0.1221863471135135\n",
            "Iteration 5900: Training Accuracy 0.5342166666666667, Test Accuracy 0.766 and Training loss 0.12322049054602346\n",
            "Iteration 6000: Training Accuracy 0.5517, Test Accuracy 0.7975 and Training loss 0.12154608433966024\n",
            "Iteration 6100: Training Accuracy 0.5388, Test Accuracy 0.7788 and Training loss 0.12136984081757875\n",
            "Iteration 6200: Training Accuracy 0.5479833333333334, Test Accuracy 0.801 and Training loss 0.12044032658919557\n",
            "Iteration 6300: Training Accuracy 0.54385, Test Accuracy 0.7964 and Training loss 0.12051909218718718\n",
            "Iteration 6400: Training Accuracy 0.5519, Test Accuracy 0.8084 and Training loss 0.11986469787571295\n",
            "Iteration 6500: Training Accuracy 0.5404166666666667, Test Accuracy 0.7923 and Training loss 0.11998807821600843\n",
            "Iteration 6600: Training Accuracy 0.5475833333333333, Test Accuracy 0.8053 and Training loss 0.1192339299302102\n",
            "Iteration 6700: Training Accuracy 0.5502666666666667, Test Accuracy 0.8091 and Training loss 0.11894225453164478\n",
            "Iteration 6800: Training Accuracy 0.5428, Test Accuracy 0.8018 and Training loss 0.11839505665792861\n",
            "Iteration 6900: Training Accuracy 0.5378833333333334, Test Accuracy 0.8001 and Training loss 0.1180989926589469\n",
            "Iteration 7000: Training Accuracy 0.5351833333333333, Test Accuracy 0.7938 and Training loss 0.11793416391307467\n",
            "Iteration 7100: Training Accuracy 0.5603333333333333, Test Accuracy 0.8289 and Training loss 0.11786881673369147\n",
            "Iteration 7200: Training Accuracy 0.5437333333333333, Test Accuracy 0.8101 and Training loss 0.11722250977410953\n",
            "Iteration 7300: Training Accuracy 0.5458666666666666, Test Accuracy 0.8193 and Training loss 0.1165050265039802\n",
            "Iteration 7400: Training Accuracy 0.5537833333333333, Test Accuracy 0.8316 and Training loss 0.11626936059851226\n",
            "Iteration 7500: Training Accuracy 0.5435833333333333, Test Accuracy 0.8186 and Training loss 0.11576656399361317\n",
            "Iteration 7600: Training Accuracy 0.5588166666666666, Test Accuracy 0.8325 and Training loss 0.11557673785885986\n",
            "Iteration 7700: Training Accuracy 0.5387333333333333, Test Accuracy 0.8064 and Training loss 0.114800423435128\n",
            "Iteration 7800: Training Accuracy 0.53775, Test Accuracy 0.8099 and Training loss 0.11422671083159354\n",
            "Iteration 7900: Training Accuracy 0.5388166666666667, Test Accuracy 0.8166 and Training loss 0.1138995708037809\n",
            "Iteration 8000: Training Accuracy 0.5443666666666667, Test Accuracy 0.8162 and Training loss 0.11359690529042829\n",
            "Iteration 8100: Training Accuracy 0.55465, Test Accuracy 0.8264 and Training loss 0.11321354819171324\n",
            "Iteration 8200: Training Accuracy 0.5502833333333333, Test Accuracy 0.8175 and Training loss 0.1128311889306731\n",
            "Iteration 8300: Training Accuracy 0.5413333333333333, Test Accuracy 0.809 and Training loss 0.11239923271827654\n",
            "Iteration 8400: Training Accuracy 0.5573333333333333, Test Accuracy 0.8299 and Training loss 0.11221384574500523\n",
            "Iteration 8500: Training Accuracy 0.5438333333333333, Test Accuracy 0.8127 and Training loss 0.11110371204013723\n",
            "Iteration 8600: Training Accuracy 0.5321166666666667, Test Accuracy 0.7992 and Training loss 0.11128717342898593\n",
            "Iteration 8700: Training Accuracy 0.54945, Test Accuracy 0.8222 and Training loss 0.11036106625242635\n",
            "Iteration 8800: Training Accuracy 0.54775, Test Accuracy 0.8246 and Training loss 0.10969696183287243\n",
            "Iteration 8900: Training Accuracy 0.5501666666666667, Test Accuracy 0.8235 and Training loss 0.10922544122683019\n",
            "Iteration 9000: Training Accuracy 0.5497, Test Accuracy 0.8214 and Training loss 0.1086361353517361\n",
            "Iteration 9100: Training Accuracy 0.5548, Test Accuracy 0.8242 and Training loss 0.10826891879133049\n",
            "Iteration 9200: Training Accuracy 0.5523333333333333, Test Accuracy 0.8207 and Training loss 0.10776841967086058\n",
            "Iteration 9300: Training Accuracy 0.5526666666666666, Test Accuracy 0.819 and Training loss 0.10758574740033548\n",
            "Iteration 9400: Training Accuracy 0.53275, Test Accuracy 0.7796 and Training loss 0.10789468747893202\n",
            "Iteration 9500: Training Accuracy 0.5468666666666666, Test Accuracy 0.8094 and Training loss 0.10618529404645329\n",
            "Iteration 9600: Training Accuracy 0.5439, Test Accuracy 0.8131 and Training loss 0.10570338357690306\n",
            "Iteration 9700: Training Accuracy 0.54725, Test Accuracy 0.8204 and Training loss 0.1052489457140701\n",
            "Iteration 9800: Training Accuracy 0.5466666666666666, Test Accuracy 0.8089 and Training loss 0.1048070128343081\n",
            "Iteration 9900: Training Accuracy 0.54165, Test Accuracy 0.7997 and Training loss 0.10425403903955105\n",
            "Iteration 10000: Training Accuracy 0.5601833333333334, Test Accuracy 0.8234 and Training loss 0.10378795866701143\n",
            "Iteration 10100: Training Accuracy 0.5666333333333333, Test Accuracy 0.8316 and Training loss 0.10342645105306875\n",
            "Iteration 10200: Training Accuracy 0.5444666666666667, Test Accuracy 0.8137 and Training loss 0.10324086655642373\n",
            "Iteration 10300: Training Accuracy 0.5521, Test Accuracy 0.8254 and Training loss 0.10185169643478927\n",
            "Iteration 10400: Training Accuracy 0.5539166666666666, Test Accuracy 0.8207 and Training loss 0.10146011552280407\n",
            "Iteration 10500: Training Accuracy 0.5781166666666666, Test Accuracy 0.8594 and Training loss 0.10271369705801113\n",
            "Iteration 10600: Training Accuracy 0.5573666666666667, Test Accuracy 0.8364 and Training loss 0.10041455237344231\n",
            "Iteration 10700: Training Accuracy 0.5482166666666667, Test Accuracy 0.8291 and Training loss 0.10018126269648957\n",
            "Iteration 10800: Training Accuracy 0.5514666666666667, Test Accuracy 0.8363 and Training loss 0.09953620292121264\n",
            "Iteration 10900: Training Accuracy 0.5466, Test Accuracy 0.8349 and Training loss 0.09896172512509434\n",
            "Iteration 11000: Training Accuracy 0.5598666666666666, Test Accuracy 0.8539 and Training loss 0.09826211891323312\n",
            "Iteration 11100: Training Accuracy 0.5444166666666667, Test Accuracy 0.825 and Training loss 0.09839897599773914\n",
            "Iteration 11200: Training Accuracy 0.5588666666666666, Test Accuracy 0.8425 and Training loss 0.09700902667095287\n",
            "Iteration 11300: Training Accuracy 0.5517833333333333, Test Accuracy 0.8283 and Training loss 0.0966661845870572\n",
            "Iteration 11400: Training Accuracy 0.5591166666666667, Test Accuracy 0.8323 and Training loss 0.09598044978650738\n",
            "Iteration 11500: Training Accuracy 0.5655, Test Accuracy 0.8441 and Training loss 0.0955408641594279\n",
            "Iteration 11600: Training Accuracy 0.55715, Test Accuracy 0.8424 and Training loss 0.09485910485803435\n",
            "Iteration 11700: Training Accuracy 0.56855, Test Accuracy 0.8518 and Training loss 0.09430750178377263\n",
            "Iteration 11800: Training Accuracy 0.5517166666666666, Test Accuracy 0.8387 and Training loss 0.09408712658952675\n",
            "Iteration 11900: Training Accuracy 0.5705, Test Accuracy 0.8571 and Training loss 0.09345211636325088\n",
            "Iteration 12000: Training Accuracy 0.5477833333333333, Test Accuracy 0.835 and Training loss 0.09321611658653288\n",
            "Iteration 12100: Training Accuracy 0.5622166666666667, Test Accuracy 0.8401 and Training loss 0.09207344904835568\n",
            "Iteration 12200: Training Accuracy 0.5751833333333334, Test Accuracy 0.8594 and Training loss 0.09175127288399992\n",
            "Iteration 12300: Training Accuracy 0.5525, Test Accuracy 0.848 and Training loss 0.09194427486188955\n",
            "Iteration 12400: Training Accuracy 0.5684333333333333, Test Accuracy 0.8624 and Training loss 0.09039752737395021\n",
            "Iteration 12500: Training Accuracy 0.5559, Test Accuracy 0.8583 and Training loss 0.09022959777892799\n",
            "Iteration 12600: Training Accuracy 0.5619166666666666, Test Accuracy 0.8715 and Training loss 0.08961630208577337\n",
            "Iteration 12700: Training Accuracy 0.5675833333333333, Test Accuracy 0.8723 and Training loss 0.08904214937410383\n",
            "Iteration 12800: Training Accuracy 0.57125, Test Accuracy 0.8749 and Training loss 0.08857952701127778\n",
            "Iteration 12900: Training Accuracy 0.5707, Test Accuracy 0.8757 and Training loss 0.08809587273071313\n",
            "Iteration 13000: Training Accuracy 0.56575, Test Accuracy 0.8698 and Training loss 0.08751334744166894\n",
            "Iteration 13100: Training Accuracy 0.59175, Test Accuracy 0.8837 and Training loss 0.08754298574417563\n",
            "Iteration 13200: Training Accuracy 0.5647666666666666, Test Accuracy 0.8593 and Training loss 0.08677350208102423\n",
            "Iteration 13300: Training Accuracy 0.5862333333333334, Test Accuracy 0.8721 and Training loss 0.08626443007293189\n",
            "Iteration 13400: Training Accuracy 0.5839833333333333, Test Accuracy 0.8769 and Training loss 0.08574736884983981\n",
            "Iteration 13500: Training Accuracy 0.5809, Test Accuracy 0.8768 and Training loss 0.08532514585377203\n",
            "Iteration 13600: Training Accuracy 0.5886166666666667, Test Accuracy 0.8784 and Training loss 0.0848481354078437\n",
            "Iteration 13700: Training Accuracy 0.5796666666666667, Test Accuracy 0.8812 and Training loss 0.08422335591722438\n",
            "Iteration 13800: Training Accuracy 0.5617, Test Accuracy 0.8657 and Training loss 0.08427431699031059\n",
            "Iteration 13900: Training Accuracy 0.5835166666666667, Test Accuracy 0.8829 and Training loss 0.0833925733692901\n",
            "Iteration 14000: Training Accuracy 0.5835833333333333, Test Accuracy 0.8881 and Training loss 0.08323956109872235\n",
            "Iteration 14100: Training Accuracy 0.5912333333333334, Test Accuracy 0.8885 and Training loss 0.08267059666337029\n",
            "Iteration 14200: Training Accuracy 0.6006, Test Accuracy 0.8919 and Training loss 0.08269136203257253\n",
            "Iteration 14300: Training Accuracy 0.5634, Test Accuracy 0.8819 and Training loss 0.08264720405262121\n",
            "Iteration 14400: Training Accuracy 0.60335, Test Accuracy 0.901 and Training loss 0.08194087530687831\n",
            "Iteration 14500: Training Accuracy 0.5822833333333334, Test Accuracy 0.8893 and Training loss 0.0809824642399363\n",
            "Iteration 14600: Training Accuracy 0.6039166666666667, Test Accuracy 0.8961 and Training loss 0.08122450835905391\n",
            "Iteration 14700: Training Accuracy 0.5768833333333333, Test Accuracy 0.887 and Training loss 0.07989533807853864\n",
            "Iteration 14800: Training Accuracy 0.57365, Test Accuracy 0.8861 and Training loss 0.079534964303635\n",
            "Iteration 14900: Training Accuracy 0.5643833333333333, Test Accuracy 0.8808 and Training loss 0.07984811881146679\n",
            "Iteration 15000: Training Accuracy 0.5726, Test Accuracy 0.8846 and Training loss 0.0787663140714077\n",
            "Iteration 15100: Training Accuracy 0.5957333333333333, Test Accuracy 0.8981 and Training loss 0.07857678022890557\n",
            "Iteration 15200: Training Accuracy 0.5789333333333333, Test Accuracy 0.8873 and Training loss 0.07792211484165214\n",
            "Iteration 15300: Training Accuracy 0.5728666666666666, Test Accuracy 0.8892 and Training loss 0.07782605126639561\n",
            "Iteration 15400: Training Accuracy 0.5821333333333333, Test Accuracy 0.8883 and Training loss 0.07729751119257239\n",
            "Iteration 15500: Training Accuracy 0.6119, Test Accuracy 0.9002 and Training loss 0.0774260586332631\n",
            "Iteration 15600: Training Accuracy 0.5756333333333333, Test Accuracy 0.8821 and Training loss 0.07651571566228321\n",
            "Iteration 15700: Training Accuracy 0.5912166666666666, Test Accuracy 0.8843 and Training loss 0.07590502351058356\n",
            "Iteration 15800: Training Accuracy 0.6021166666666666, Test Accuracy 0.8856 and Training loss 0.07627182493166286\n",
            "Iteration 15900: Training Accuracy 0.5940333333333333, Test Accuracy 0.8853 and Training loss 0.07551953892084846\n",
            "Iteration 16000: Training Accuracy 0.5712833333333334, Test Accuracy 0.8727 and Training loss 0.07547511483542596\n",
            "Iteration 16100: Training Accuracy 0.6032833333333333, Test Accuracy 0.8897 and Training loss 0.07520744198886098\n",
            "Iteration 16200: Training Accuracy 0.6050833333333333, Test Accuracy 0.8931 and Training loss 0.07435298714190614\n",
            "Iteration 16300: Training Accuracy 0.5975833333333334, Test Accuracy 0.8898 and Training loss 0.07390313855440242\n",
            "Iteration 16400: Training Accuracy 0.5982833333333333, Test Accuracy 0.8884 and Training loss 0.07356629048553999\n",
            "Iteration 16500: Training Accuracy 0.5974, Test Accuracy 0.8829 and Training loss 0.07328742399579817\n",
            "Iteration 16600: Training Accuracy 0.6069666666666667, Test Accuracy 0.8828 and Training loss 0.07343581811992651\n",
            "Iteration 16700: Training Accuracy 0.5919333333333333, Test Accuracy 0.8822 and Training loss 0.07286660840276878\n",
            "Iteration 16800: Training Accuracy 0.5890833333333333, Test Accuracy 0.8811 and Training loss 0.07264285762893771\n",
            "Iteration 16900: Training Accuracy 0.5861833333333333, Test Accuracy 0.8844 and Training loss 0.07210168324526339\n",
            "Iteration 17000: Training Accuracy 0.5766, Test Accuracy 0.8863 and Training loss 0.0722899552456349\n",
            "Iteration 17100: Training Accuracy 0.5827, Test Accuracy 0.8813 and Training loss 0.0717930115716312\n",
            "Iteration 17200: Training Accuracy 0.6164666666666667, Test Accuracy 0.8956 and Training loss 0.07168017749024677\n",
            "Iteration 17300: Training Accuracy 0.60795, Test Accuracy 0.8939 and Training loss 0.07097521142997318\n",
            "Iteration 17400: Training Accuracy 0.5900666666666666, Test Accuracy 0.8883 and Training loss 0.07076724029314604\n",
            "Iteration 17500: Training Accuracy 0.6111166666666666, Test Accuracy 0.9004 and Training loss 0.07061175010282239\n",
            "Iteration 17600: Training Accuracy 0.613, Test Accuracy 0.9024 and Training loss 0.07051108234914526\n",
            "Iteration 17700: Training Accuracy 0.5851166666666666, Test Accuracy 0.8837 and Training loss 0.06996162967951272\n",
            "Iteration 17800: Training Accuracy 0.5898833333333333, Test Accuracy 0.8954 and Training loss 0.06970312037796485\n",
            "Iteration 17900: Training Accuracy 0.6112833333333333, Test Accuracy 0.9036 and Training loss 0.06997577110217526\n",
            "Iteration 18000: Training Accuracy 0.60435, Test Accuracy 0.9015 and Training loss 0.06931261520766516\n",
            "Iteration 18100: Training Accuracy 0.5865333333333334, Test Accuracy 0.8957 and Training loss 0.06893256890459021\n",
            "Iteration 18200: Training Accuracy 0.60035, Test Accuracy 0.9003 and Training loss 0.06853564211136938\n",
            "Iteration 18300: Training Accuracy 0.6032333333333333, Test Accuracy 0.9023 and Training loss 0.06840687746412269\n",
            "Iteration 18400: Training Accuracy 0.5952, Test Accuracy 0.8992 and Training loss 0.06807198043898693\n",
            "Iteration 18500: Training Accuracy 0.5991, Test Accuracy 0.899 and Training loss 0.06800070434608939\n",
            "Iteration 18600: Training Accuracy 0.5966666666666667, Test Accuracy 0.8985 and Training loss 0.06779888781458975\n",
            "Iteration 18700: Training Accuracy 0.6136833333333334, Test Accuracy 0.902 and Training loss 0.0674150926722282\n",
            "Iteration 18800: Training Accuracy 0.6430166666666667, Test Accuracy 0.909 and Training loss 0.06814293815452686\n",
            "Iteration 18900: Training Accuracy 0.59805, Test Accuracy 0.8975 and Training loss 0.06721500058086159\n",
            "Iteration 19000: Training Accuracy 0.6239166666666667, Test Accuracy 0.9038 and Training loss 0.06711914344516567\n",
            "Iteration 19100: Training Accuracy 0.5698166666666666, Test Accuracy 0.8714 and Training loss 0.06788442056011794\n",
            "Iteration 19200: Training Accuracy 0.59955, Test Accuracy 0.8895 and Training loss 0.06618010048820529\n",
            "Iteration 19300: Training Accuracy 0.6155333333333334, Test Accuracy 0.895 and Training loss 0.06601210533499761\n",
            "Iteration 19400: Training Accuracy 0.5952333333333333, Test Accuracy 0.8895 and Training loss 0.06593669884593484\n",
            "Iteration 19500: Training Accuracy 0.6368833333333334, Test Accuracy 0.9035 and Training loss 0.0666221535647309\n",
            "Iteration 19600: Training Accuracy 0.60725, Test Accuracy 0.8924 and Training loss 0.06543582826527503\n",
            "Iteration 19700: Training Accuracy 0.6219166666666667, Test Accuracy 0.9025 and Training loss 0.06512883377683028\n",
            "Iteration 19800: Training Accuracy 0.6073166666666666, Test Accuracy 0.8946 and Training loss 0.0649731927115883\n",
            "Iteration 19900: Training Accuracy 0.6248, Test Accuracy 0.9018 and Training loss 0.06477674498096175\n",
            "Iteration 20000: Training Accuracy 0.5965333333333334, Test Accuracy 0.8786 and Training loss 0.06479954117273642\n",
            "Iteration 20100: Training Accuracy 0.6134833333333334, Test Accuracy 0.8901 and Training loss 0.06440017365996711\n",
            "Iteration 20200: Training Accuracy 0.6414, Test Accuracy 0.9105 and Training loss 0.06488907701616752\n",
            "Iteration 20300: Training Accuracy 0.6165666666666667, Test Accuracy 0.8963 and Training loss 0.06407584016121162\n",
            "Iteration 20400: Training Accuracy 0.6153, Test Accuracy 0.9016 and Training loss 0.06368191289196673\n",
            "Iteration 20500: Training Accuracy 0.6117, Test Accuracy 0.8974 and Training loss 0.06354003912964667\n",
            "Iteration 20600: Training Accuracy 0.61355, Test Accuracy 0.9053 and Training loss 0.06338842795888827\n",
            "Iteration 20700: Training Accuracy 0.6301166666666667, Test Accuracy 0.9108 and Training loss 0.06336242704033701\n",
            "Iteration 20800: Training Accuracy 0.6063666666666667, Test Accuracy 0.9003 and Training loss 0.06319011114391278\n",
            "Iteration 20900: Training Accuracy 0.6126333333333334, Test Accuracy 0.9032 and Training loss 0.062950072565556\n",
            "Iteration 21000: Training Accuracy 0.62385, Test Accuracy 0.9122 and Training loss 0.06282160763273653\n",
            "Iteration 21100: Training Accuracy 0.64955, Test Accuracy 0.9126 and Training loss 0.06415537297824028\n",
            "Iteration 21200: Training Accuracy 0.6072333333333333, Test Accuracy 0.9034 and Training loss 0.06246929076646858\n",
            "Iteration 21300: Training Accuracy 0.6019666666666666, Test Accuracy 0.8982 and Training loss 0.06213819013025998\n",
            "Iteration 21400: Training Accuracy 0.6058, Test Accuracy 0.9007 and Training loss 0.061927099619783835\n",
            "Iteration 21500: Training Accuracy 0.5833166666666667, Test Accuracy 0.886 and Training loss 0.06286788090936242\n",
            "Iteration 21600: Training Accuracy 0.6033333333333334, Test Accuracy 0.9014 and Training loss 0.06162060710712729\n",
            "Iteration 21700: Training Accuracy 0.6131, Test Accuracy 0.9059 and Training loss 0.0617776697439159\n",
            "Iteration 21800: Training Accuracy 0.5993833333333334, Test Accuracy 0.9003 and Training loss 0.06166194742976135\n",
            "Iteration 21900: Training Accuracy 0.6058, Test Accuracy 0.8959 and Training loss 0.06133827019360907\n",
            "Iteration 22000: Training Accuracy 0.6307833333333334, Test Accuracy 0.9078 and Training loss 0.061237371638734044\n",
            "Iteration 22100: Training Accuracy 0.6042833333333333, Test Accuracy 0.8936 and Training loss 0.06111671585738789\n",
            "Iteration 22200: Training Accuracy 0.6021333333333333, Test Accuracy 0.8937 and Training loss 0.06109055552834898\n",
            "Iteration 22300: Training Accuracy 0.62585, Test Accuracy 0.9064 and Training loss 0.06065021985127963\n",
            "Iteration 22400: Training Accuracy 0.6327166666666667, Test Accuracy 0.9088 and Training loss 0.06073382616742909\n",
            "Iteration 22500: Training Accuracy 0.6270833333333333, Test Accuracy 0.9093 and Training loss 0.060359136173806484\n",
            "Iteration 22600: Training Accuracy 0.6177, Test Accuracy 0.9004 and Training loss 0.06022817984295104\n",
            "Iteration 22700: Training Accuracy 0.6261333333333333, Test Accuracy 0.9039 and Training loss 0.060266009375809365\n",
            "Iteration 22800: Training Accuracy 0.6188166666666667, Test Accuracy 0.9018 and Training loss 0.0599779382230767\n",
            "Iteration 22900: Training Accuracy 0.6436833333333334, Test Accuracy 0.9171 and Training loss 0.0601615616752182\n",
            "Iteration 23000: Training Accuracy 0.63505, Test Accuracy 0.9127 and Training loss 0.05980000448499257\n",
            "Iteration 23100: Training Accuracy 0.6298166666666667, Test Accuracy 0.9088 and Training loss 0.05986760929239329\n",
            "Iteration 23200: Training Accuracy 0.6288833333333333, Test Accuracy 0.9114 and Training loss 0.05932576134539931\n",
            "Iteration 23300: Training Accuracy 0.6214833333333334, Test Accuracy 0.9148 and Training loss 0.05937539136942305\n",
            "Iteration 23400: Training Accuracy 0.6088333333333333, Test Accuracy 0.9031 and Training loss 0.059433483296884713\n",
            "Iteration 23500: Training Accuracy 0.6168666666666667, Test Accuracy 0.907 and Training loss 0.058950374001457855\n",
            "Iteration 23600: Training Accuracy 0.63065, Test Accuracy 0.9099 and Training loss 0.05882409827442739\n",
            "Iteration 23700: Training Accuracy 0.6206166666666667, Test Accuracy 0.9075 and Training loss 0.05886943453222158\n",
            "Iteration 23800: Training Accuracy 0.6323166666666666, Test Accuracy 0.9084 and Training loss 0.05857967792595194\n",
            "Iteration 23900: Training Accuracy 0.6051, Test Accuracy 0.9059 and Training loss 0.05888649977027588\n",
            "Iteration 24000: Training Accuracy 0.62115, Test Accuracy 0.9092 and Training loss 0.05845322910572748\n",
            "Iteration 24100: Training Accuracy 0.6393, Test Accuracy 0.9144 and Training loss 0.0584136234976717\n",
            "Iteration 24200: Training Accuracy 0.6356833333333334, Test Accuracy 0.9146 and Training loss 0.058214408606711\n",
            "Iteration 24300: Training Accuracy 0.6115166666666667, Test Accuracy 0.8983 and Training loss 0.0583554105664172\n",
            "Iteration 24400: Training Accuracy 0.63645, Test Accuracy 0.9124 and Training loss 0.058109458125720936\n",
            "Iteration 24500: Training Accuracy 0.6379666666666667, Test Accuracy 0.912 and Training loss 0.05810057536980829\n",
            "Iteration 24600: Training Accuracy 0.6355666666666666, Test Accuracy 0.9098 and Training loss 0.05765841991453825\n",
            "Iteration 24700: Training Accuracy 0.6193, Test Accuracy 0.909 and Training loss 0.057657520391348166\n",
            "Iteration 24800: Training Accuracy 0.6237666666666667, Test Accuracy 0.9085 and Training loss 0.05762232874600461\n",
            "Iteration 24900: Training Accuracy 0.6201, Test Accuracy 0.9081 and Training loss 0.05758483236167879\n",
            "Iteration 25000: Training Accuracy 0.6276666666666667, Test Accuracy 0.9093 and Training loss 0.05708960323350472\n",
            "Iteration 25100: Training Accuracy 0.6229666666666667, Test Accuracy 0.908 and Training loss 0.057358457147760986\n",
            "Iteration 25200: Training Accuracy 0.62125, Test Accuracy 0.905 and Training loss 0.057700437593462696\n",
            "Iteration 25300: Training Accuracy 0.6141, Test Accuracy 0.9014 and Training loss 0.05705383068631341\n",
            "Iteration 25400: Training Accuracy 0.6384166666666666, Test Accuracy 0.9096 and Training loss 0.0567644468861497\n",
            "Iteration 25500: Training Accuracy 0.6493, Test Accuracy 0.9139 and Training loss 0.05694716871584545\n",
            "Iteration 25600: Training Accuracy 0.6365, Test Accuracy 0.9081 and Training loss 0.056539551168095774\n",
            "Iteration 25700: Training Accuracy 0.6452833333333333, Test Accuracy 0.9099 and Training loss 0.05649495979051405\n",
            "Iteration 25800: Training Accuracy 0.64975, Test Accuracy 0.91 and Training loss 0.056297956586572766\n",
            "Iteration 25900: Training Accuracy 0.6213166666666666, Test Accuracy 0.8955 and Training loss 0.05612231081378255\n",
            "Iteration 26000: Training Accuracy 0.6515, Test Accuracy 0.9008 and Training loss 0.05641036447191692\n",
            "Iteration 26100: Training Accuracy 0.66565, Test Accuracy 0.9143 and Training loss 0.0569224336448588\n",
            "Iteration 26200: Training Accuracy 0.6349333333333333, Test Accuracy 0.9004 and Training loss 0.0558720989857562\n",
            "Iteration 26300: Training Accuracy 0.6304, Test Accuracy 0.8994 and Training loss 0.055663966521025225\n",
            "Iteration 26400: Training Accuracy 0.6235166666666667, Test Accuracy 0.8907 and Training loss 0.05572224486531418\n",
            "Iteration 26500: Training Accuracy 0.6428333333333334, Test Accuracy 0.9018 and Training loss 0.055390699015456686\n",
            "Iteration 26600: Training Accuracy 0.66085, Test Accuracy 0.9093 and Training loss 0.05579075011037291\n",
            "Iteration 26700: Training Accuracy 0.6310666666666667, Test Accuracy 0.8927 and Training loss 0.055162637313538404\n",
            "Iteration 26800: Training Accuracy 0.6559833333333334, Test Accuracy 0.9036 and Training loss 0.05563695056879003\n",
            "Iteration 26900: Training Accuracy 0.6273333333333333, Test Accuracy 0.8867 and Training loss 0.05515181345746633\n",
            "Iteration 27000: Training Accuracy 0.6101, Test Accuracy 0.8875 and Training loss 0.05587099071166451\n",
            "Iteration 27100: Training Accuracy 0.6297166666666667, Test Accuracy 0.9008 and Training loss 0.05482495444414129\n",
            "Iteration 27200: Training Accuracy 0.6413, Test Accuracy 0.9107 and Training loss 0.05479738810457707\n",
            "Iteration 27300: Training Accuracy 0.63415, Test Accuracy 0.9007 and Training loss 0.054653162345563604\n",
            "Iteration 27400: Training Accuracy 0.6401666666666667, Test Accuracy 0.9039 and Training loss 0.05463724883318093\n",
            "Iteration 27500: Training Accuracy 0.6416333333333334, Test Accuracy 0.8977 and Training loss 0.05445627624631344\n",
            "Iteration 27600: Training Accuracy 0.6420833333333333, Test Accuracy 0.9028 and Training loss 0.05440519204341526\n",
            "Iteration 27700: Training Accuracy 0.6192166666666666, Test Accuracy 0.8957 and Training loss 0.054773407812505746\n",
            "Iteration 27800: Training Accuracy 0.6373166666666666, Test Accuracy 0.8997 and Training loss 0.05421011891938138\n",
            "Iteration 27900: Training Accuracy 0.6347166666666667, Test Accuracy 0.9042 and Training loss 0.05413126767637327\n",
            "Iteration 28000: Training Accuracy 0.6265333333333334, Test Accuracy 0.9 and Training loss 0.05397465965437751\n",
            "Iteration 28100: Training Accuracy 0.6300833333333333, Test Accuracy 0.8921 and Training loss 0.053989574518926726\n",
            "Iteration 28200: Training Accuracy 0.6398666666666667, Test Accuracy 0.8993 and Training loss 0.05392371304067418\n",
            "Iteration 28300: Training Accuracy 0.6080166666666666, Test Accuracy 0.878 and Training loss 0.05433679595062792\n",
            "Iteration 28400: Training Accuracy 0.6357666666666667, Test Accuracy 0.8936 and Training loss 0.053614735970195816\n",
            "Iteration 28500: Training Accuracy 0.6252666666666666, Test Accuracy 0.8903 and Training loss 0.05353538307507236\n",
            "Iteration 28600: Training Accuracy 0.6140333333333333, Test Accuracy 0.8808 and Training loss 0.053787264831734176\n",
            "Iteration 28700: Training Accuracy 0.6201333333333333, Test Accuracy 0.8797 and Training loss 0.05367037578687191\n",
            "Iteration 28800: Training Accuracy 0.6264, Test Accuracy 0.889 and Training loss 0.05334279765302966\n",
            "Iteration 28900: Training Accuracy 0.6301666666666667, Test Accuracy 0.8923 and Training loss 0.05333274523427531\n",
            "Iteration 29000: Training Accuracy 0.6538166666666667, Test Accuracy 0.9068 and Training loss 0.05337614877974836\n",
            "Iteration 29100: Training Accuracy 0.6084833333333334, Test Accuracy 0.8787 and Training loss 0.05373097557786951\n",
            "Iteration 29200: Training Accuracy 0.64675, Test Accuracy 0.9021 and Training loss 0.052820207529893866\n",
            "Iteration 29300: Training Accuracy 0.6441166666666667, Test Accuracy 0.9041 and Training loss 0.05291367360886012\n",
            "Iteration 29400: Training Accuracy 0.6678666666666667, Test Accuracy 0.9104 and Training loss 0.053377189069142406\n",
            "Iteration 29500: Training Accuracy 0.6405666666666666, Test Accuracy 0.9004 and Training loss 0.05262160469446336\n",
            "Iteration 29600: Training Accuracy 0.6372, Test Accuracy 0.8953 and Training loss 0.05251382182787039\n",
            "Iteration 29700: Training Accuracy 0.6309666666666667, Test Accuracy 0.8862 and Training loss 0.05250785396145946\n",
            "Iteration 29800: Training Accuracy 0.6424, Test Accuracy 0.894 and Training loss 0.052567980625513\n",
            "Iteration 29900: Training Accuracy 0.6316666666666667, Test Accuracy 0.8925 and Training loss 0.0523370503773571\n",
            "Iteration 30000: Training Accuracy 0.6408166666666667, Test Accuracy 0.8973 and Training loss 0.05237171818076225\n",
            "Iteration 30100: Training Accuracy 0.6471, Test Accuracy 0.9025 and Training loss 0.052050562531461037\n",
            "Iteration 30200: Training Accuracy 0.6461333333333333, Test Accuracy 0.899 and Training loss 0.05204347091038873\n",
            "Iteration 30300: Training Accuracy 0.6263333333333333, Test Accuracy 0.8877 and Training loss 0.05203677452971962\n",
            "Iteration 30400: Training Accuracy 0.6556166666666666, Test Accuracy 0.9019 and Training loss 0.052052178303125\n",
            "Iteration 30500: Training Accuracy 0.6604, Test Accuracy 0.9007 and Training loss 0.05201365845761466\n",
            "Iteration 30600: Training Accuracy 0.6628666666666667, Test Accuracy 0.9113 and Training loss 0.05199010582486536\n",
            "Iteration 30700: Training Accuracy 0.6381333333333333, Test Accuracy 0.8981 and Training loss 0.051547203499467606\n",
            "Iteration 30800: Training Accuracy 0.6589666666666667, Test Accuracy 0.9131 and Training loss 0.05169710611124421\n",
            "Iteration 30900: Training Accuracy 0.6192833333333333, Test Accuracy 0.8972 and Training loss 0.05243523137983996\n",
            "Iteration 31000: Training Accuracy 0.62355, Test Accuracy 0.892 and Training loss 0.05181825539791193\n",
            "Iteration 31100: Training Accuracy 0.6300333333333333, Test Accuracy 0.8906 and Training loss 0.05154974496714172\n",
            "Iteration 31200: Training Accuracy 0.63335, Test Accuracy 0.8865 and Training loss 0.05147824369379712\n",
            "Iteration 31300: Training Accuracy 0.63925, Test Accuracy 0.8941 and Training loss 0.051486793074934235\n",
            "Iteration 31400: Training Accuracy 0.62725, Test Accuracy 0.8838 and Training loss 0.051481930422577926\n",
            "Iteration 31500: Training Accuracy 0.6320333333333333, Test Accuracy 0.8828 and Training loss 0.05155942992181065\n",
            "Iteration 31600: Training Accuracy 0.6777166666666666, Test Accuracy 0.905 and Training loss 0.05186496262498744\n",
            "Iteration 31700: Training Accuracy 0.6485666666666666, Test Accuracy 0.892 and Training loss 0.05099152167810766\n",
            "Iteration 31800: Training Accuracy 0.66285, Test Accuracy 0.8997 and Training loss 0.05085727529986574\n",
            "Iteration 31900: Training Accuracy 0.6596666666666666, Test Accuracy 0.9017 and Training loss 0.05078593321100405\n",
            "Iteration 32000: Training Accuracy 0.6360166666666667, Test Accuracy 0.8931 and Training loss 0.05070083997870447\n",
            "Iteration 32100: Training Accuracy 0.65295, Test Accuracy 0.8962 and Training loss 0.05069607015104071\n",
            "Iteration 32200: Training Accuracy 0.6547666666666667, Test Accuracy 0.8988 and Training loss 0.05061843440402001\n",
            "Iteration 32300: Training Accuracy 0.6440166666666667, Test Accuracy 0.8924 and Training loss 0.0506050130020843\n",
            "Iteration 32400: Training Accuracy 0.6369, Test Accuracy 0.8909 and Training loss 0.050373012321152696\n",
            "Iteration 32500: Training Accuracy 0.6138833333333333, Test Accuracy 0.8777 and Training loss 0.05106089288232158\n",
            "Iteration 32600: Training Accuracy 0.6418833333333334, Test Accuracy 0.8902 and Training loss 0.050167909164680946\n",
            "Iteration 32700: Training Accuracy 0.6713, Test Accuracy 0.9048 and Training loss 0.050634034841288623\n",
            "Iteration 32800: Training Accuracy 0.6407, Test Accuracy 0.8924 and Training loss 0.050117303346159436\n",
            "Iteration 32900: Training Accuracy 0.6335, Test Accuracy 0.8845 and Training loss 0.05024161412269841\n",
            "Iteration 33000: Training Accuracy 0.66615, Test Accuracy 0.8958 and Training loss 0.05030951354951267\n",
            "Iteration 33100: Training Accuracy 0.6398833333333334, Test Accuracy 0.8905 and Training loss 0.04989583323068663\n",
            "Iteration 33200: Training Accuracy 0.6646666666666666, Test Accuracy 0.895 and Training loss 0.050014848748940535\n",
            "Iteration 33300: Training Accuracy 0.6276, Test Accuracy 0.8827 and Training loss 0.050502948452689794\n",
            "Iteration 33400: Training Accuracy 0.6751166666666667, Test Accuracy 0.9071 and Training loss 0.05012599512290084\n",
            "Iteration 33500: Training Accuracy 0.6616333333333333, Test Accuracy 0.9015 and Training loss 0.04977788787585305\n",
            "Iteration 33600: Training Accuracy 0.6576666666666666, Test Accuracy 0.8969 and Training loss 0.049794636970740214\n",
            "Iteration 33700: Training Accuracy 0.6625833333333333, Test Accuracy 0.898 and Training loss 0.04949812833085633\n",
            "Iteration 33800: Training Accuracy 0.6660166666666667, Test Accuracy 0.8984 and Training loss 0.04948440956916498\n",
            "Iteration 33900: Training Accuracy 0.6452666666666667, Test Accuracy 0.8924 and Training loss 0.04946399474943993\n",
            "Iteration 34000: Training Accuracy 0.6438666666666667, Test Accuracy 0.8893 and Training loss 0.04941779033786296\n",
            "Iteration 34100: Training Accuracy 0.6710666666666667, Test Accuracy 0.9035 and Training loss 0.050008748323291975\n",
            "Iteration 34200: Training Accuracy 0.66285, Test Accuracy 0.9076 and Training loss 0.049280200484544366\n",
            "Iteration 34300: Training Accuracy 0.66725, Test Accuracy 0.9059 and Training loss 0.04923616090814896\n",
            "Iteration 34400: Training Accuracy 0.6587166666666666, Test Accuracy 0.8946 and Training loss 0.04908127980656402\n",
            "Iteration 34500: Training Accuracy 0.6380333333333333, Test Accuracy 0.8892 and Training loss 0.04902243246861426\n",
            "Iteration 34600: Training Accuracy 0.6353833333333333, Test Accuracy 0.8942 and Training loss 0.048906642916749996\n",
            "Iteration 34700: Training Accuracy 0.6063333333333333, Test Accuracy 0.8752 and Training loss 0.05010390990101132\n",
            "Iteration 34800: Training Accuracy 0.6269333333333333, Test Accuracy 0.8797 and Training loss 0.04891886645486274\n",
            "Iteration 34900: Training Accuracy 0.6379, Test Accuracy 0.8798 and Training loss 0.04863020167315159\n",
            "Iteration 35000: Training Accuracy 0.6299333333333333, Test Accuracy 0.8742 and Training loss 0.04918888501650414\n",
            "Iteration 35100: Training Accuracy 0.669, Test Accuracy 0.9013 and Training loss 0.0486940828846562\n",
            "Iteration 35200: Training Accuracy 0.6273666666666666, Test Accuracy 0.8847 and Training loss 0.04863928370550129\n",
            "Iteration 35300: Training Accuracy 0.6158166666666667, Test Accuracy 0.8769 and Training loss 0.04889945187814693\n",
            "Iteration 35400: Training Accuracy 0.6314166666666666, Test Accuracy 0.8866 and Training loss 0.048579266889594096\n",
            "Iteration 35500: Training Accuracy 0.62255, Test Accuracy 0.8884 and Training loss 0.048924392569793786\n",
            "Iteration 35600: Training Accuracy 0.6237666666666667, Test Accuracy 0.8914 and Training loss 0.04851557878666548\n",
            "Iteration 35700: Training Accuracy 0.6648, Test Accuracy 0.9068 and Training loss 0.048252790753513\n",
            "Iteration 35800: Training Accuracy 0.68215, Test Accuracy 0.9157 and Training loss 0.048829595825862764\n",
            "Iteration 35900: Training Accuracy 0.6557, Test Accuracy 0.9039 and Training loss 0.04791472769293051\n",
            "Iteration 36000: Training Accuracy 0.6379166666666667, Test Accuracy 0.8854 and Training loss 0.047850758260308615\n",
            "Iteration 36100: Training Accuracy 0.64865, Test Accuracy 0.889 and Training loss 0.04784233125772631\n",
            "Iteration 36200: Training Accuracy 0.6653833333333333, Test Accuracy 0.9063 and Training loss 0.04779996019482851\n",
            "Iteration 36300: Training Accuracy 0.6417666666666667, Test Accuracy 0.893 and Training loss 0.04779880644097231\n",
            "Iteration 36400: Training Accuracy 0.6883166666666667, Test Accuracy 0.9123 and Training loss 0.048771502861090284\n",
            "Iteration 36500: Training Accuracy 0.6653833333333333, Test Accuracy 0.9101 and Training loss 0.047772559137905284\n",
            "Iteration 36600: Training Accuracy 0.6699833333333334, Test Accuracy 0.9091 and Training loss 0.04806561102336736\n",
            "Iteration 36700: Training Accuracy 0.6501833333333333, Test Accuracy 0.8983 and Training loss 0.047526649552240396\n",
            "Iteration 36800: Training Accuracy 0.6607666666666666, Test Accuracy 0.9012 and Training loss 0.04748152616729479\n",
            "Iteration 36900: Training Accuracy 0.6482166666666667, Test Accuracy 0.898 and Training loss 0.04746256849790382\n",
            "Iteration 37000: Training Accuracy 0.6661, Test Accuracy 0.9059 and Training loss 0.04766480839056223\n",
            "Iteration 37100: Training Accuracy 0.6434, Test Accuracy 0.8898 and Training loss 0.04730009135208943\n",
            "Iteration 37200: Training Accuracy 0.6487166666666667, Test Accuracy 0.8944 and Training loss 0.04731942025310686\n",
            "Iteration 37300: Training Accuracy 0.6727333333333333, Test Accuracy 0.908 and Training loss 0.0477088749852073\n",
            "Iteration 37400: Training Accuracy 0.6493833333333333, Test Accuracy 0.8924 and Training loss 0.047214981724135616\n",
            "Iteration 37500: Training Accuracy 0.63635, Test Accuracy 0.8911 and Training loss 0.04755302848443616\n",
            "Iteration 37600: Training Accuracy 0.6627333333333333, Test Accuracy 0.8949 and Training loss 0.04708586693818979\n",
            "Iteration 37700: Training Accuracy 0.6679833333333334, Test Accuracy 0.8947 and Training loss 0.04730920057970227\n",
            "Iteration 37800: Training Accuracy 0.6509666666666667, Test Accuracy 0.8949 and Training loss 0.046887779315045314\n",
            "Iteration 37900: Training Accuracy 0.6184833333333334, Test Accuracy 0.876 and Training loss 0.047737000044455885\n",
            "Iteration 38000: Training Accuracy 0.6367666666666667, Test Accuracy 0.8869 and Training loss 0.04678588834896547\n",
            "Iteration 38100: Training Accuracy 0.6475, Test Accuracy 0.8895 and Training loss 0.046632488482824114\n",
            "Iteration 38200: Training Accuracy 0.68945, Test Accuracy 0.9105 and Training loss 0.04748748349467542\n",
            "Iteration 38300: Training Accuracy 0.63325, Test Accuracy 0.8773 and Training loss 0.04668165767274567\n",
            "Iteration 38400: Training Accuracy 0.6655, Test Accuracy 0.8902 and Training loss 0.0469222749118188\n",
            "Iteration 38500: Training Accuracy 0.6555333333333333, Test Accuracy 0.8835 and Training loss 0.04652693189380803\n",
            "Iteration 38600: Training Accuracy 0.6751166666666667, Test Accuracy 0.8994 and Training loss 0.04680367842771384\n",
            "Iteration 38700: Training Accuracy 0.6364, Test Accuracy 0.8884 and Training loss 0.0469005479251352\n",
            "Iteration 38800: Training Accuracy 0.6302166666666666, Test Accuracy 0.8719 and Training loss 0.046673585256781315\n",
            "Iteration 38900: Training Accuracy 0.6332333333333333, Test Accuracy 0.8704 and Training loss 0.046661231024739014\n",
            "Iteration 39000: Training Accuracy 0.7012833333333334, Test Accuracy 0.9084 and Training loss 0.04767857603662731\n",
            "Iteration 39100: Training Accuracy 0.6385333333333333, Test Accuracy 0.8775 and Training loss 0.04636383034138968\n",
            "Iteration 39200: Training Accuracy 0.6506833333333333, Test Accuracy 0.8869 and Training loss 0.0460372204904097\n",
            "Iteration 39300: Training Accuracy 0.6536333333333333, Test Accuracy 0.888 and Training loss 0.04610586911282856\n",
            "Iteration 39400: Training Accuracy 0.64865, Test Accuracy 0.8866 and Training loss 0.04605991175901621\n",
            "Iteration 39500: Training Accuracy 0.65715, Test Accuracy 0.8991 and Training loss 0.04593879977787264\n",
            "Iteration 39600: Training Accuracy 0.66645, Test Accuracy 0.9024 and Training loss 0.04594769458047675\n",
            "Iteration 39700: Training Accuracy 0.66345, Test Accuracy 0.8995 and Training loss 0.04599057447445792\n",
            "Iteration 39800: Training Accuracy 0.6667833333333333, Test Accuracy 0.899 and Training loss 0.04588251231258347\n",
            "Iteration 39900: Training Accuracy 0.6606, Test Accuracy 0.9001 and Training loss 0.04583175571568631\n",
            "Iteration 40000: Training Accuracy 0.6590833333333334, Test Accuracy 0.8946 and Training loss 0.04590199473012144\n",
            "Iteration 40100: Training Accuracy 0.6385333333333333, Test Accuracy 0.8904 and Training loss 0.045708641508048396\n",
            "Iteration 40200: Training Accuracy 0.6624666666666666, Test Accuracy 0.9051 and Training loss 0.0456029096935114\n",
            "Iteration 40300: Training Accuracy 0.6495166666666666, Test Accuracy 0.8968 and Training loss 0.045638690012076995\n",
            "Iteration 40400: Training Accuracy 0.6385333333333333, Test Accuracy 0.8924 and Training loss 0.045605497495585096\n",
            "Iteration 40500: Training Accuracy 0.64025, Test Accuracy 0.8984 and Training loss 0.04556966748253243\n",
            "Iteration 40600: Training Accuracy 0.65235, Test Accuracy 0.9024 and Training loss 0.04533783383492596\n",
            "Iteration 40700: Training Accuracy 0.6592, Test Accuracy 0.9024 and Training loss 0.04531700016891463\n",
            "Iteration 40800: Training Accuracy 0.6718333333333333, Test Accuracy 0.9089 and Training loss 0.045377858339121196\n",
            "Iteration 40900: Training Accuracy 0.6560166666666667, Test Accuracy 0.891 and Training loss 0.04518988113824921\n",
            "Iteration 41000: Training Accuracy 0.6867166666666666, Test Accuracy 0.8964 and Training loss 0.04555591782755417\n",
            "Iteration 41100: Training Accuracy 0.6393833333333333, Test Accuracy 0.879 and Training loss 0.04546335971313965\n",
            "Iteration 41200: Training Accuracy 0.6693833333333333, Test Accuracy 0.8913 and Training loss 0.04510340235665552\n",
            "Iteration 41300: Training Accuracy 0.6632333333333333, Test Accuracy 0.8937 and Training loss 0.04509213769649486\n",
            "Iteration 41400: Training Accuracy 0.6325166666666666, Test Accuracy 0.875 and Training loss 0.04536513531158609\n",
            "Iteration 41500: Training Accuracy 0.6525666666666666, Test Accuracy 0.8898 and Training loss 0.04500621213347892\n",
            "Iteration 41600: Training Accuracy 0.6339333333333333, Test Accuracy 0.8762 and Training loss 0.04504517089584815\n",
            "Iteration 41700: Training Accuracy 0.662, Test Accuracy 0.8913 and Training loss 0.044824805984242266\n",
            "Iteration 41800: Training Accuracy 0.6737166666666666, Test Accuracy 0.894 and Training loss 0.04509389598131919\n",
            "Iteration 41900: Training Accuracy 0.6646333333333333, Test Accuracy 0.8975 and Training loss 0.04485973987810675\n",
            "Iteration 42000: Training Accuracy 0.67455, Test Accuracy 0.8967 and Training loss 0.0448169746545117\n",
            "Iteration 42100: Training Accuracy 0.6672833333333333, Test Accuracy 0.9031 and Training loss 0.04507839866086014\n",
            "Iteration 42200: Training Accuracy 0.6441, Test Accuracy 0.8842 and Training loss 0.04485490813740999\n",
            "Iteration 42300: Training Accuracy 0.6557, Test Accuracy 0.8936 and Training loss 0.04462952147600775\n",
            "Iteration 42400: Training Accuracy 0.6722333333333333, Test Accuracy 0.8984 and Training loss 0.04462090449315504\n",
            "Iteration 42500: Training Accuracy 0.6832833333333334, Test Accuracy 0.9022 and Training loss 0.04475340707824186\n",
            "Iteration 42600: Training Accuracy 0.6722166666666667, Test Accuracy 0.9001 and Training loss 0.04460514812567142\n",
            "Iteration 42700: Training Accuracy 0.6521833333333333, Test Accuracy 0.8886 and Training loss 0.04447905012039656\n",
            "Iteration 42800: Training Accuracy 0.6242333333333333, Test Accuracy 0.872 and Training loss 0.044886382561668485\n",
            "Iteration 42900: Training Accuracy 0.6575, Test Accuracy 0.8933 and Training loss 0.04427484335305094\n",
            "Iteration 43000: Training Accuracy 0.6354833333333333, Test Accuracy 0.8852 and Training loss 0.0446887784015986\n",
            "Iteration 43100: Training Accuracy 0.65655, Test Accuracy 0.8936 and Training loss 0.04426602504060427\n",
            "Iteration 43200: Training Accuracy 0.6485, Test Accuracy 0.8889 and Training loss 0.044264607559106064\n",
            "Iteration 43300: Training Accuracy 0.6278166666666667, Test Accuracy 0.8683 and Training loss 0.044731079205473256\n",
            "Iteration 43400: Training Accuracy 0.6722, Test Accuracy 0.9 and Training loss 0.04413697653086436\n",
            "Iteration 43500: Training Accuracy 0.6717333333333333, Test Accuracy 0.9028 and Training loss 0.044084855880937884\n",
            "Iteration 43600: Training Accuracy 0.65395, Test Accuracy 0.8946 and Training loss 0.043932941292651705\n",
            "Iteration 43700: Training Accuracy 0.6676, Test Accuracy 0.8943 and Training loss 0.04401263733169315\n",
            "Iteration 43800: Training Accuracy 0.6680666666666667, Test Accuracy 0.8931 and Training loss 0.04382806073261969\n",
            "Iteration 43900: Training Accuracy 0.6540833333333333, Test Accuracy 0.8832 and Training loss 0.04391816969703693\n",
            "Iteration 44000: Training Accuracy 0.6789333333333334, Test Accuracy 0.8974 and Training loss 0.044151040311428184\n",
            "Iteration 44100: Training Accuracy 0.6513333333333333, Test Accuracy 0.8835 and Training loss 0.04386261464732811\n",
            "Iteration 44200: Training Accuracy 0.6591333333333333, Test Accuracy 0.8986 and Training loss 0.04371276146508382\n",
            "Iteration 44300: Training Accuracy 0.66615, Test Accuracy 0.8985 and Training loss 0.043661024087912746\n",
            "Iteration 44400: Training Accuracy 0.6315, Test Accuracy 0.8693 and Training loss 0.04426935297255517\n",
            "Iteration 44500: Training Accuracy 0.66015, Test Accuracy 0.8816 and Training loss 0.04365242061902669\n",
            "Iteration 44600: Training Accuracy 0.6665, Test Accuracy 0.8905 and Training loss 0.04359406875352572\n",
            "Iteration 44700: Training Accuracy 0.6766666666666666, Test Accuracy 0.8982 and Training loss 0.04365258480333124\n",
            "Iteration 44800: Training Accuracy 0.6609833333333334, Test Accuracy 0.8836 and Training loss 0.04353911397406425\n",
            "Iteration 44900: Training Accuracy 0.6688166666666666, Test Accuracy 0.8928 and Training loss 0.043500855423967706\n",
            "Iteration 45000: Training Accuracy 0.6359666666666667, Test Accuracy 0.875 and Training loss 0.043634513519455936\n",
            "Iteration 45100: Training Accuracy 0.6736333333333333, Test Accuracy 0.8977 and Training loss 0.04350958758755325\n",
            "Iteration 45200: Training Accuracy 0.65445, Test Accuracy 0.8851 and Training loss 0.04347872555515436\n",
            "Iteration 45300: Training Accuracy 0.6664, Test Accuracy 0.8968 and Training loss 0.043309684155048614\n",
            "Iteration 45400: Training Accuracy 0.679, Test Accuracy 0.9036 and Training loss 0.043548635411179065\n",
            "Iteration 45500: Training Accuracy 0.6559333333333334, Test Accuracy 0.8909 and Training loss 0.043285441715015756\n",
            "Iteration 45600: Training Accuracy 0.6606, Test Accuracy 0.8899 and Training loss 0.043156121788269775\n",
            "Iteration 45700: Training Accuracy 0.658, Test Accuracy 0.8961 and Training loss 0.043302632183507404\n",
            "Iteration 45800: Training Accuracy 0.6437666666666667, Test Accuracy 0.8925 and Training loss 0.04322447493933342\n",
            "Iteration 45900: Training Accuracy 0.6786333333333333, Test Accuracy 0.9016 and Training loss 0.0434296708156761\n",
            "Iteration 46000: Training Accuracy 0.6555166666666666, Test Accuracy 0.8831 and Training loss 0.04311762751392788\n",
            "Iteration 46100: Training Accuracy 0.6677833333333333, Test Accuracy 0.888 and Training loss 0.04298292983199319\n",
            "Iteration 46200: Training Accuracy 0.6422166666666667, Test Accuracy 0.8807 and Training loss 0.04327313495412498\n",
            "Iteration 46300: Training Accuracy 0.6653, Test Accuracy 0.889 and Training loss 0.04296416067276972\n",
            "Iteration 46400: Training Accuracy 0.6513, Test Accuracy 0.8844 and Training loss 0.04299461633250537\n",
            "Iteration 46500: Training Accuracy 0.6474833333333333, Test Accuracy 0.8959 and Training loss 0.043012723665825904\n",
            "Iteration 46600: Training Accuracy 0.6509333333333334, Test Accuracy 0.8859 and Training loss 0.042720864085689314\n",
            "Iteration 46700: Training Accuracy 0.709, Test Accuracy 0.9112 and Training loss 0.044055388404173286\n",
            "Iteration 46800: Training Accuracy 0.6482166666666667, Test Accuracy 0.8856 and Training loss 0.04284325828506899\n",
            "Iteration 46900: Training Accuracy 0.6673166666666667, Test Accuracy 0.8999 and Training loss 0.04266068748876951\n",
            "Iteration 47000: Training Accuracy 0.704, Test Accuracy 0.9149 and Training loss 0.04344766701241021\n",
            "Iteration 47100: Training Accuracy 0.67415, Test Accuracy 0.9067 and Training loss 0.042710880658240136\n",
            "Iteration 47200: Training Accuracy 0.6641666666666667, Test Accuracy 0.9058 and Training loss 0.042484737524859255\n",
            "Iteration 47300: Training Accuracy 0.68175, Test Accuracy 0.9088 and Training loss 0.04257210226868503\n",
            "Iteration 47400: Training Accuracy 0.66215, Test Accuracy 0.8999 and Training loss 0.04244267062703065\n",
            "Iteration 47500: Training Accuracy 0.6168833333333333, Test Accuracy 0.8675 and Training loss 0.043829078977251176\n",
            "Iteration 47600: Training Accuracy 0.6446166666666666, Test Accuracy 0.892 and Training loss 0.042527083487129365\n",
            "Iteration 47700: Training Accuracy 0.6480333333333334, Test Accuracy 0.894 and Training loss 0.042479033675836435\n",
            "Iteration 47800: Training Accuracy 0.6813666666666667, Test Accuracy 0.9006 and Training loss 0.04258184407508948\n",
            "Iteration 47900: Training Accuracy 0.6578666666666667, Test Accuracy 0.8873 and Training loss 0.04227814502759387\n",
            "Iteration 48000: Training Accuracy 0.6409, Test Accuracy 0.8758 and Training loss 0.04249166940897166\n",
            "Iteration 48100: Training Accuracy 0.6528166666666667, Test Accuracy 0.875 and Training loss 0.0422269834918937\n",
            "Iteration 48200: Training Accuracy 0.6574166666666666, Test Accuracy 0.8811 and Training loss 0.042316657263387944\n",
            "Iteration 48300: Training Accuracy 0.6742166666666667, Test Accuracy 0.8877 and Training loss 0.042109181620038856\n",
            "Iteration 48400: Training Accuracy 0.6415833333333333, Test Accuracy 0.8793 and Training loss 0.04233041358603338\n",
            "Iteration 48500: Training Accuracy 0.6908, Test Accuracy 0.8991 and Training loss 0.04238941320317973\n",
            "Iteration 48600: Training Accuracy 0.6735, Test Accuracy 0.9007 and Training loss 0.04197121337091673\n",
            "Iteration 48700: Training Accuracy 0.6707166666666666, Test Accuracy 0.8968 and Training loss 0.04200591885038244\n",
            "Iteration 48800: Training Accuracy 0.67385, Test Accuracy 0.9026 and Training loss 0.042208969689304515\n",
            "Iteration 48900: Training Accuracy 0.6843, Test Accuracy 0.9097 and Training loss 0.04239636225868871\n",
            "Iteration 49000: Training Accuracy 0.6644, Test Accuracy 0.8957 and Training loss 0.042040784421386784\n",
            "Iteration 49100: Training Accuracy 0.6678666666666667, Test Accuracy 0.8951 and Training loss 0.04196310322554153\n",
            "Iteration 49200: Training Accuracy 0.663, Test Accuracy 0.8917 and Training loss 0.041787042997420504\n",
            "Iteration 49300: Training Accuracy 0.6470333333333333, Test Accuracy 0.8885 and Training loss 0.04212604181181867\n",
            "Iteration 49400: Training Accuracy 0.6642166666666667, Test Accuracy 0.8914 and Training loss 0.04170509769722191\n",
            "Iteration 49500: Training Accuracy 0.6504166666666666, Test Accuracy 0.8839 and Training loss 0.04213859642217121\n",
            "Iteration 49600: Training Accuracy 0.6551666666666667, Test Accuracy 0.8862 and Training loss 0.041738538334857696\n",
            "Iteration 49700: Training Accuracy 0.6536166666666666, Test Accuracy 0.8909 and Training loss 0.041745374236274196\n",
            "Iteration 49800: Training Accuracy 0.6580666666666667, Test Accuracy 0.8945 and Training loss 0.04157056854275175\n",
            "Iteration 49900: Training Accuracy 0.68185, Test Accuracy 0.9073 and Training loss 0.04176578961326278\n",
            "Iteration 50000: Training Accuracy 0.6643833333333333, Test Accuracy 0.8999 and Training loss 0.04155944007619162\n",
            "Iteration 50100: Training Accuracy 0.65335, Test Accuracy 0.8889 and Training loss 0.04146133368984679\n",
            "Iteration 50200: Training Accuracy 0.6554166666666666, Test Accuracy 0.8882 and Training loss 0.04147292550124659\n",
            "Iteration 50300: Training Accuracy 0.6559333333333334, Test Accuracy 0.8888 and Training loss 0.04155568369599763\n",
            "Iteration 50400: Training Accuracy 0.65535, Test Accuracy 0.8964 and Training loss 0.04151924556379637\n",
            "Iteration 50500: Training Accuracy 0.6721333333333334, Test Accuracy 0.9025 and Training loss 0.04169154007699\n",
            "Iteration 50600: Training Accuracy 0.6691, Test Accuracy 0.9036 and Training loss 0.04145774443797506\n",
            "Iteration 50700: Training Accuracy 0.65725, Test Accuracy 0.9012 and Training loss 0.041443861041222274\n",
            "Iteration 50800: Training Accuracy 0.6608166666666667, Test Accuracy 0.879 and Training loss 0.04132401299995757\n",
            "Iteration 50900: Training Accuracy 0.64725, Test Accuracy 0.8869 and Training loss 0.04193108152844302\n",
            "Iteration 51000: Training Accuracy 0.6999833333333333, Test Accuracy 0.9092 and Training loss 0.04166462395819382\n",
            "Iteration 51100: Training Accuracy 0.6875, Test Accuracy 0.9046 and Training loss 0.041319340295849855\n",
            "Iteration 51200: Training Accuracy 0.6702333333333333, Test Accuracy 0.8938 and Training loss 0.04119085780394958\n",
            "Iteration 51300: Training Accuracy 0.6577833333333334, Test Accuracy 0.8912 and Training loss 0.04107157370384903\n",
            "Iteration 51400: Training Accuracy 0.6702333333333333, Test Accuracy 0.8951 and Training loss 0.04117389159704376\n",
            "Iteration 51500: Training Accuracy 0.65505, Test Accuracy 0.892 and Training loss 0.041097458040028116\n",
            "Iteration 51600: Training Accuracy 0.6754666666666667, Test Accuracy 0.8946 and Training loss 0.04112121811181651\n",
            "Iteration 51700: Training Accuracy 0.6856333333333333, Test Accuracy 0.9035 and Training loss 0.041171395713766816\n",
            "Iteration 51800: Training Accuracy 0.65565, Test Accuracy 0.8861 and Training loss 0.04098844979673943\n",
            "Iteration 51900: Training Accuracy 0.6511833333333333, Test Accuracy 0.9006 and Training loss 0.041031713913537264\n",
            "Iteration 52000: Training Accuracy 0.6413333333333333, Test Accuracy 0.8822 and Training loss 0.041135936895471494\n",
            "Iteration 52100: Training Accuracy 0.64835, Test Accuracy 0.8814 and Training loss 0.04090946517396939\n",
            "Iteration 52200: Training Accuracy 0.6741833333333334, Test Accuracy 0.8969 and Training loss 0.04077282986380566\n",
            "Iteration 52300: Training Accuracy 0.6689666666666667, Test Accuracy 0.8861 and Training loss 0.040816724044873895\n",
            "Iteration 52400: Training Accuracy 0.68555, Test Accuracy 0.8989 and Training loss 0.0409711043613162\n",
            "Iteration 52500: Training Accuracy 0.6678666666666667, Test Accuracy 0.8973 and Training loss 0.04072556986516816\n",
            "Iteration 52600: Training Accuracy 0.6839333333333333, Test Accuracy 0.9023 and Training loss 0.040859146885864416\n",
            "Iteration 52700: Training Accuracy 0.65395, Test Accuracy 0.8866 and Training loss 0.040876682492785955\n",
            "Iteration 52800: Training Accuracy 0.6646666666666666, Test Accuracy 0.8993 and Training loss 0.0405789728126875\n",
            "Iteration 52900: Training Accuracy 0.6645166666666666, Test Accuracy 0.8949 and Training loss 0.04056536662703464\n",
            "Iteration 53000: Training Accuracy 0.6411166666666667, Test Accuracy 0.8889 and Training loss 0.040767345402528216\n",
            "Iteration 53100: Training Accuracy 0.6802166666666667, Test Accuracy 0.9069 and Training loss 0.040693094680619685\n",
            "Iteration 53200: Training Accuracy 0.6696, Test Accuracy 0.9014 and Training loss 0.04054491157933493\n",
            "Iteration 53300: Training Accuracy 0.6738, Test Accuracy 0.8988 and Training loss 0.04058187538884686\n",
            "Iteration 53400: Training Accuracy 0.6597666666666666, Test Accuracy 0.8901 and Training loss 0.04047839515370865\n",
            "Iteration 53500: Training Accuracy 0.6739833333333334, Test Accuracy 0.8987 and Training loss 0.04050889233464979\n",
            "Iteration 53600: Training Accuracy 0.6572333333333333, Test Accuracy 0.8899 and Training loss 0.040577371617704264\n",
            "Iteration 53700: Training Accuracy 0.6757666666666666, Test Accuracy 0.8993 and Training loss 0.04029274478971969\n",
            "Iteration 53800: Training Accuracy 0.6625333333333333, Test Accuracy 0.8939 and Training loss 0.04037580497018144\n",
            "Iteration 53900: Training Accuracy 0.6691333333333334, Test Accuracy 0.8975 and Training loss 0.04053481065842008\n",
            "Iteration 54000: Training Accuracy 0.6703833333333333, Test Accuracy 0.8979 and Training loss 0.040279448984852584\n",
            "Iteration 54100: Training Accuracy 0.6968, Test Accuracy 0.9032 and Training loss 0.040529176912482624\n",
            "Iteration 54200: Training Accuracy 0.6863833333333333, Test Accuracy 0.901 and Training loss 0.04070650542143346\n",
            "Iteration 54300: Training Accuracy 0.6755833333333333, Test Accuracy 0.8971 and Training loss 0.0402409526241138\n",
            "Iteration 54400: Training Accuracy 0.6306833333333334, Test Accuracy 0.8753 and Training loss 0.04080654472114394\n",
            "Iteration 54500: Training Accuracy 0.6385833333333333, Test Accuracy 0.8691 and Training loss 0.04085380280470379\n",
            "Iteration 54600: Training Accuracy 0.6698, Test Accuracy 0.8881 and Training loss 0.0401281426862857\n",
            "Iteration 54700: Training Accuracy 0.67635, Test Accuracy 0.888 and Training loss 0.040340224839418584\n",
            "Iteration 54800: Training Accuracy 0.6651166666666667, Test Accuracy 0.8873 and Training loss 0.04007603517563865\n",
            "Iteration 54900: Training Accuracy 0.6458166666666667, Test Accuracy 0.8802 and Training loss 0.04031668860546036\n",
            "Iteration 55000: Training Accuracy 0.6691166666666667, Test Accuracy 0.8925 and Training loss 0.039972960054344496\n",
            "Iteration 55100: Training Accuracy 0.6649333333333334, Test Accuracy 0.8926 and Training loss 0.039933341689970744\n",
            "Iteration 55200: Training Accuracy 0.6531166666666667, Test Accuracy 0.8933 and Training loss 0.040045628141203396\n",
            "Iteration 55300: Training Accuracy 0.64925, Test Accuracy 0.8927 and Training loss 0.040057110830703145\n",
            "Iteration 55400: Training Accuracy 0.6843666666666667, Test Accuracy 0.9075 and Training loss 0.03995126164250112\n",
            "Iteration 55500: Training Accuracy 0.6928166666666666, Test Accuracy 0.9021 and Training loss 0.040365315069562\n",
            "Iteration 55600: Training Accuracy 0.66225, Test Accuracy 0.8984 and Training loss 0.03982914846649444\n",
            "Iteration 55700: Training Accuracy 0.6580666666666667, Test Accuracy 0.8988 and Training loss 0.03992133087202922\n",
            "Iteration 55800: Training Accuracy 0.6832166666666667, Test Accuracy 0.9057 and Training loss 0.03979697372583616\n",
            "Iteration 55900: Training Accuracy 0.6740833333333334, Test Accuracy 0.8975 and Training loss 0.03988917019588544\n",
            "Iteration 56000: Training Accuracy 0.6509666666666667, Test Accuracy 0.8851 and Training loss 0.03973329913383624\n",
            "Iteration 56100: Training Accuracy 0.6675333333333333, Test Accuracy 0.8916 and Training loss 0.03967154936380117\n",
            "Iteration 56200: Training Accuracy 0.6640333333333334, Test Accuracy 0.8915 and Training loss 0.03970942277663239\n",
            "Iteration 56300: Training Accuracy 0.6593, Test Accuracy 0.8924 and Training loss 0.03960187126791236\n",
            "Iteration 56400: Training Accuracy 0.7144166666666667, Test Accuracy 0.9035 and Training loss 0.041379325567208754\n",
            "Iteration 56500: Training Accuracy 0.6480666666666667, Test Accuracy 0.8782 and Training loss 0.03977873273030687\n",
            "Iteration 56600: Training Accuracy 0.63825, Test Accuracy 0.8793 and Training loss 0.03991230247860888\n",
            "Iteration 56700: Training Accuracy 0.675, Test Accuracy 0.8975 and Training loss 0.03971888000375969\n",
            "Iteration 56800: Training Accuracy 0.69905, Test Accuracy 0.9124 and Training loss 0.039988781094446785\n",
            "Iteration 56900: Training Accuracy 0.66635, Test Accuracy 0.9023 and Training loss 0.03953752686194966\n",
            "Iteration 57000: Training Accuracy 0.6388666666666667, Test Accuracy 0.8845 and Training loss 0.039645443195233936\n",
            "Iteration 57100: Training Accuracy 0.6297333333333334, Test Accuracy 0.8888 and Training loss 0.04027546389437295\n",
            "Iteration 57200: Training Accuracy 0.6550666666666667, Test Accuracy 0.8944 and Training loss 0.03954525899499538\n",
            "Iteration 57300: Training Accuracy 0.66695, Test Accuracy 0.8992 and Training loss 0.039369082014497195\n",
            "Iteration 57400: Training Accuracy 0.6875833333333333, Test Accuracy 0.9078 and Training loss 0.03949278543618532\n",
            "Iteration 57500: Training Accuracy 0.6747666666666666, Test Accuracy 0.9076 and Training loss 0.03933733757280312\n",
            "Iteration 57600: Training Accuracy 0.67135, Test Accuracy 0.9046 and Training loss 0.03920449222367546\n",
            "Iteration 57700: Training Accuracy 0.6738833333333333, Test Accuracy 0.8996 and Training loss 0.03927639690940201\n",
            "Iteration 57800: Training Accuracy 0.6816333333333333, Test Accuracy 0.9025 and Training loss 0.03920152957791802\n",
            "Iteration 57900: Training Accuracy 0.6824666666666667, Test Accuracy 0.9005 and Training loss 0.039318257741746875\n",
            "Iteration 58000: Training Accuracy 0.6805333333333333, Test Accuracy 0.9085 and Training loss 0.03915749051681852\n",
            "Iteration 58100: Training Accuracy 0.6717, Test Accuracy 0.9031 and Training loss 0.03920482633715357\n",
            "Iteration 58200: Training Accuracy 0.6537166666666666, Test Accuracy 0.9034 and Training loss 0.03920271646483392\n",
            "Iteration 58300: Training Accuracy 0.6708833333333334, Test Accuracy 0.9098 and Training loss 0.03920771268233173\n",
            "Iteration 58400: Training Accuracy 0.6930333333333333, Test Accuracy 0.9144 and Training loss 0.03942320347651749\n",
            "Iteration 58500: Training Accuracy 0.6718666666666666, Test Accuracy 0.8999 and Training loss 0.03904095584679841\n",
            "Iteration 58600: Training Accuracy 0.6875, Test Accuracy 0.8999 and Training loss 0.03911223708047424\n",
            "Iteration 58700: Training Accuracy 0.6811333333333334, Test Accuracy 0.9023 and Training loss 0.039116166989494765\n",
            "Iteration 58800: Training Accuracy 0.6700666666666667, Test Accuracy 0.9086 and Training loss 0.03927929511463328\n",
            "Iteration 58900: Training Accuracy 0.6422, Test Accuracy 0.8968 and Training loss 0.03933464336906139\n",
            "Iteration 59000: Training Accuracy 0.65985, Test Accuracy 0.8968 and Training loss 0.03891972281887868\n",
            "Iteration 59100: Training Accuracy 0.6772833333333333, Test Accuracy 0.9041 and Training loss 0.038885996219899445\n",
            "Iteration 59200: Training Accuracy 0.6744833333333333, Test Accuracy 0.9077 and Training loss 0.03886314311919867\n",
            "Iteration 59300: Training Accuracy 0.68845, Test Accuracy 0.9147 and Training loss 0.03893745476388033\n",
            "Iteration 59400: Training Accuracy 0.67105, Test Accuracy 0.9 and Training loss 0.03884964826037994\n",
            "Iteration 59500: Training Accuracy 0.6604, Test Accuracy 0.9014 and Training loss 0.03886502778464595\n",
            "Iteration 59600: Training Accuracy 0.641, Test Accuracy 0.8903 and Training loss 0.03929407880639948\n",
            "Iteration 59700: Training Accuracy 0.6548166666666667, Test Accuracy 0.8928 and Training loss 0.03884695488850954\n",
            "Iteration 59800: Training Accuracy 0.67425, Test Accuracy 0.9049 and Training loss 0.03866789187594322\n",
            "Iteration 59900: Training Accuracy 0.6538, Test Accuracy 0.8948 and Training loss 0.03909519764181819\n",
            "Iteration 60000: Training Accuracy 0.6711166666666667, Test Accuracy 0.9014 and Training loss 0.03872651896745117\n",
            "Final test accuracy for k = 40: 0.9014\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training with k = 200\n",
            "Iteration 0: Training accuracy 0.48788333333333334, Test accuracy 0.5077 and Training loss 0.49081725086748423\n",
            "Iteration 100: Training Accuracy 0.49006666666666665, Test Accuracy 0.4861 and Training loss 0.45493688761002626\n",
            "Iteration 200: Training Accuracy 0.49006666666666665, Test Accuracy 0.4861 and Training loss 0.3632783666956648\n",
            "Iteration 300: Training Accuracy 0.49006666666666665, Test Accuracy 0.4861 and Training loss 0.2628135269370997\n",
            "Iteration 400: Training Accuracy 0.49006666666666665, Test Accuracy 0.4861 and Training loss 0.22486719242079933\n",
            "Iteration 500: Training Accuracy 0.49006666666666665, Test Accuracy 0.4861 and Training loss 0.2149432191442004\n",
            "Iteration 600: Training Accuracy 0.49006666666666665, Test Accuracy 0.4861 and Training loss 0.20492285092592508\n",
            "Iteration 700: Training Accuracy 0.49016666666666664, Test Accuracy 0.4866 and Training loss 0.19842861652507773\n",
            "Iteration 800: Training Accuracy 0.4903666666666667, Test Accuracy 0.4881 and Training loss 0.1915743171913163\n",
            "Iteration 900: Training Accuracy 0.4905833333333333, Test Accuracy 0.4913 and Training loss 0.18544111216105882\n",
            "Iteration 1000: Training Accuracy 0.49128333333333335, Test Accuracy 0.4959 and Training loss 0.18078093820097704\n",
            "Iteration 1100: Training Accuracy 0.4923166666666667, Test Accuracy 0.5021 and Training loss 0.17589046732585845\n",
            "Iteration 1200: Training Accuracy 0.49365, Test Accuracy 0.5111 and Training loss 0.17257560106108236\n",
            "Iteration 1300: Training Accuracy 0.4953166666666667, Test Accuracy 0.5214 and Training loss 0.168719775346104\n",
            "Iteration 1400: Training Accuracy 0.4973666666666667, Test Accuracy 0.5323 and Training loss 0.16557633085465892\n",
            "Iteration 1500: Training Accuracy 0.5044166666666666, Test Accuracy 0.5595 and Training loss 0.16337755588009895\n",
            "Iteration 1600: Training Accuracy 0.50425, Test Accuracy 0.559 and Training loss 0.1605991694857012\n",
            "Iteration 1700: Training Accuracy 0.5107, Test Accuracy 0.5881 and Training loss 0.15780685688836388\n",
            "Iteration 1800: Training Accuracy 0.5187833333333334, Test Accuracy 0.6208 and Training loss 0.1562510923182483\n",
            "Iteration 1900: Training Accuracy 0.5145166666666666, Test Accuracy 0.6129 and Training loss 0.15377703810167404\n",
            "Iteration 2000: Training Accuracy 0.5170333333333333, Test Accuracy 0.6363 and Training loss 0.1518758915644144\n",
            "Iteration 2100: Training Accuracy 0.5198333333333334, Test Accuracy 0.6528 and Training loss 0.1497947064730224\n",
            "Iteration 2200: Training Accuracy 0.5223666666666666, Test Accuracy 0.6659 and Training loss 0.14797002714092072\n",
            "Iteration 2300: Training Accuracy 0.5285833333333333, Test Accuracy 0.691 and Training loss 0.14667618198442894\n",
            "Iteration 2400: Training Accuracy 0.5193833333333333, Test Accuracy 0.665 and Training loss 0.1461842663671111\n",
            "Iteration 2500: Training Accuracy 0.5304333333333333, Test Accuracy 0.7027 and Training loss 0.1440368774614859\n",
            "Iteration 2600: Training Accuracy 0.5320833333333334, Test Accuracy 0.7162 and Training loss 0.142861921183204\n",
            "Iteration 2700: Training Accuracy 0.5310833333333334, Test Accuracy 0.7154 and Training loss 0.14156062836725403\n",
            "Iteration 2800: Training Accuracy 0.53405, Test Accuracy 0.7252 and Training loss 0.14051264335926125\n",
            "Iteration 2900: Training Accuracy 0.53105, Test Accuracy 0.7218 and Training loss 0.14039256726692237\n",
            "Iteration 3000: Training Accuracy 0.5435, Test Accuracy 0.7504 and Training loss 0.13879567508231067\n",
            "Iteration 3100: Training Accuracy 0.5460666666666667, Test Accuracy 0.753 and Training loss 0.1380448917961551\n",
            "Iteration 3200: Training Accuracy 0.5482, Test Accuracy 0.763 and Training loss 0.13759184175092595\n",
            "Iteration 3300: Training Accuracy 0.5438333333333333, Test Accuracy 0.7588 and Training loss 0.13652600700708473\n",
            "Iteration 3400: Training Accuracy 0.5430666666666667, Test Accuracy 0.7563 and Training loss 0.13595956020799377\n",
            "Iteration 3500: Training Accuracy 0.5457333333333333, Test Accuracy 0.7609 and Training loss 0.13521670464462496\n",
            "Iteration 3600: Training Accuracy 0.5431333333333334, Test Accuracy 0.7627 and Training loss 0.13471528763108018\n",
            "Iteration 3700: Training Accuracy 0.5408333333333334, Test Accuracy 0.7598 and Training loss 0.13436845574442274\n",
            "Iteration 3800: Training Accuracy 0.5528833333333333, Test Accuracy 0.7802 and Training loss 0.13471690890226642\n",
            "Iteration 3900: Training Accuracy 0.5491833333333334, Test Accuracy 0.7746 and Training loss 0.1333123089114572\n",
            "Iteration 4000: Training Accuracy 0.5454166666666667, Test Accuracy 0.7723 and Training loss 0.1327524185559041\n",
            "Iteration 4100: Training Accuracy 0.5505666666666666, Test Accuracy 0.7827 and Training loss 0.13276985695166016\n",
            "Iteration 4200: Training Accuracy 0.5430333333333334, Test Accuracy 0.7682 and Training loss 0.13189067192882267\n",
            "Iteration 4300: Training Accuracy 0.5483833333333333, Test Accuracy 0.7743 and Training loss 0.13159512323435515\n",
            "Iteration 4400: Training Accuracy 0.5631666666666667, Test Accuracy 0.7962 and Training loss 0.13332317511765981\n",
            "Iteration 4500: Training Accuracy 0.5527333333333333, Test Accuracy 0.7825 and Training loss 0.13077511819502402\n",
            "Iteration 4600: Training Accuracy 0.5513333333333333, Test Accuracy 0.7856 and Training loss 0.13024577433784829\n",
            "Iteration 4700: Training Accuracy 0.5464666666666667, Test Accuracy 0.7777 and Training loss 0.1299172009576441\n",
            "Iteration 4800: Training Accuracy 0.5632333333333334, Test Accuracy 0.8014 and Training loss 0.1298496929271433\n",
            "Iteration 4900: Training Accuracy 0.5609833333333333, Test Accuracy 0.7968 and Training loss 0.12929823751749145\n",
            "Iteration 5000: Training Accuracy 0.5565, Test Accuracy 0.792 and Training loss 0.12885844335148164\n",
            "Iteration 5100: Training Accuracy 0.5484666666666667, Test Accuracy 0.7819 and Training loss 0.12863448482339312\n",
            "Iteration 5200: Training Accuracy 0.5507166666666666, Test Accuracy 0.7834 and Training loss 0.1282963687115397\n",
            "Iteration 5300: Training Accuracy 0.5592333333333334, Test Accuracy 0.7957 and Training loss 0.12816450991055048\n",
            "Iteration 5400: Training Accuracy 0.5591166666666667, Test Accuracy 0.798 and Training loss 0.1278552794392485\n",
            "Iteration 5500: Training Accuracy 0.5478166666666666, Test Accuracy 0.7812 and Training loss 0.12729308082194618\n",
            "Iteration 5600: Training Accuracy 0.5532166666666667, Test Accuracy 0.7912 and Training loss 0.12705697969554697\n",
            "Iteration 5700: Training Accuracy 0.5452833333333333, Test Accuracy 0.7827 and Training loss 0.12733438717194914\n",
            "Iteration 5800: Training Accuracy 0.5465833333333333, Test Accuracy 0.784 and Training loss 0.1266534490436077\n",
            "Iteration 5900: Training Accuracy 0.547, Test Accuracy 0.7876 and Training loss 0.1264289029074178\n",
            "Iteration 6000: Training Accuracy 0.5587666666666666, Test Accuracy 0.8025 and Training loss 0.12626278593586837\n",
            "Iteration 6100: Training Accuracy 0.5459166666666667, Test Accuracy 0.786 and Training loss 0.12564559205809145\n",
            "Iteration 6200: Training Accuracy 0.5484, Test Accuracy 0.786 and Training loss 0.12530224273255264\n",
            "Iteration 6300: Training Accuracy 0.5480833333333334, Test Accuracy 0.7833 and Training loss 0.1252284595758031\n",
            "Iteration 6400: Training Accuracy 0.5520333333333334, Test Accuracy 0.7874 and Training loss 0.12487362582907152\n",
            "Iteration 6500: Training Accuracy 0.5433166666666667, Test Accuracy 0.7721 and Training loss 0.12602118037996946\n",
            "Iteration 6600: Training Accuracy 0.5464166666666667, Test Accuracy 0.7803 and Training loss 0.12479456991243165\n",
            "Iteration 6700: Training Accuracy 0.5573166666666667, Test Accuracy 0.7977 and Training loss 0.12452465824367093\n",
            "Iteration 6800: Training Accuracy 0.5434666666666667, Test Accuracy 0.7782 and Training loss 0.12399165569065661\n",
            "Iteration 6900: Training Accuracy 0.5447, Test Accuracy 0.783 and Training loss 0.1235076932793943\n",
            "Iteration 7000: Training Accuracy 0.5505, Test Accuracy 0.7911 and Training loss 0.12298331115687539\n",
            "Iteration 7100: Training Accuracy 0.5580166666666667, Test Accuracy 0.8008 and Training loss 0.1230869329413023\n",
            "Iteration 7200: Training Accuracy 0.55705, Test Accuracy 0.7968 and Training loss 0.12253908032145201\n",
            "Iteration 7300: Training Accuracy 0.5454833333333333, Test Accuracy 0.7823 and Training loss 0.1222960831331175\n",
            "Iteration 7400: Training Accuracy 0.5517166666666666, Test Accuracy 0.7921 and Training loss 0.12182456052678879\n",
            "Iteration 7500: Training Accuracy 0.55345, Test Accuracy 0.7956 and Training loss 0.12152018320460076\n",
            "Iteration 7600: Training Accuracy 0.5642166666666667, Test Accuracy 0.8117 and Training loss 0.12171669333254079\n",
            "Iteration 7700: Training Accuracy 0.5457, Test Accuracy 0.7831 and Training loss 0.12125517483803232\n",
            "Iteration 7800: Training Accuracy 0.54515, Test Accuracy 0.7833 and Training loss 0.12114992369897175\n",
            "Iteration 7900: Training Accuracy 0.5470333333333334, Test Accuracy 0.7904 and Training loss 0.12076693269636829\n",
            "Iteration 8000: Training Accuracy 0.5728166666666666, Test Accuracy 0.8154 and Training loss 0.12117341499409606\n",
            "Iteration 8100: Training Accuracy 0.5716833333333333, Test Accuracy 0.8135 and Training loss 0.12108260154348123\n",
            "Iteration 8200: Training Accuracy 0.54435, Test Accuracy 0.7813 and Training loss 0.11926891626574905\n",
            "Iteration 8300: Training Accuracy 0.5491833333333334, Test Accuracy 0.7915 and Training loss 0.11882241224423153\n",
            "Iteration 8400: Training Accuracy 0.54895, Test Accuracy 0.7911 and Training loss 0.11848941285884261\n",
            "Iteration 8500: Training Accuracy 0.5468, Test Accuracy 0.7917 and Training loss 0.11823840339475108\n",
            "Iteration 8600: Training Accuracy 0.5529833333333334, Test Accuracy 0.7958 and Training loss 0.11837569258855848\n",
            "Iteration 8700: Training Accuracy 0.5456333333333333, Test Accuracy 0.7727 and Training loss 0.1175025312857381\n",
            "Iteration 8800: Training Accuracy 0.5459166666666667, Test Accuracy 0.7762 and Training loss 0.11728422738921605\n",
            "Iteration 8900: Training Accuracy 0.5442833333333333, Test Accuracy 0.7738 and Training loss 0.11700072831320558\n",
            "Iteration 9000: Training Accuracy 0.5451333333333334, Test Accuracy 0.7833 and Training loss 0.11659854858348752\n",
            "Iteration 9100: Training Accuracy 0.5379333333333334, Test Accuracy 0.7659 and Training loss 0.11640176877803735\n",
            "Iteration 9200: Training Accuracy 0.5436333333333333, Test Accuracy 0.7751 and Training loss 0.11587415259926616\n",
            "Iteration 9300: Training Accuracy 0.5323833333333333, Test Accuracy 0.7556 and Training loss 0.11536623618585906\n",
            "Iteration 9400: Training Accuracy 0.55485, Test Accuracy 0.7896 and Training loss 0.11650299534667066\n",
            "Iteration 9500: Training Accuracy 0.54935, Test Accuracy 0.7931 and Training loss 0.11523437449940054\n",
            "Iteration 9600: Training Accuracy 0.5382166666666667, Test Accuracy 0.7694 and Training loss 0.11410396268634389\n",
            "Iteration 9700: Training Accuracy 0.5431666666666667, Test Accuracy 0.7805 and Training loss 0.11386786746771702\n",
            "Iteration 9800: Training Accuracy 0.5517, Test Accuracy 0.7953 and Training loss 0.11434124472488266\n",
            "Iteration 9900: Training Accuracy 0.5391833333333333, Test Accuracy 0.7735 and Training loss 0.1130887519559829\n",
            "Iteration 10000: Training Accuracy 0.5473833333333333, Test Accuracy 0.7806 and Training loss 0.11258036326074301\n",
            "Iteration 10100: Training Accuracy 0.5423666666666667, Test Accuracy 0.7842 and Training loss 0.11226848684485949\n",
            "Iteration 10200: Training Accuracy 0.54875, Test Accuracy 0.7876 and Training loss 0.1115772715232918\n",
            "Iteration 10300: Training Accuracy 0.5561, Test Accuracy 0.7972 and Training loss 0.11214203593525053\n",
            "Iteration 10400: Training Accuracy 0.54825, Test Accuracy 0.7835 and Training loss 0.110876557789826\n",
            "Iteration 10500: Training Accuracy 0.5368666666666667, Test Accuracy 0.7683 and Training loss 0.11033140303760103\n",
            "Iteration 10600: Training Accuracy 0.555, Test Accuracy 0.7952 and Training loss 0.11040283578709242\n",
            "Iteration 10700: Training Accuracy 0.5574, Test Accuracy 0.7982 and Training loss 0.10982921048629343\n",
            "Iteration 10800: Training Accuracy 0.5441833333333334, Test Accuracy 0.7813 and Training loss 0.10908865484259965\n",
            "Iteration 10900: Training Accuracy 0.5519333333333334, Test Accuracy 0.7957 and Training loss 0.10836445796619266\n",
            "Iteration 11000: Training Accuracy 0.5377166666666666, Test Accuracy 0.775 and Training loss 0.10818861035163924\n",
            "Iteration 11100: Training Accuracy 0.5636333333333333, Test Accuracy 0.8142 and Training loss 0.10791633225879566\n",
            "Iteration 11200: Training Accuracy 0.5540833333333334, Test Accuracy 0.7984 and Training loss 0.1069798488214453\n",
            "Iteration 11300: Training Accuracy 0.5640166666666667, Test Accuracy 0.8121 and Training loss 0.10662285900459524\n",
            "Iteration 11400: Training Accuracy 0.5484333333333333, Test Accuracy 0.793 and Training loss 0.10634470249516098\n",
            "Iteration 11500: Training Accuracy 0.5532333333333334, Test Accuracy 0.7935 and Training loss 0.10551997568603347\n",
            "Iteration 11600: Training Accuracy 0.5597666666666666, Test Accuracy 0.8098 and Training loss 0.10508265275766239\n",
            "Iteration 11700: Training Accuracy 0.5555, Test Accuracy 0.8051 and Training loss 0.10451041790097765\n",
            "Iteration 11800: Training Accuracy 0.5666166666666667, Test Accuracy 0.8153 and Training loss 0.1041976368064234\n",
            "Iteration 11900: Training Accuracy 0.5689, Test Accuracy 0.8184 and Training loss 0.10411918164625479\n",
            "Iteration 12000: Training Accuracy 0.5521333333333334, Test Accuracy 0.7985 and Training loss 0.10287097873147534\n",
            "Iteration 12100: Training Accuracy 0.55715, Test Accuracy 0.8049 and Training loss 0.10242269429015885\n",
            "Iteration 12200: Training Accuracy 0.5497166666666666, Test Accuracy 0.7963 and Training loss 0.10208153892895643\n",
            "Iteration 12300: Training Accuracy 0.5561333333333334, Test Accuracy 0.8039 and Training loss 0.10131260704019654\n",
            "Iteration 12400: Training Accuracy 0.56, Test Accuracy 0.8027 and Training loss 0.10090462426274595\n",
            "Iteration 12500: Training Accuracy 0.5664, Test Accuracy 0.8164 and Training loss 0.10077953808474427\n",
            "Iteration 12600: Training Accuracy 0.54645, Test Accuracy 0.7881 and Training loss 0.10055623044261344\n",
            "Iteration 12700: Training Accuracy 0.5352333333333333, Test Accuracy 0.7711 and Training loss 0.10072861969980254\n",
            "Iteration 12800: Training Accuracy 0.5656333333333333, Test Accuracy 0.8124 and Training loss 0.09937312101897974\n",
            "Iteration 12900: Training Accuracy 0.5564333333333333, Test Accuracy 0.7938 and Training loss 0.09843008392710925\n",
            "Iteration 13000: Training Accuracy 0.5722166666666667, Test Accuracy 0.8175 and Training loss 0.09817269673899154\n",
            "Iteration 13100: Training Accuracy 0.5533666666666667, Test Accuracy 0.7948 and Training loss 0.09770460180992689\n",
            "Iteration 13200: Training Accuracy 0.54955, Test Accuracy 0.7875 and Training loss 0.09768136474235564\n",
            "Iteration 13300: Training Accuracy 0.5586333333333333, Test Accuracy 0.8067 and Training loss 0.09642760898552628\n",
            "Iteration 13400: Training Accuracy 0.55315, Test Accuracy 0.7994 and Training loss 0.0957545735184119\n",
            "Iteration 13500: Training Accuracy 0.5629666666666666, Test Accuracy 0.8074 and Training loss 0.0953332908165279\n",
            "Iteration 13600: Training Accuracy 0.5578333333333333, Test Accuracy 0.8067 and Training loss 0.09471024289002507\n",
            "Iteration 13700: Training Accuracy 0.55325, Test Accuracy 0.8052 and Training loss 0.09471842671012264\n",
            "Iteration 13800: Training Accuracy 0.5578666666666666, Test Accuracy 0.8021 and Training loss 0.09462095100334816\n",
            "Iteration 13900: Training Accuracy 0.5837666666666667, Test Accuracy 0.8267 and Training loss 0.09340859457225935\n",
            "Iteration 14000: Training Accuracy 0.5598, Test Accuracy 0.8044 and Training loss 0.0933772837610559\n",
            "Iteration 14100: Training Accuracy 0.5602833333333334, Test Accuracy 0.8151 and Training loss 0.0924459144385379\n",
            "Iteration 14200: Training Accuracy 0.5689666666666666, Test Accuracy 0.8194 and Training loss 0.09155240193937954\n",
            "Iteration 14300: Training Accuracy 0.57695, Test Accuracy 0.8356 and Training loss 0.09141469135484202\n",
            "Iteration 14400: Training Accuracy 0.5625166666666667, Test Accuracy 0.8271 and Training loss 0.09047950150163332\n",
            "Iteration 14500: Training Accuracy 0.561, Test Accuracy 0.8234 and Training loss 0.08986771715476075\n",
            "Iteration 14600: Training Accuracy 0.5482166666666667, Test Accuracy 0.8086 and Training loss 0.08943498703908351\n",
            "Iteration 14700: Training Accuracy 0.5548333333333333, Test Accuracy 0.8211 and Training loss 0.08882117490866284\n",
            "Iteration 14800: Training Accuracy 0.5682333333333334, Test Accuracy 0.8372 and Training loss 0.08834985285633544\n",
            "Iteration 14900: Training Accuracy 0.56535, Test Accuracy 0.8373 and Training loss 0.08788208656862803\n",
            "Iteration 15000: Training Accuracy 0.5764666666666667, Test Accuracy 0.8405 and Training loss 0.0872837463778661\n",
            "Iteration 15100: Training Accuracy 0.5992333333333333, Test Accuracy 0.8598 and Training loss 0.0880146766210438\n",
            "Iteration 15200: Training Accuracy 0.5649333333333333, Test Accuracy 0.8317 and Training loss 0.08611052673958802\n",
            "Iteration 15300: Training Accuracy 0.5613333333333334, Test Accuracy 0.8344 and Training loss 0.08553596976398556\n",
            "Iteration 15400: Training Accuracy 0.5759, Test Accuracy 0.8515 and Training loss 0.08515991841574092\n",
            "Iteration 15500: Training Accuracy 0.5794166666666667, Test Accuracy 0.8551 and Training loss 0.08494121288368874\n",
            "Iteration 15600: Training Accuracy 0.5615, Test Accuracy 0.8427 and Training loss 0.08417744459861205\n",
            "Iteration 15700: Training Accuracy 0.58075, Test Accuracy 0.8567 and Training loss 0.08390074121923681\n",
            "Iteration 15800: Training Accuracy 0.5780833333333333, Test Accuracy 0.8637 and Training loss 0.08352001361717515\n",
            "Iteration 15900: Training Accuracy 0.5983666666666667, Test Accuracy 0.8665 and Training loss 0.08415590110818737\n",
            "Iteration 16000: Training Accuracy 0.5779166666666666, Test Accuracy 0.856 and Training loss 0.08227158903664164\n",
            "Iteration 16100: Training Accuracy 0.5817, Test Accuracy 0.8589 and Training loss 0.08205872134505487\n",
            "Iteration 16200: Training Accuracy 0.5796333333333333, Test Accuracy 0.8579 and Training loss 0.0814512409191168\n",
            "Iteration 16300: Training Accuracy 0.564, Test Accuracy 0.8463 and Training loss 0.08117432772376688\n",
            "Iteration 16400: Training Accuracy 0.5764666666666667, Test Accuracy 0.8613 and Training loss 0.08053048432554202\n",
            "Iteration 16500: Training Accuracy 0.5701833333333334, Test Accuracy 0.8493 and Training loss 0.08028345390539247\n",
            "Iteration 16600: Training Accuracy 0.5759333333333333, Test Accuracy 0.8388 and Training loss 0.07968202541524717\n",
            "Iteration 16700: Training Accuracy 0.5732, Test Accuracy 0.8369 and Training loss 0.07948443647708688\n",
            "Iteration 16800: Training Accuracy 0.5636333333333333, Test Accuracy 0.8296 and Training loss 0.078767623879318\n",
            "Iteration 16900: Training Accuracy 0.5702666666666667, Test Accuracy 0.84 and Training loss 0.07823288159681335\n",
            "Iteration 17000: Training Accuracy 0.5553666666666667, Test Accuracy 0.8276 and Training loss 0.07870970952052939\n",
            "Iteration 17100: Training Accuracy 0.5800166666666666, Test Accuracy 0.8507 and Training loss 0.07737450343826066\n",
            "Iteration 17200: Training Accuracy 0.5571666666666667, Test Accuracy 0.8417 and Training loss 0.0780823635486898\n",
            "Iteration 17300: Training Accuracy 0.5709833333333333, Test Accuracy 0.8462 and Training loss 0.07662737569429788\n",
            "Iteration 17400: Training Accuracy 0.60285, Test Accuracy 0.8646 and Training loss 0.07664562128490404\n",
            "Iteration 17500: Training Accuracy 0.6065166666666667, Test Accuracy 0.8583 and Training loss 0.07618633062986341\n",
            "Iteration 17600: Training Accuracy 0.5711666666666667, Test Accuracy 0.8369 and Training loss 0.07592878187118896\n",
            "Iteration 17700: Training Accuracy 0.58195, Test Accuracy 0.8571 and Training loss 0.07516054232178802\n",
            "Iteration 17800: Training Accuracy 0.5759666666666666, Test Accuracy 0.8465 and Training loss 0.07463596949520224\n",
            "Iteration 17900: Training Accuracy 0.5907833333333333, Test Accuracy 0.859 and Training loss 0.07429513522934139\n",
            "Iteration 18000: Training Accuracy 0.5975833333333334, Test Accuracy 0.8638 and Training loss 0.07384973059244959\n",
            "Iteration 18100: Training Accuracy 0.5972166666666666, Test Accuracy 0.8511 and Training loss 0.07357152256425942\n",
            "Iteration 18200: Training Accuracy 0.5840166666666666, Test Accuracy 0.8449 and Training loss 0.07393105387598459\n",
            "Iteration 18300: Training Accuracy 0.58045, Test Accuracy 0.8466 and Training loss 0.0730771674889382\n",
            "Iteration 18400: Training Accuracy 0.591, Test Accuracy 0.8615 and Training loss 0.07235286632616234\n",
            "Iteration 18500: Training Accuracy 0.5830666666666666, Test Accuracy 0.851 and Training loss 0.07203313525140058\n",
            "Iteration 18600: Training Accuracy 0.61095, Test Accuracy 0.8705 and Training loss 0.07200367648772539\n",
            "Iteration 18700: Training Accuracy 0.5854, Test Accuracy 0.8551 and Training loss 0.071346691269101\n",
            "Iteration 18800: Training Accuracy 0.6135166666666667, Test Accuracy 0.8718 and Training loss 0.07191050111686087\n",
            "Iteration 18900: Training Accuracy 0.5953833333333334, Test Accuracy 0.8498 and Training loss 0.07066221026947561\n",
            "Iteration 19000: Training Accuracy 0.6035333333333334, Test Accuracy 0.8554 and Training loss 0.07041845343201968\n",
            "Iteration 19100: Training Accuracy 0.5989166666666667, Test Accuracy 0.8581 and Training loss 0.0700027094986032\n",
            "Iteration 19200: Training Accuracy 0.6042666666666666, Test Accuracy 0.8668 and Training loss 0.06983799047329345\n",
            "Iteration 19300: Training Accuracy 0.6081666666666666, Test Accuracy 0.8625 and Training loss 0.0696583954216554\n",
            "Iteration 19400: Training Accuracy 0.6157166666666667, Test Accuracy 0.8725 and Training loss 0.06968706181883623\n",
            "Iteration 19500: Training Accuracy 0.6029666666666667, Test Accuracy 0.8641 and Training loss 0.06942429135793154\n",
            "Iteration 19600: Training Accuracy 0.62225, Test Accuracy 0.8716 and Training loss 0.06909574812081506\n",
            "Iteration 19700: Training Accuracy 0.6036833333333333, Test Accuracy 0.8556 and Training loss 0.06842262141523771\n",
            "Iteration 19800: Training Accuracy 0.5987833333333333, Test Accuracy 0.8516 and Training loss 0.06814341821498353\n",
            "Iteration 19900: Training Accuracy 0.5948666666666667, Test Accuracy 0.8514 and Training loss 0.06797571388151676\n",
            "Iteration 20000: Training Accuracy 0.5970333333333333, Test Accuracy 0.8521 and Training loss 0.06782009312579637\n",
            "Iteration 20100: Training Accuracy 0.5865, Test Accuracy 0.8501 and Training loss 0.06738319969883809\n",
            "Iteration 20200: Training Accuracy 0.5795833333333333, Test Accuracy 0.8389 and Training loss 0.06719009984175288\n",
            "Iteration 20300: Training Accuracy 0.5891166666666666, Test Accuracy 0.8486 and Training loss 0.0669027725971626\n",
            "Iteration 20400: Training Accuracy 0.60455, Test Accuracy 0.8625 and Training loss 0.06651844600183213\n",
            "Iteration 20500: Training Accuracy 0.6250833333333333, Test Accuracy 0.8819 and Training loss 0.06728807527641907\n",
            "Iteration 20600: Training Accuracy 0.5896666666666667, Test Accuracy 0.8498 and Training loss 0.06593321321227512\n",
            "Iteration 20700: Training Accuracy 0.58425, Test Accuracy 0.8475 and Training loss 0.06595467626227669\n",
            "Iteration 20800: Training Accuracy 0.6103333333333333, Test Accuracy 0.866 and Training loss 0.06573002012688843\n",
            "Iteration 20900: Training Accuracy 0.59745, Test Accuracy 0.8689 and Training loss 0.06512466806515363\n",
            "Iteration 21000: Training Accuracy 0.6128833333333333, Test Accuracy 0.8813 and Training loss 0.06499763362610131\n",
            "Iteration 21100: Training Accuracy 0.5944666666666667, Test Accuracy 0.8696 and Training loss 0.0646907671690063\n",
            "Iteration 21200: Training Accuracy 0.6042, Test Accuracy 0.8743 and Training loss 0.0644436814446193\n",
            "Iteration 21300: Training Accuracy 0.6105833333333334, Test Accuracy 0.8777 and Training loss 0.06427456297486775\n",
            "Iteration 21400: Training Accuracy 0.6047666666666667, Test Accuracy 0.8621 and Training loss 0.06397938714076555\n",
            "Iteration 21500: Training Accuracy 0.6246666666666667, Test Accuracy 0.8774 and Training loss 0.06374957578898481\n",
            "Iteration 21600: Training Accuracy 0.6091, Test Accuracy 0.8729 and Training loss 0.06349746895849001\n",
            "Iteration 21700: Training Accuracy 0.6163666666666666, Test Accuracy 0.8683 and Training loss 0.06318985348651428\n",
            "Iteration 21800: Training Accuracy 0.60845, Test Accuracy 0.874 and Training loss 0.06302964457152696\n",
            "Iteration 21900: Training Accuracy 0.5998, Test Accuracy 0.8636 and Training loss 0.06286431565822423\n",
            "Iteration 22000: Training Accuracy 0.5864, Test Accuracy 0.8507 and Training loss 0.06316527915780554\n",
            "Iteration 22100: Training Accuracy 0.6022666666666666, Test Accuracy 0.8693 and Training loss 0.062452626612610244\n",
            "Iteration 22200: Training Accuracy 0.60105, Test Accuracy 0.8685 and Training loss 0.06223871038340899\n",
            "Iteration 22300: Training Accuracy 0.62545, Test Accuracy 0.8823 and Training loss 0.06211009364536142\n",
            "Iteration 22400: Training Accuracy 0.6063833333333334, Test Accuracy 0.868 and Training loss 0.06205108458003287\n",
            "Iteration 22500: Training Accuracy 0.6114166666666667, Test Accuracy 0.8704 and Training loss 0.061778928072233064\n",
            "Iteration 22600: Training Accuracy 0.6135666666666667, Test Accuracy 0.8756 and Training loss 0.06166040882335846\n",
            "Iteration 22700: Training Accuracy 0.6183166666666666, Test Accuracy 0.8725 and Training loss 0.061381997385956934\n",
            "Iteration 22800: Training Accuracy 0.6241833333333333, Test Accuracy 0.883 and Training loss 0.06119691057291237\n",
            "Iteration 22900: Training Accuracy 0.6117166666666667, Test Accuracy 0.8677 and Training loss 0.06111964839362939\n",
            "Iteration 23000: Training Accuracy 0.62525, Test Accuracy 0.8759 and Training loss 0.060748955164751414\n",
            "Iteration 23100: Training Accuracy 0.6283333333333333, Test Accuracy 0.8743 and Training loss 0.060731728810608655\n",
            "Iteration 23200: Training Accuracy 0.6193833333333333, Test Accuracy 0.8754 and Training loss 0.06034389751247972\n",
            "Iteration 23300: Training Accuracy 0.5850166666666666, Test Accuracy 0.8563 and Training loss 0.060910346135703765\n",
            "Iteration 23400: Training Accuracy 0.6154, Test Accuracy 0.8819 and Training loss 0.06009207993375625\n",
            "Iteration 23500: Training Accuracy 0.6101666666666666, Test Accuracy 0.8744 and Training loss 0.060036480298077816\n",
            "Iteration 23600: Training Accuracy 0.6233333333333333, Test Accuracy 0.8758 and Training loss 0.05960758049103291\n",
            "Iteration 23700: Training Accuracy 0.6001833333333333, Test Accuracy 0.8665 and Training loss 0.05964819512984949\n",
            "Iteration 23800: Training Accuracy 0.64315, Test Accuracy 0.8847 and Training loss 0.059535770895286486\n",
            "Iteration 23900: Training Accuracy 0.62735, Test Accuracy 0.8785 and Training loss 0.0590699839255827\n",
            "Iteration 24000: Training Accuracy 0.61715, Test Accuracy 0.8772 and Training loss 0.05895900140469028\n",
            "Iteration 24100: Training Accuracy 0.6220333333333333, Test Accuracy 0.8826 and Training loss 0.05880196089491186\n",
            "Iteration 24200: Training Accuracy 0.6179666666666667, Test Accuracy 0.8752 and Training loss 0.05852355114095206\n",
            "Iteration 24300: Training Accuracy 0.6237833333333334, Test Accuracy 0.8696 and Training loss 0.05839095038249853\n",
            "Iteration 24400: Training Accuracy 0.6260166666666667, Test Accuracy 0.8803 and Training loss 0.05838838650095133\n",
            "Iteration 24500: Training Accuracy 0.6230666666666667, Test Accuracy 0.8805 and Training loss 0.058147852274821075\n",
            "Iteration 24600: Training Accuracy 0.6402333333333333, Test Accuracy 0.8881 and Training loss 0.05827168854256454\n",
            "Iteration 24700: Training Accuracy 0.6406333333333334, Test Accuracy 0.8874 and Training loss 0.0579604466861322\n",
            "Iteration 24800: Training Accuracy 0.6203666666666666, Test Accuracy 0.876 and Training loss 0.05772878598927366\n",
            "Iteration 24900: Training Accuracy 0.6365, Test Accuracy 0.8835 and Training loss 0.05763702256756778\n",
            "Iteration 25000: Training Accuracy 0.6313833333333333, Test Accuracy 0.8782 and Training loss 0.05747531674594449\n",
            "Iteration 25100: Training Accuracy 0.62575, Test Accuracy 0.8731 and Training loss 0.057431002580284315\n",
            "Iteration 25200: Training Accuracy 0.6245333333333334, Test Accuracy 0.8686 and Training loss 0.05723443700967894\n",
            "Iteration 25300: Training Accuracy 0.6342666666666666, Test Accuracy 0.8735 and Training loss 0.05698172544440715\n",
            "Iteration 25400: Training Accuracy 0.6069666666666667, Test Accuracy 0.8593 and Training loss 0.05727185037900429\n",
            "Iteration 25500: Training Accuracy 0.6313333333333333, Test Accuracy 0.8692 and Training loss 0.05658889253557056\n",
            "Iteration 25600: Training Accuracy 0.6257, Test Accuracy 0.8738 and Training loss 0.0564860158560463\n",
            "Iteration 25700: Training Accuracy 0.64455, Test Accuracy 0.8749 and Training loss 0.056435817543638626\n",
            "Iteration 25800: Training Accuracy 0.6477666666666667, Test Accuracy 0.8802 and Training loss 0.05660352372906842\n",
            "Iteration 25900: Training Accuracy 0.6003166666666667, Test Accuracy 0.8488 and Training loss 0.056493021111345965\n",
            "Iteration 26000: Training Accuracy 0.62525, Test Accuracy 0.8612 and Training loss 0.05597967817045494\n",
            "Iteration 26100: Training Accuracy 0.62955, Test Accuracy 0.8707 and Training loss 0.05587064347012154\n",
            "Iteration 26200: Training Accuracy 0.6151333333333333, Test Accuracy 0.8641 and Training loss 0.05584432219170729\n",
            "Iteration 26300: Training Accuracy 0.6344333333333333, Test Accuracy 0.8845 and Training loss 0.05556090102074919\n",
            "Iteration 26400: Training Accuracy 0.6346, Test Accuracy 0.8838 and Training loss 0.055389099889194264\n",
            "Iteration 26500: Training Accuracy 0.6273333333333333, Test Accuracy 0.8752 and Training loss 0.055197298748152074\n",
            "Iteration 26600: Training Accuracy 0.6103166666666666, Test Accuracy 0.871 and Training loss 0.055464756402850986\n",
            "Iteration 26700: Training Accuracy 0.6301333333333333, Test Accuracy 0.8775 and Training loss 0.054851519720387994\n",
            "Iteration 26800: Training Accuracy 0.6444166666666666, Test Accuracy 0.8792 and Training loss 0.05486541572160298\n",
            "Iteration 26900: Training Accuracy 0.6242333333333333, Test Accuracy 0.8715 and Training loss 0.054783954803920724\n",
            "Iteration 27000: Training Accuracy 0.6551666666666667, Test Accuracy 0.8789 and Training loss 0.05481500479021037\n",
            "Iteration 27100: Training Accuracy 0.64705, Test Accuracy 0.8781 and Training loss 0.054631372255857576\n",
            "Iteration 27200: Training Accuracy 0.6333833333333333, Test Accuracy 0.8783 and Training loss 0.054367308945378674\n",
            "Iteration 27300: Training Accuracy 0.6091666666666666, Test Accuracy 0.869 and Training loss 0.05434167587500051\n",
            "Iteration 27400: Training Accuracy 0.6228666666666667, Test Accuracy 0.8721 and Training loss 0.054115065722507336\n",
            "Iteration 27500: Training Accuracy 0.6253833333333333, Test Accuracy 0.8679 and Training loss 0.05401099434013094\n",
            "Iteration 27600: Training Accuracy 0.61445, Test Accuracy 0.864 and Training loss 0.05405030670228383\n",
            "Iteration 27700: Training Accuracy 0.6335666666666666, Test Accuracy 0.874 and Training loss 0.0536404334835183\n",
            "Iteration 27800: Training Accuracy 0.6635166666666666, Test Accuracy 0.8802 and Training loss 0.05410149618213382\n",
            "Iteration 27900: Training Accuracy 0.6299833333333333, Test Accuracy 0.8675 and Training loss 0.05356298632974697\n",
            "Iteration 28000: Training Accuracy 0.6069, Test Accuracy 0.8594 and Training loss 0.05378460993811295\n",
            "Iteration 28100: Training Accuracy 0.6358166666666667, Test Accuracy 0.8719 and Training loss 0.05329535700972408\n",
            "Iteration 28200: Training Accuracy 0.6343, Test Accuracy 0.8757 and Training loss 0.053177349437294456\n",
            "Iteration 28300: Training Accuracy 0.6357, Test Accuracy 0.8703 and Training loss 0.053079089929552584\n",
            "Iteration 28400: Training Accuracy 0.6260333333333333, Test Accuracy 0.8744 and Training loss 0.053092699472938085\n",
            "Iteration 28500: Training Accuracy 0.6596, Test Accuracy 0.8808 and Training loss 0.05343273244261876\n",
            "Iteration 28600: Training Accuracy 0.6426833333333334, Test Accuracy 0.88 and Training loss 0.052745714034998524\n",
            "Iteration 28700: Training Accuracy 0.6187, Test Accuracy 0.8667 and Training loss 0.05283822977352526\n",
            "Iteration 28800: Training Accuracy 0.6557833333333334, Test Accuracy 0.884 and Training loss 0.05260079245270772\n",
            "Iteration 28900: Training Accuracy 0.6461833333333333, Test Accuracy 0.8743 and Training loss 0.052405264849724686\n",
            "Iteration 29000: Training Accuracy 0.6091, Test Accuracy 0.8544 and Training loss 0.05283177244202276\n",
            "Iteration 29100: Training Accuracy 0.6165833333333334, Test Accuracy 0.8608 and Training loss 0.05242461362065981\n",
            "Iteration 29200: Training Accuracy 0.6485666666666666, Test Accuracy 0.871 and Training loss 0.052003551428550975\n",
            "Iteration 29300: Training Accuracy 0.6462333333333333, Test Accuracy 0.8787 and Training loss 0.052010798593307594\n",
            "Iteration 29400: Training Accuracy 0.631, Test Accuracy 0.8688 and Training loss 0.05193705159682279\n",
            "Iteration 29500: Training Accuracy 0.61575, Test Accuracy 0.8603 and Training loss 0.05192484851172089\n",
            "Iteration 29600: Training Accuracy 0.6572166666666667, Test Accuracy 0.8881 and Training loss 0.051895731292030574\n",
            "Iteration 29700: Training Accuracy 0.6239333333333333, Test Accuracy 0.8695 and Training loss 0.05161358068478793\n",
            "Iteration 29800: Training Accuracy 0.6575333333333333, Test Accuracy 0.8795 and Training loss 0.05144291869275863\n",
            "Iteration 29900: Training Accuracy 0.6522166666666667, Test Accuracy 0.8758 and Training loss 0.05139339852249521\n",
            "Iteration 30000: Training Accuracy 0.6418333333333334, Test Accuracy 0.8666 and Training loss 0.051294883876155925\n",
            "Iteration 30100: Training Accuracy 0.65695, Test Accuracy 0.8873 and Training loss 0.051453892960328165\n",
            "Iteration 30200: Training Accuracy 0.6563833333333333, Test Accuracy 0.8824 and Training loss 0.051327477643952235\n",
            "Iteration 30300: Training Accuracy 0.6563333333333333, Test Accuracy 0.8812 and Training loss 0.050899723528135134\n",
            "Iteration 30400: Training Accuracy 0.6581166666666667, Test Accuracy 0.8869 and Training loss 0.0510877980194126\n",
            "Iteration 30500: Training Accuracy 0.6212833333333333, Test Accuracy 0.8709 and Training loss 0.05078202016157273\n",
            "Iteration 30600: Training Accuracy 0.6339166666666667, Test Accuracy 0.871 and Training loss 0.05058248043387294\n",
            "Iteration 30700: Training Accuracy 0.6186333333333334, Test Accuracy 0.864 and Training loss 0.05095467560672787\n",
            "Iteration 30800: Training Accuracy 0.6196, Test Accuracy 0.8675 and Training loss 0.050537784610625865\n",
            "Iteration 30900: Training Accuracy 0.6341666666666667, Test Accuracy 0.8725 and Training loss 0.05030325441156143\n",
            "Iteration 31000: Training Accuracy 0.6405666666666666, Test Accuracy 0.8775 and Training loss 0.05027412656153208\n",
            "Iteration 31100: Training Accuracy 0.6285666666666667, Test Accuracy 0.8681 and Training loss 0.05017432104406105\n",
            "Iteration 31200: Training Accuracy 0.6507666666666667, Test Accuracy 0.8789 and Training loss 0.049998174029461454\n",
            "Iteration 31300: Training Accuracy 0.6517, Test Accuracy 0.88 and Training loss 0.04998322764022217\n",
            "Iteration 31400: Training Accuracy 0.65215, Test Accuracy 0.8738 and Training loss 0.049891288447325974\n",
            "Iteration 31500: Training Accuracy 0.6179833333333333, Test Accuracy 0.8708 and Training loss 0.05013872433778129\n",
            "Iteration 31600: Training Accuracy 0.64775, Test Accuracy 0.8778 and Training loss 0.04964652572016096\n",
            "Iteration 31700: Training Accuracy 0.6455833333333333, Test Accuracy 0.8742 and Training loss 0.04956174022305609\n",
            "Iteration 31800: Training Accuracy 0.6453333333333333, Test Accuracy 0.8604 and Training loss 0.049568258284206974\n",
            "Iteration 31900: Training Accuracy 0.64965, Test Accuracy 0.8771 and Training loss 0.04953758099807618\n",
            "Iteration 32000: Training Accuracy 0.6256833333333334, Test Accuracy 0.8694 and Training loss 0.04960755516362613\n",
            "Iteration 32100: Training Accuracy 0.62595, Test Accuracy 0.8607 and Training loss 0.0495822025899365\n",
            "Iteration 32200: Training Accuracy 0.64615, Test Accuracy 0.8723 and Training loss 0.04911639992369624\n",
            "Iteration 32300: Training Accuracy 0.65175, Test Accuracy 0.8751 and Training loss 0.049097975129723366\n",
            "Iteration 32400: Training Accuracy 0.6554166666666666, Test Accuracy 0.8765 and Training loss 0.049028712454572965\n",
            "Iteration 32500: Training Accuracy 0.6637833333333333, Test Accuracy 0.878 and Training loss 0.04945695860213813\n",
            "Iteration 32600: Training Accuracy 0.6321, Test Accuracy 0.8619 and Training loss 0.04874888542600345\n",
            "Iteration 32700: Training Accuracy 0.6478166666666667, Test Accuracy 0.8685 and Training loss 0.048835224745834245\n",
            "Iteration 32800: Training Accuracy 0.6214666666666666, Test Accuracy 0.8589 and Training loss 0.048981125067243565\n",
            "Iteration 32900: Training Accuracy 0.6658, Test Accuracy 0.8775 and Training loss 0.04924419129736173\n",
            "Iteration 33000: Training Accuracy 0.6474166666666666, Test Accuracy 0.8674 and Training loss 0.048536366912560074\n",
            "Iteration 33100: Training Accuracy 0.66595, Test Accuracy 0.8708 and Training loss 0.048887484316187835\n",
            "Iteration 33200: Training Accuracy 0.6171166666666666, Test Accuracy 0.8507 and Training loss 0.048635508886304954\n",
            "Iteration 33300: Training Accuracy 0.6332166666666666, Test Accuracy 0.8668 and Training loss 0.0482371740569579\n",
            "Iteration 33400: Training Accuracy 0.6426166666666666, Test Accuracy 0.8774 and Training loss 0.04806863192030519\n",
            "Iteration 33500: Training Accuracy 0.6336166666666667, Test Accuracy 0.8756 and Training loss 0.04807215929962627\n",
            "Iteration 33600: Training Accuracy 0.6351333333333333, Test Accuracy 0.8716 and Training loss 0.047850556503470115\n",
            "Iteration 33700: Training Accuracy 0.65845, Test Accuracy 0.8839 and Training loss 0.0478200212254685\n",
            "Iteration 33800: Training Accuracy 0.6355666666666666, Test Accuracy 0.8704 and Training loss 0.047940399931840405\n",
            "Iteration 33900: Training Accuracy 0.6561666666666667, Test Accuracy 0.8782 and Training loss 0.04781362665895919\n",
            "Iteration 34000: Training Accuracy 0.6283333333333333, Test Accuracy 0.8603 and Training loss 0.04781667649781202\n",
            "Iteration 34100: Training Accuracy 0.6424666666666666, Test Accuracy 0.8604 and Training loss 0.04773054483302205\n",
            "Iteration 34200: Training Accuracy 0.6698166666666666, Test Accuracy 0.8676 and Training loss 0.047673539674120254\n",
            "Iteration 34300: Training Accuracy 0.6367333333333334, Test Accuracy 0.8535 and Training loss 0.047558191097286845\n",
            "Iteration 34400: Training Accuracy 0.6381166666666667, Test Accuracy 0.8667 and Training loss 0.04733206988414513\n",
            "Iteration 34500: Training Accuracy 0.6619833333333334, Test Accuracy 0.8704 and Training loss 0.04727030052570729\n",
            "Iteration 34600: Training Accuracy 0.6282666666666666, Test Accuracy 0.8595 and Training loss 0.04735115714939072\n",
            "Iteration 34700: Training Accuracy 0.6468333333333334, Test Accuracy 0.8663 and Training loss 0.04695694104577282\n",
            "Iteration 34800: Training Accuracy 0.63445, Test Accuracy 0.8733 and Training loss 0.047176890946855427\n",
            "Iteration 34900: Training Accuracy 0.6500666666666667, Test Accuracy 0.8703 and Training loss 0.0469563022406892\n",
            "Iteration 35000: Training Accuracy 0.6342166666666667, Test Accuracy 0.8743 and Training loss 0.046739748134377014\n",
            "Iteration 35100: Training Accuracy 0.62745, Test Accuracy 0.8655 and Training loss 0.046806099114826076\n",
            "Iteration 35200: Training Accuracy 0.6885166666666667, Test Accuracy 0.8894 and Training loss 0.04787345600944628\n",
            "Iteration 35300: Training Accuracy 0.6351666666666667, Test Accuracy 0.8704 and Training loss 0.046621220707946234\n",
            "Iteration 35400: Training Accuracy 0.6766833333333333, Test Accuracy 0.8856 and Training loss 0.04712975028588746\n",
            "Iteration 35500: Training Accuracy 0.6633, Test Accuracy 0.8726 and Training loss 0.04635783415543716\n",
            "Iteration 35600: Training Accuracy 0.6585166666666666, Test Accuracy 0.8729 and Training loss 0.04638014825813563\n",
            "Iteration 35700: Training Accuracy 0.6597166666666666, Test Accuracy 0.8799 and Training loss 0.04658271441793069\n",
            "Iteration 35800: Training Accuracy 0.6369833333333333, Test Accuracy 0.866 and Training loss 0.04636515161115025\n",
            "Iteration 35900: Training Accuracy 0.6487166666666667, Test Accuracy 0.8788 and Training loss 0.04626228660155648\n",
            "Iteration 36000: Training Accuracy 0.6607666666666666, Test Accuracy 0.8768 and Training loss 0.04612087437759054\n",
            "Iteration 36100: Training Accuracy 0.6716833333333333, Test Accuracy 0.8872 and Training loss 0.046235424863526595\n",
            "Iteration 36200: Training Accuracy 0.6656666666666666, Test Accuracy 0.8866 and Training loss 0.04607240785686857\n",
            "Iteration 36300: Training Accuracy 0.69005, Test Accuracy 0.8938 and Training loss 0.046963523157280335\n",
            "Iteration 36400: Training Accuracy 0.6725833333333333, Test Accuracy 0.8813 and Training loss 0.04604880652394334\n",
            "Iteration 36500: Training Accuracy 0.63115, Test Accuracy 0.8689 and Training loss 0.045897817716791155\n",
            "Iteration 36600: Training Accuracy 0.65965, Test Accuracy 0.872 and Training loss 0.04565602904996485\n",
            "Iteration 36700: Training Accuracy 0.6704333333333333, Test Accuracy 0.8791 and Training loss 0.04580249436841184\n",
            "Iteration 36800: Training Accuracy 0.6366833333333334, Test Accuracy 0.8637 and Training loss 0.04544098247727245\n",
            "Iteration 36900: Training Accuracy 0.6492833333333333, Test Accuracy 0.8711 and Training loss 0.04535047020269989\n",
            "Iteration 37000: Training Accuracy 0.62825, Test Accuracy 0.8656 and Training loss 0.04551331723737964\n",
            "Iteration 37100: Training Accuracy 0.6214833333333334, Test Accuracy 0.8544 and Training loss 0.04576771199999612\n",
            "Iteration 37200: Training Accuracy 0.6577166666666666, Test Accuracy 0.8771 and Training loss 0.04535199010644235\n",
            "Iteration 37300: Training Accuracy 0.6514, Test Accuracy 0.873 and Training loss 0.04502135931538618\n",
            "Iteration 37400: Training Accuracy 0.6887333333333333, Test Accuracy 0.8853 and Training loss 0.045633683758656785\n",
            "Iteration 37500: Training Accuracy 0.6812, Test Accuracy 0.8919 and Training loss 0.045393134821997576\n",
            "Iteration 37600: Training Accuracy 0.6495833333333333, Test Accuracy 0.8735 and Training loss 0.044925853823055764\n",
            "Iteration 37700: Training Accuracy 0.6441166666666667, Test Accuracy 0.8663 and Training loss 0.044966281346785965\n",
            "Iteration 37800: Training Accuracy 0.6637333333333333, Test Accuracy 0.8818 and Training loss 0.04516956449998314\n",
            "Iteration 37900: Training Accuracy 0.6482, Test Accuracy 0.8723 and Training loss 0.04507375170177497\n",
            "Iteration 38000: Training Accuracy 0.6450833333333333, Test Accuracy 0.8799 and Training loss 0.04454111456020209\n",
            "Iteration 38100: Training Accuracy 0.636, Test Accuracy 0.8793 and Training loss 0.04458766317228658\n",
            "Iteration 38200: Training Accuracy 0.6655, Test Accuracy 0.8855 and Training loss 0.044718654160241185\n",
            "Iteration 38300: Training Accuracy 0.6504, Test Accuracy 0.8817 and Training loss 0.04440671280789873\n",
            "Iteration 38400: Training Accuracy 0.6371166666666667, Test Accuracy 0.8631 and Training loss 0.04473372817675158\n",
            "Iteration 38500: Training Accuracy 0.6551833333333333, Test Accuracy 0.8825 and Training loss 0.044584606748021005\n",
            "Iteration 38600: Training Accuracy 0.6359, Test Accuracy 0.8669 and Training loss 0.044544414099372695\n",
            "Iteration 38700: Training Accuracy 0.6432666666666667, Test Accuracy 0.8633 and Training loss 0.04422058837639751\n",
            "Iteration 38800: Training Accuracy 0.6382833333333333, Test Accuracy 0.855 and Training loss 0.0441329310766565\n",
            "Iteration 38900: Training Accuracy 0.6507666666666667, Test Accuracy 0.8618 and Training loss 0.04410543527412283\n",
            "Iteration 39000: Training Accuracy 0.6641, Test Accuracy 0.8755 and Training loss 0.04425051733878314\n",
            "Iteration 39100: Training Accuracy 0.6565666666666666, Test Accuracy 0.8592 and Training loss 0.04399179171788696\n",
            "Iteration 39200: Training Accuracy 0.6615666666666666, Test Accuracy 0.8674 and Training loss 0.0440760122108686\n",
            "Iteration 39300: Training Accuracy 0.6603666666666667, Test Accuracy 0.8694 and Training loss 0.04391624681555966\n",
            "Iteration 39400: Training Accuracy 0.6582, Test Accuracy 0.8676 and Training loss 0.043801861510807436\n",
            "Iteration 39500: Training Accuracy 0.6592333333333333, Test Accuracy 0.8741 and Training loss 0.043742684219952616\n",
            "Iteration 39600: Training Accuracy 0.6573, Test Accuracy 0.8674 and Training loss 0.04367465503315172\n",
            "Iteration 39700: Training Accuracy 0.666, Test Accuracy 0.8749 and Training loss 0.043560923430797815\n",
            "Iteration 39800: Training Accuracy 0.65905, Test Accuracy 0.8685 and Training loss 0.04345213836052489\n",
            "Iteration 39900: Training Accuracy 0.6175, Test Accuracy 0.8546 and Training loss 0.044169720190426545\n",
            "Iteration 40000: Training Accuracy 0.6539833333333334, Test Accuracy 0.877 and Training loss 0.0432469451621288\n",
            "Iteration 40100: Training Accuracy 0.6686833333333333, Test Accuracy 0.8883 and Training loss 0.043254720184511326\n",
            "Iteration 40200: Training Accuracy 0.6629666666666667, Test Accuracy 0.8765 and Training loss 0.043322323967407456\n",
            "Iteration 40300: Training Accuracy 0.6695, Test Accuracy 0.8845 and Training loss 0.04318414155160628\n",
            "Iteration 40400: Training Accuracy 0.6454833333333333, Test Accuracy 0.8675 and Training loss 0.043253881937356846\n",
            "Iteration 40500: Training Accuracy 0.65015, Test Accuracy 0.8704 and Training loss 0.04307131181772754\n",
            "Iteration 40600: Training Accuracy 0.67015, Test Accuracy 0.8813 and Training loss 0.04327545898423015\n",
            "Iteration 40700: Training Accuracy 0.6756833333333333, Test Accuracy 0.8905 and Training loss 0.04328151953802985\n",
            "Iteration 40800: Training Accuracy 0.6368333333333334, Test Accuracy 0.877 and Training loss 0.0430808212444307\n",
            "Iteration 40900: Training Accuracy 0.67885, Test Accuracy 0.8854 and Training loss 0.04315635123177431\n",
            "Iteration 41000: Training Accuracy 0.6722, Test Accuracy 0.8933 and Training loss 0.042903775974181775\n",
            "Iteration 41100: Training Accuracy 0.6509333333333334, Test Accuracy 0.8725 and Training loss 0.042648480602772355\n",
            "Iteration 41200: Training Accuracy 0.64585, Test Accuracy 0.8726 and Training loss 0.04260121131117788\n",
            "Iteration 41300: Training Accuracy 0.6376833333333334, Test Accuracy 0.8798 and Training loss 0.042721273234557565\n",
            "Iteration 41400: Training Accuracy 0.65365, Test Accuracy 0.8733 and Training loss 0.04246274716013196\n",
            "Iteration 41500: Training Accuracy 0.6808, Test Accuracy 0.8906 and Training loss 0.042826954658948285\n",
            "Iteration 41600: Training Accuracy 0.6635333333333333, Test Accuracy 0.8785 and Training loss 0.042332478855767554\n",
            "Iteration 41700: Training Accuracy 0.6532333333333333, Test Accuracy 0.8722 and Training loss 0.04228649306082398\n",
            "Iteration 41800: Training Accuracy 0.6488666666666667, Test Accuracy 0.8763 and Training loss 0.042295318695650626\n",
            "Iteration 41900: Training Accuracy 0.6716333333333333, Test Accuracy 0.8847 and Training loss 0.04227077656033552\n",
            "Iteration 42000: Training Accuracy 0.6606666666666666, Test Accuracy 0.8719 and Training loss 0.04209298349932331\n",
            "Iteration 42100: Training Accuracy 0.69895, Test Accuracy 0.8828 and Training loss 0.04298101716352065\n",
            "Iteration 42200: Training Accuracy 0.6571166666666667, Test Accuracy 0.8715 and Training loss 0.04207063715137731\n",
            "Iteration 42300: Training Accuracy 0.6637166666666666, Test Accuracy 0.874 and Training loss 0.04202512799916\n",
            "Iteration 42400: Training Accuracy 0.6699333333333334, Test Accuracy 0.8829 and Training loss 0.042073173711115026\n",
            "Iteration 42500: Training Accuracy 0.65935, Test Accuracy 0.8766 and Training loss 0.04178161235093189\n",
            "Iteration 42600: Training Accuracy 0.6564333333333333, Test Accuracy 0.8816 and Training loss 0.0418525447278794\n",
            "Iteration 42700: Training Accuracy 0.6611166666666667, Test Accuracy 0.8805 and Training loss 0.04179530396881704\n",
            "Iteration 42800: Training Accuracy 0.6492166666666667, Test Accuracy 0.8749 and Training loss 0.041743461080271514\n",
            "Iteration 42900: Training Accuracy 0.6471833333333333, Test Accuracy 0.87 and Training loss 0.04186734360674236\n",
            "Iteration 43000: Training Accuracy 0.6445, Test Accuracy 0.8769 and Training loss 0.04183927963566382\n",
            "Iteration 43100: Training Accuracy 0.6437833333333334, Test Accuracy 0.8704 and Training loss 0.041740554793181825\n",
            "Iteration 43200: Training Accuracy 0.6569833333333334, Test Accuracy 0.8666 and Training loss 0.041670248380235746\n",
            "Iteration 43300: Training Accuracy 0.6532833333333333, Test Accuracy 0.8546 and Training loss 0.04157617229577051\n",
            "Iteration 43400: Training Accuracy 0.66505, Test Accuracy 0.8786 and Training loss 0.04156473881213115\n",
            "Iteration 43500: Training Accuracy 0.63715, Test Accuracy 0.864 and Training loss 0.04183190999120197\n",
            "Iteration 43600: Training Accuracy 0.6592666666666667, Test Accuracy 0.8595 and Training loss 0.041446470698699264\n",
            "Iteration 43700: Training Accuracy 0.6913333333333334, Test Accuracy 0.8839 and Training loss 0.041609966408339014\n",
            "Iteration 43800: Training Accuracy 0.6641, Test Accuracy 0.875 and Training loss 0.0412603857754762\n",
            "Iteration 43900: Training Accuracy 0.6701166666666667, Test Accuracy 0.8797 and Training loss 0.04119348441182035\n",
            "Iteration 44000: Training Accuracy 0.6559166666666667, Test Accuracy 0.8634 and Training loss 0.041191010165323935\n",
            "Iteration 44100: Training Accuracy 0.6454, Test Accuracy 0.8652 and Training loss 0.041168256707664656\n",
            "Iteration 44200: Training Accuracy 0.6705166666666666, Test Accuracy 0.885 and Training loss 0.041041848052855046\n",
            "Iteration 44300: Training Accuracy 0.6607666666666666, Test Accuracy 0.8766 and Training loss 0.04105213430120355\n",
            "Iteration 44400: Training Accuracy 0.6582166666666667, Test Accuracy 0.8802 and Training loss 0.04083543633031266\n",
            "Iteration 44500: Training Accuracy 0.6304666666666666, Test Accuracy 0.8699 and Training loss 0.041236648128648766\n",
            "Iteration 44600: Training Accuracy 0.6521833333333333, Test Accuracy 0.8762 and Training loss 0.04094059864429963\n",
            "Iteration 44700: Training Accuracy 0.6245, Test Accuracy 0.8613 and Training loss 0.041173259195565685\n",
            "Iteration 44800: Training Accuracy 0.6487666666666667, Test Accuracy 0.8787 and Training loss 0.04068298980416815\n",
            "Iteration 44900: Training Accuracy 0.6661, Test Accuracy 0.8877 and Training loss 0.04077472440646982\n",
            "Iteration 45000: Training Accuracy 0.6714833333333333, Test Accuracy 0.882 and Training loss 0.04056769396269364\n",
            "Iteration 45100: Training Accuracy 0.6687666666666666, Test Accuracy 0.8831 and Training loss 0.040537521098041915\n",
            "Iteration 45200: Training Accuracy 0.67375, Test Accuracy 0.8899 and Training loss 0.040569793750504686\n",
            "Iteration 45300: Training Accuracy 0.6384666666666666, Test Accuracy 0.8701 and Training loss 0.04064365129200627\n",
            "Iteration 45400: Training Accuracy 0.6581833333333333, Test Accuracy 0.8725 and Training loss 0.04062255974524115\n",
            "Iteration 45500: Training Accuracy 0.6475166666666666, Test Accuracy 0.8783 and Training loss 0.040465859332182906\n",
            "Iteration 45600: Training Accuracy 0.6494, Test Accuracy 0.8889 and Training loss 0.040388200737050246\n",
            "Iteration 45700: Training Accuracy 0.66455, Test Accuracy 0.882 and Training loss 0.040373970057634864\n",
            "Iteration 45800: Training Accuracy 0.6488666666666667, Test Accuracy 0.8749 and Training loss 0.04036598815811132\n",
            "Iteration 45900: Training Accuracy 0.6665333333333333, Test Accuracy 0.8782 and Training loss 0.04045590806676203\n",
            "Iteration 46000: Training Accuracy 0.6789333333333334, Test Accuracy 0.8884 and Training loss 0.04028377900160002\n",
            "Iteration 46100: Training Accuracy 0.66515, Test Accuracy 0.8805 and Training loss 0.04012725050195694\n",
            "Iteration 46200: Training Accuracy 0.6868166666666666, Test Accuracy 0.8888 and Training loss 0.04042371085241632\n",
            "Iteration 46300: Training Accuracy 0.6592666666666667, Test Accuracy 0.8679 and Training loss 0.040078210973218426\n",
            "Iteration 46400: Training Accuracy 0.6407166666666667, Test Accuracy 0.8693 and Training loss 0.040140909228332355\n",
            "Iteration 46500: Training Accuracy 0.6599333333333334, Test Accuracy 0.8781 and Training loss 0.0398652748228901\n",
            "Iteration 46600: Training Accuracy 0.6183333333333333, Test Accuracy 0.8563 and Training loss 0.04073576201201208\n",
            "Iteration 46700: Training Accuracy 0.6587666666666666, Test Accuracy 0.871 and Training loss 0.03974365397308187\n",
            "Iteration 46800: Training Accuracy 0.6802833333333334, Test Accuracy 0.8829 and Training loss 0.03984631339171355\n",
            "Iteration 46900: Training Accuracy 0.66835, Test Accuracy 0.8888 and Training loss 0.03963168256573016\n",
            "Iteration 47000: Training Accuracy 0.6903166666666667, Test Accuracy 0.8989 and Training loss 0.03982483111962198\n",
            "Iteration 47100: Training Accuracy 0.6737833333333333, Test Accuracy 0.8945 and Training loss 0.03968985587615055\n",
            "Iteration 47200: Training Accuracy 0.67865, Test Accuracy 0.8948 and Training loss 0.03990585997516756\n",
            "Iteration 47300: Training Accuracy 0.6424333333333333, Test Accuracy 0.8657 and Training loss 0.039593896290891835\n",
            "Iteration 47400: Training Accuracy 0.7010166666666666, Test Accuracy 0.894 and Training loss 0.03997611478535939\n",
            "Iteration 47500: Training Accuracy 0.6639666666666667, Test Accuracy 0.8784 and Training loss 0.03936955639968084\n",
            "Iteration 47600: Training Accuracy 0.6629, Test Accuracy 0.8685 and Training loss 0.03935207780361398\n",
            "Iteration 47700: Training Accuracy 0.6538166666666667, Test Accuracy 0.8716 and Training loss 0.03934216061639691\n",
            "Iteration 47800: Training Accuracy 0.6412666666666667, Test Accuracy 0.882 and Training loss 0.03954629034935528\n",
            "Iteration 47900: Training Accuracy 0.6322, Test Accuracy 0.8689 and Training loss 0.039520051152134084\n",
            "Iteration 48000: Training Accuracy 0.6514666666666666, Test Accuracy 0.8812 and Training loss 0.039231771139375995\n",
            "Iteration 48100: Training Accuracy 0.6909166666666666, Test Accuracy 0.897 and Training loss 0.0395884306204564\n",
            "Iteration 48200: Training Accuracy 0.6745166666666667, Test Accuracy 0.8866 and Training loss 0.03917195391595095\n",
            "Iteration 48300: Training Accuracy 0.6878333333333333, Test Accuracy 0.8934 and Training loss 0.03928165996707166\n",
            "Iteration 48400: Training Accuracy 0.6931166666666667, Test Accuracy 0.8873 and Training loss 0.03951823539631991\n",
            "Iteration 48500: Training Accuracy 0.6597166666666666, Test Accuracy 0.8788 and Training loss 0.038911427190333726\n",
            "Iteration 48600: Training Accuracy 0.6527333333333334, Test Accuracy 0.8751 and Training loss 0.038932230340224326\n",
            "Iteration 48700: Training Accuracy 0.679, Test Accuracy 0.8936 and Training loss 0.039415358087570004\n",
            "Iteration 48800: Training Accuracy 0.6693666666666667, Test Accuracy 0.8816 and Training loss 0.03898366944286525\n",
            "Iteration 48900: Training Accuracy 0.6714166666666667, Test Accuracy 0.8848 and Training loss 0.038814088916005046\n",
            "Iteration 49000: Training Accuracy 0.6642833333333333, Test Accuracy 0.8894 and Training loss 0.03869677402269326\n",
            "Iteration 49100: Training Accuracy 0.6295166666666666, Test Accuracy 0.8638 and Training loss 0.039179387024341567\n",
            "Iteration 49200: Training Accuracy 0.65695, Test Accuracy 0.8776 and Training loss 0.03876902330000672\n",
            "Iteration 49300: Training Accuracy 0.6432166666666667, Test Accuracy 0.8542 and Training loss 0.039017148977825676\n",
            "Iteration 49400: Training Accuracy 0.66215, Test Accuracy 0.871 and Training loss 0.03878811092606915\n",
            "Iteration 49500: Training Accuracy 0.65555, Test Accuracy 0.8758 and Training loss 0.03853938281727232\n",
            "Iteration 49600: Training Accuracy 0.6305666666666667, Test Accuracy 0.852 and Training loss 0.039174943088672566\n",
            "Iteration 49700: Training Accuracy 0.6473166666666667, Test Accuracy 0.8628 and Training loss 0.038633111732661866\n",
            "Iteration 49800: Training Accuracy 0.6643833333333333, Test Accuracy 0.8681 and Training loss 0.03843594115907565\n",
            "Iteration 49900: Training Accuracy 0.6616166666666666, Test Accuracy 0.8584 and Training loss 0.03845685219026019\n",
            "Iteration 50000: Training Accuracy 0.6614833333333333, Test Accuracy 0.8644 and Training loss 0.03863265476195501\n",
            "Iteration 50100: Training Accuracy 0.6532333333333333, Test Accuracy 0.8724 and Training loss 0.03833434593570115\n",
            "Iteration 50200: Training Accuracy 0.6833666666666667, Test Accuracy 0.8841 and Training loss 0.038344836005553655\n",
            "Iteration 50300: Training Accuracy 0.69715, Test Accuracy 0.8965 and Training loss 0.03881657084201933\n",
            "Iteration 50400: Training Accuracy 0.67015, Test Accuracy 0.8848 and Training loss 0.03820184591312918\n",
            "Iteration 50500: Training Accuracy 0.6860333333333334, Test Accuracy 0.8885 and Training loss 0.038489359645302895\n",
            "Iteration 50600: Training Accuracy 0.6612333333333333, Test Accuracy 0.8708 and Training loss 0.03811414971614089\n",
            "Iteration 50700: Training Accuracy 0.6859166666666666, Test Accuracy 0.893 and Training loss 0.038434958121665704\n",
            "Iteration 50800: Training Accuracy 0.6520333333333334, Test Accuracy 0.8659 and Training loss 0.03818542645941355\n",
            "Iteration 50900: Training Accuracy 0.66765, Test Accuracy 0.884 and Training loss 0.038137182902510815\n",
            "Iteration 51000: Training Accuracy 0.6924, Test Accuracy 0.8902 and Training loss 0.038096248149079526\n",
            "Iteration 51100: Training Accuracy 0.6549333333333334, Test Accuracy 0.8765 and Training loss 0.03792381050201884\n",
            "Iteration 51200: Training Accuracy 0.65465, Test Accuracy 0.8776 and Training loss 0.03800810701799538\n",
            "Iteration 51300: Training Accuracy 0.6517666666666667, Test Accuracy 0.868 and Training loss 0.03790954918930176\n",
            "Iteration 51400: Training Accuracy 0.6443, Test Accuracy 0.8634 and Training loss 0.0379546573751063\n",
            "Iteration 51500: Training Accuracy 0.6286666666666667, Test Accuracy 0.8566 and Training loss 0.03845469643915845\n",
            "Iteration 51600: Training Accuracy 0.6582833333333333, Test Accuracy 0.8627 and Training loss 0.03784909136301647\n",
            "Iteration 51700: Training Accuracy 0.65875, Test Accuracy 0.8726 and Training loss 0.03764220147267071\n",
            "Iteration 51800: Training Accuracy 0.6426, Test Accuracy 0.8784 and Training loss 0.037700047743716665\n",
            "Iteration 51900: Training Accuracy 0.6812666666666667, Test Accuracy 0.8913 and Training loss 0.03774347703228119\n",
            "Iteration 52000: Training Accuracy 0.6798333333333333, Test Accuracy 0.8866 and Training loss 0.037585776481268075\n",
            "Iteration 52100: Training Accuracy 0.6875666666666667, Test Accuracy 0.8916 and Training loss 0.0376581994403384\n",
            "Iteration 52200: Training Accuracy 0.6875833333333333, Test Accuracy 0.8931 and Training loss 0.03763851233686546\n",
            "Iteration 52300: Training Accuracy 0.6698333333333333, Test Accuracy 0.8734 and Training loss 0.037479577043400776\n",
            "Iteration 52400: Training Accuracy 0.6293, Test Accuracy 0.8608 and Training loss 0.03825349824152644\n",
            "Iteration 52500: Training Accuracy 0.6757666666666666, Test Accuracy 0.8859 and Training loss 0.03754527781172778\n",
            "Iteration 52600: Training Accuracy 0.6886333333333333, Test Accuracy 0.8891 and Training loss 0.03743121956474854\n",
            "Iteration 52700: Training Accuracy 0.6641666666666667, Test Accuracy 0.8768 and Training loss 0.0373035269859454\n",
            "Iteration 52800: Training Accuracy 0.6967666666666666, Test Accuracy 0.8855 and Training loss 0.03761957576373408\n",
            "Iteration 52900: Training Accuracy 0.6668, Test Accuracy 0.8732 and Training loss 0.037265955948425834\n",
            "Iteration 53000: Training Accuracy 0.6878, Test Accuracy 0.8766 and Training loss 0.03730475307175008\n",
            "Iteration 53100: Training Accuracy 0.7272166666666666, Test Accuracy 0.9011 and Training loss 0.03835190202205755\n",
            "Iteration 53200: Training Accuracy 0.71575, Test Accuracy 0.9068 and Training loss 0.0380525656721674\n",
            "Iteration 53300: Training Accuracy 0.6514166666666666, Test Accuracy 0.8701 and Training loss 0.03715471873645157\n",
            "Iteration 53400: Training Accuracy 0.6691, Test Accuracy 0.8815 and Training loss 0.03699512597989652\n",
            "Iteration 53500: Training Accuracy 0.6261666666666666, Test Accuracy 0.8699 and Training loss 0.03750719206974508\n",
            "Iteration 53600: Training Accuracy 0.6624333333333333, Test Accuracy 0.8762 and Training loss 0.03701212930046618\n",
            "Iteration 53700: Training Accuracy 0.6678166666666666, Test Accuracy 0.8959 and Training loss 0.03690446950793622\n",
            "Iteration 53800: Training Accuracy 0.6356666666666667, Test Accuracy 0.8821 and Training loss 0.03735605015220232\n",
            "Iteration 53900: Training Accuracy 0.6522, Test Accuracy 0.8768 and Training loss 0.03721293277745201\n",
            "Iteration 54000: Training Accuracy 0.6735833333333333, Test Accuracy 0.8814 and Training loss 0.0369028838267505\n",
            "Iteration 54100: Training Accuracy 0.6745, Test Accuracy 0.8931 and Training loss 0.03676701310903871\n",
            "Iteration 54200: Training Accuracy 0.6649, Test Accuracy 0.8984 and Training loss 0.036855101146455425\n",
            "Iteration 54300: Training Accuracy 0.6393666666666666, Test Accuracy 0.878 and Training loss 0.037203736525147524\n",
            "Iteration 54400: Training Accuracy 0.6574666666666666, Test Accuracy 0.8857 and Training loss 0.03680646970369839\n",
            "Iteration 54500: Training Accuracy 0.7114333333333334, Test Accuracy 0.9015 and Training loss 0.03804452243540781\n",
            "Iteration 54600: Training Accuracy 0.69025, Test Accuracy 0.8947 and Training loss 0.03691101260836152\n",
            "Iteration 54700: Training Accuracy 0.6750166666666667, Test Accuracy 0.8773 and Training loss 0.036707029851199426\n",
            "Iteration 54800: Training Accuracy 0.6542833333333333, Test Accuracy 0.8789 and Training loss 0.03662708319672409\n",
            "Iteration 54900: Training Accuracy 0.6782666666666667, Test Accuracy 0.8953 and Training loss 0.036488465464611305\n",
            "Iteration 55000: Training Accuracy 0.6525166666666666, Test Accuracy 0.8875 and Training loss 0.03665171391083996\n",
            "Iteration 55100: Training Accuracy 0.6637333333333333, Test Accuracy 0.8776 and Training loss 0.036540396867296196\n",
            "Iteration 55200: Training Accuracy 0.6557333333333333, Test Accuracy 0.8832 and Training loss 0.03652643149481935\n",
            "Iteration 55300: Training Accuracy 0.6536833333333333, Test Accuracy 0.884 and Training loss 0.03636882270829996\n",
            "Iteration 55400: Training Accuracy 0.6841666666666667, Test Accuracy 0.8916 and Training loss 0.03669725012173194\n",
            "Iteration 55500: Training Accuracy 0.6486666666666666, Test Accuracy 0.8727 and Training loss 0.03622857646282957\n",
            "Iteration 55600: Training Accuracy 0.6515333333333333, Test Accuracy 0.8711 and Training loss 0.0362602703217523\n",
            "Iteration 55700: Training Accuracy 0.6183, Test Accuracy 0.8479 and Training loss 0.03704163602563798\n",
            "Iteration 55800: Training Accuracy 0.6572, Test Accuracy 0.8688 and Training loss 0.03612589833871375\n",
            "Iteration 55900: Training Accuracy 0.6442333333333333, Test Accuracy 0.8692 and Training loss 0.036260901391198176\n",
            "Iteration 56000: Training Accuracy 0.6773, Test Accuracy 0.8834 and Training loss 0.03608162002766471\n",
            "Iteration 56100: Training Accuracy 0.6613833333333333, Test Accuracy 0.8753 and Training loss 0.03602407619248161\n",
            "Iteration 56200: Training Accuracy 0.6783833333333333, Test Accuracy 0.8849 and Training loss 0.036347369338121605\n",
            "Iteration 56300: Training Accuracy 0.6862333333333334, Test Accuracy 0.8994 and Training loss 0.0362248572624715\n",
            "Iteration 56400: Training Accuracy 0.6902666666666667, Test Accuracy 0.8951 and Training loss 0.03625281975464815\n",
            "Iteration 56500: Training Accuracy 0.6754333333333333, Test Accuracy 0.8769 and Training loss 0.03597063668970741\n",
            "Iteration 56600: Training Accuracy 0.69635, Test Accuracy 0.8894 and Training loss 0.03632852874725387\n",
            "Iteration 56700: Training Accuracy 0.6784333333333333, Test Accuracy 0.8901 and Training loss 0.03595861732678747\n",
            "Iteration 56800: Training Accuracy 0.6902, Test Accuracy 0.8889 and Training loss 0.03601246299784243\n",
            "Iteration 56900: Training Accuracy 0.6754166666666667, Test Accuracy 0.8712 and Training loss 0.0359374773393478\n",
            "Iteration 57000: Training Accuracy 0.6737166666666666, Test Accuracy 0.8822 and Training loss 0.035902040965918154\n",
            "Iteration 57100: Training Accuracy 0.6714833333333333, Test Accuracy 0.8866 and Training loss 0.03593956220089991\n",
            "Iteration 57200: Training Accuracy 0.6865666666666667, Test Accuracy 0.8838 and Training loss 0.0357797515330751\n",
            "Iteration 57300: Training Accuracy 0.6491333333333333, Test Accuracy 0.8769 and Training loss 0.035800500420762306\n",
            "Iteration 57400: Training Accuracy 0.6623, Test Accuracy 0.8894 and Training loss 0.03589037835069224\n",
            "Iteration 57500: Training Accuracy 0.6752, Test Accuracy 0.8842 and Training loss 0.035568586346842075\n",
            "Iteration 57600: Training Accuracy 0.65295, Test Accuracy 0.8729 and Training loss 0.03572992609036427\n",
            "Iteration 57700: Training Accuracy 0.6587333333333333, Test Accuracy 0.88 and Training loss 0.03566116511197622\n",
            "Iteration 57800: Training Accuracy 0.6619666666666667, Test Accuracy 0.8616 and Training loss 0.03561563278009538\n",
            "Iteration 57900: Training Accuracy 0.6433833333333333, Test Accuracy 0.8706 and Training loss 0.035770372447630046\n",
            "Iteration 58000: Training Accuracy 0.6956333333333333, Test Accuracy 0.9047 and Training loss 0.03566466483719971\n",
            "Iteration 58100: Training Accuracy 0.6718666666666666, Test Accuracy 0.8928 and Training loss 0.03539745364132546\n",
            "Iteration 58200: Training Accuracy 0.6726166666666666, Test Accuracy 0.8869 and Training loss 0.03535467666880316\n",
            "Iteration 58300: Training Accuracy 0.6865166666666667, Test Accuracy 0.8968 and Training loss 0.03546994327256555\n",
            "Iteration 58400: Training Accuracy 0.6696666666666666, Test Accuracy 0.8795 and Training loss 0.03525463240965717\n",
            "Iteration 58500: Training Accuracy 0.6752833333333333, Test Accuracy 0.8862 and Training loss 0.03526295119322698\n",
            "Iteration 58600: Training Accuracy 0.6652833333333333, Test Accuracy 0.876 and Training loss 0.03527001248794046\n",
            "Iteration 58700: Training Accuracy 0.6741833333333334, Test Accuracy 0.8762 and Training loss 0.03525800562382506\n",
            "Iteration 58800: Training Accuracy 0.6628833333333334, Test Accuracy 0.8651 and Training loss 0.03534327881154284\n",
            "Iteration 58900: Training Accuracy 0.672, Test Accuracy 0.8728 and Training loss 0.03537497549258902\n",
            "Iteration 59000: Training Accuracy 0.6908, Test Accuracy 0.8924 and Training loss 0.03547931074059706\n",
            "Iteration 59100: Training Accuracy 0.6360666666666667, Test Accuracy 0.87 and Training loss 0.03554438919962416\n",
            "Iteration 59200: Training Accuracy 0.6760666666666667, Test Accuracy 0.8781 and Training loss 0.03515275953726967\n",
            "Iteration 59300: Training Accuracy 0.6406166666666666, Test Accuracy 0.8816 and Training loss 0.035267304776724726\n",
            "Iteration 59400: Training Accuracy 0.68045, Test Accuracy 0.8781 and Training loss 0.03495326930902402\n",
            "Iteration 59500: Training Accuracy 0.6680666666666667, Test Accuracy 0.8799 and Training loss 0.034981289275407446\n",
            "Iteration 59600: Training Accuracy 0.6703166666666667, Test Accuracy 0.8888 and Training loss 0.03502158684356541\n",
            "Iteration 59700: Training Accuracy 0.6972166666666667, Test Accuracy 0.8965 and Training loss 0.03503626782529398\n",
            "Iteration 59800: Training Accuracy 0.7126166666666667, Test Accuracy 0.9105 and Training loss 0.035433309467737296\n",
            "Iteration 59900: Training Accuracy 0.6721833333333334, Test Accuracy 0.8768 and Training loss 0.03484217486349212\n",
            "Iteration 60000: Training Accuracy 0.6535166666666666, Test Accuracy 0.8818 and Training loss 0.03490721700430783\n",
            "Final test accuracy for k = 200: 0.8818\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Asnwer3) The number of nodes in a neural network can have a significant impact on its accuracy. In general, more nodes will lead to higher accuracy, but it is important to note that there is a point of diminishing returns.\n",
        "\n",
        "In the above output, we can see that the final test accuracy for K=5 is 83.82%, for K=40 is 90.14%, and for K=200 is 88.18%. This shows that there is a significant increase in accuracy from K=5 to K=40, but the accuracy from K=40 to K=200 remains same .\n",
        "\n",
        "This is because the neural network has already learned most of the patterns in the data with 40 nodes. Adding more nodes does not significantly improve the accuracy of the model, but it does increase the training time.\n",
        "\n",
        "It is important to note that the number of nodes that is optimal for a particular problem will vary depending on the complexity of the problem and the size of the dataset."
      ],
      "metadata": {
        "id": "FM8zOCAm4KLV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 4) (7 pts) Train a neural network classifier with logistic loss, namely â„“(y, f (x)) = âˆ’y log(Ïƒ(f (x))) âˆ’ (1 âˆ’\n",
        "y) log(1 âˆ’ Ïƒ(f (x))) where Ïƒ(x) = 1/(1 + eâˆ’x) is the sigmoid function. Repeat step 3.**"
      ],
      "metadata": {
        "id": "XqQN_3nyCeLZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\"\"\" Sigmoid Method \"\"\"\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "\"\"\" Updating Weights\"\"\"\n",
        "def set_weights(W, v, gradient_W, gradient_v, lr, b_size):\n",
        "    v =v -lr*(gradient_v / b_size)\n",
        "    W = W -lr*(gradient_W / b_size)\n",
        "    return W,v\n",
        "\n",
        "def get_accuracy_and_quadratic_loss(x, y, W, v):\n",
        "    y_pred = np.array([feed_forward(i, W, v) for i in x])\n",
        "    acc = np.mean((sigmoid(y_pred) > 0.5) == y)\n",
        "    loss = np.mean(-y * np.log(sigmoid(y_pred)) - (1 - y) * np.log(1 - sigmoid(y_pred)))\n",
        "    return acc, loss\n",
        "\n",
        "\"\"\"Calculating Gradient\"\"\"\n",
        "def get_gradients_quadratic_loss(x_b, y_b, W, v):\n",
        "    gradient_v = np.zeros_like(v)\n",
        "    gradient_W = np.zeros_like(W)\n",
        "    for x, y in zip(x_b, y_b):\n",
        "      h = relu(np.dot(W,x))\n",
        "      f_x = np.dot(v.T,h)\n",
        "      sigmoid_fx = sigmoid(f_x)\n",
        "      error = y - sigmoid_fx\n",
        "      gradient_v += -(error) * h\n",
        "      gradient_W += -np.outer((error) * v * (h > 0), x)\n",
        "    return gradient_v, gradient_W\n",
        "\n",
        "\n",
        "def train_logistic_loss(x_train, y_train, x_test, y_test, k, epochs, b_size, lr, output_index2):\n",
        "    \"\"\"Initalizing the weights\"\"\"\n",
        "    d = x_train.shape[1]\n",
        "    W, v = xavier_initialization(d, k)\n",
        "\n",
        "    train_accuracy = []\n",
        "    test_accuracy = []\n",
        "    train_loss = []\n",
        "    test_loss = []\n",
        "    itr = 0\n",
        "\n",
        "    \"\"\" Calculating initial accuracy\"\"\"\n",
        "    train_acc, train_epoch_loss = get_accuracy_and_quadratic_loss(x_train,y_train, W,v)\n",
        "    test_acc, test_epoch_loss =get_accuracy_and_quadratic_loss(x_test,y_test, W,v)\n",
        "\n",
        "    print(f\"Iteration {itr}: Training accuracy {train_acc}, test accuracy {test_acc} and Training loss {train_epoch_loss}\")\n",
        "    train_accuracy.append(train_acc)\n",
        "    test_accuracy.append(test_acc)\n",
        "    train_loss.append(train_epoch_loss)\n",
        "    test_loss.append(test_epoch_loss)\n",
        "    \"\"\"Iterating For Each Epoch\"\"\"\n",
        "    for epoch in range(epochs):\n",
        "        indices = np.random.permutation(x_train.shape[0])\n",
        "\n",
        "        for t in range(0, x_train.shape[0], b_size):\n",
        "            batch_indices = indices[t:t+b_size]\n",
        "            x_b = x_train[batch_indices]\n",
        "            y_b = y_train[batch_indices]\n",
        "\n",
        "            \"\"\"Calculating Gradient\"\"\"\n",
        "            gradient_v, gradient_W = get_gradients_quadratic_loss(x_b, y_b, W, v)\n",
        "            \"\"\"Updating Weight\"\"\"\n",
        "            W, v = set_weights(W, v, gradient_W, gradient_v, lr, b_size)\n",
        "\n",
        "            itr += 1\n",
        "\n",
        "            \"\"\"Printing Accuracy for each 100th iteration \"\"\"\n",
        "            if itr % output_index2 == 0:\n",
        "\n",
        "              train_acc, train_epoch_loss = get_accuracy_and_quadratic_loss(x_train, y_train, W, v)\n",
        "              test_acc, test_epoch_loss = get_accuracy_and_quadratic_loss(x_test, y_test, W, v)\n",
        "\n",
        "              train_accuracy.append(train_acc)\n",
        "              test_accuracy.append(test_acc)\n",
        "              train_loss.append(train_epoch_loss)\n",
        "              test_loss.append(test_epoch_loss)\n",
        "              print(f\"Iteration {itr}: Training accuracy {train_acc}, Test accuracy {test_acc} and Training loss {train_epoch_loss}\")\n",
        "    return train_accuracy, test_accuracy, train_loss, test_loss, W, v\n",
        "\n"
      ],
      "metadata": {
        "id": "6zVPoUNQCgBu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def solution4():\n",
        "    x_train, y_train, x_test, y_test = load_data()\n",
        "    k_values = [5, 40, 200]\n",
        "    learning_rate = 0.0005\n",
        "    epochs = 10\n",
        "    b_size = 10\n",
        "    output_index = 100\n",
        "\n",
        "    for k in k_values:\n",
        "        print(f\"\\nTraining with k = {k}\")\n",
        "        train_accuracy, test_accuracy, train_loss, test_loss, W, v = train_logistic_loss(x_train, y_train, x_test, y_test, k, epochs, b_size, learning_rate, output_index)\n",
        "\n",
        "        print(f\"Final test accuracy for k = {k}: {test_accuracy[-1]}\")\n",
        "\n",
        "        plt.plot(range(0, (epochs * (x_train.shape[0] // b_size)) + output_index, output_index), train_accuracy, label=\"Training Accuracy\")\n",
        "        plt.plot(range(0, (epochs * (x_train.shape[0] // b_size)) + output_index, output_index), test_accuracy, label=\"Test Accuracy\")\n",
        "        plt.xlabel(\"Iteration\")\n",
        "        plt.ylabel(\"Accuracy\")\n",
        "        plt.title(f\"Accuracy vs Iteration (k = {k})\")\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "solution4()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PosPSaL_CiCz",
        "outputId": "f49a9e22-cd98-4dee-d05b-eca4ab938be7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training with k = 5\n",
            "Iteration 0: Training accuracy 0.5000333333333333, test accuracy 0.5122 and Training loss 0.6929641423103524\n",
            "Iteration 100: Training accuracy 0.6840333333333334, Test accuracy 0.7064 and Training loss 0.6729062052294628\n",
            "Iteration 200: Training accuracy 0.7390166666666667, Test accuracy 0.7534 and Training loss 0.6537632920927376\n",
            "Iteration 300: Training accuracy 0.7351166666666666, Test accuracy 0.7492 and Training loss 0.6367012632959256\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-197f18ed6cdc>:18: RuntimeWarning: divide by zero encountered in log\n",
            "  loss = np.mean(-y * np.log(sigmoid(y_pred)) - (1 - y) * np.log(1 - sigmoid(y_pred)))\n",
            "<ipython-input-17-197f18ed6cdc>:18: RuntimeWarning: invalid value encountered in multiply\n",
            "  loss = np.mean(-y * np.log(sigmoid(y_pred)) - (1 - y) * np.log(1 - sigmoid(y_pred)))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 400: Training accuracy 0.7588, Test accuracy 0.7712 and Training loss 0.6211321239084209\n",
            "Iteration 500: Training accuracy 0.7761833333333333, Test accuracy 0.7829 and Training loss 0.6077059765984615\n",
            "Iteration 600: Training accuracy 0.7767833333333334, Test accuracy 0.7836 and Training loss 0.5948450084608864\n",
            "Iteration 700: Training accuracy 0.7730333333333334, Test accuracy 0.7828 and Training loss 0.581535229029433\n",
            "Iteration 800: Training accuracy 0.7759, Test accuracy 0.7841 and Training loss 0.5703507893335351\n",
            "Iteration 900: Training accuracy 0.78045, Test accuracy 0.7867 and Training loss 0.5599389028229242\n",
            "Iteration 1000: Training accuracy 0.78025, Test accuracy 0.7875 and Training loss 0.5499236499477838\n",
            "Iteration 1100: Training accuracy 0.78445, Test accuracy 0.7878 and Training loss 0.5417384860917897\n",
            "Iteration 1200: Training accuracy 0.7821833333333333, Test accuracy 0.7881 and Training loss 0.5314491526189846\n",
            "Iteration 1300: Training accuracy 0.7827166666666666, Test accuracy 0.7897 and Training loss 0.5241702498876074\n",
            "Iteration 1400: Training accuracy 0.7805833333333333, Test accuracy 0.7912 and Training loss 0.5176393886159408\n",
            "Iteration 1500: Training accuracy 0.7828166666666667, Test accuracy 0.7909 and Training loss 0.5105219293418087\n",
            "Iteration 1600: Training accuracy 0.7887, Test accuracy 0.7904 and Training loss 0.5048517701697451\n",
            "Iteration 1700: Training accuracy 0.7908, Test accuracy 0.7909 and Training loss 0.49934373224916767\n",
            "Iteration 1800: Training accuracy 0.7920666666666667, Test accuracy 0.7933 and Training loss 0.4931511651213011\n",
            "Iteration 1900: Training accuracy 0.7938833333333334, Test accuracy 0.7926 and Training loss 0.48803514213546056\n",
            "Iteration 2000: Training accuracy 0.7938666666666667, Test accuracy 0.799 and Training loss 0.48178860077123814\n",
            "Iteration 2100: Training accuracy 0.7962833333333333, Test accuracy 0.8012 and Training loss 0.47684541373642275\n",
            "Iteration 2200: Training accuracy 0.7993666666666667, Test accuracy 0.7971 and Training loss 0.4733439994436352\n",
            "Iteration 2300: Training accuracy 0.8002, Test accuracy 0.7975 and Training loss 0.46917677536376384\n",
            "Iteration 2400: Training accuracy 0.8014666666666667, Test accuracy 0.7988 and Training loss 0.46468687674448045\n",
            "Iteration 2500: Training accuracy 0.8021333333333334, Test accuracy 0.801 and Training loss 0.46061445751674457\n",
            "Iteration 2600: Training accuracy 0.8003166666666667, Test accuracy 0.8049 and Training loss 0.4580299173249341\n",
            "Iteration 2700: Training accuracy 0.8012666666666667, Test accuracy 0.803 and Training loss 0.45493434422085316\n",
            "Iteration 2800: Training accuracy 0.8027833333333333, Test accuracy 0.8028 and Training loss 0.45151540596834683\n",
            "Iteration 2900: Training accuracy 0.8044333333333333, Test accuracy 0.8008 and Training loss 0.4483484381058773\n",
            "Iteration 3000: Training accuracy 0.8057833333333333, Test accuracy 0.8013 and Training loss 0.4455872496700011\n",
            "Iteration 3100: Training accuracy 0.80765, Test accuracy 0.8014 and Training loss 0.4429585818848837\n",
            "Iteration 3200: Training accuracy 0.8080166666666667, Test accuracy 0.8077 and Training loss 0.43992336973998025\n",
            "Iteration 3300: Training accuracy 0.808, Test accuracy 0.809 and Training loss 0.4376632768394681\n",
            "Iteration 3400: Training accuracy 0.8096333333333333, Test accuracy 0.8028 and Training loss 0.43489121678702314\n",
            "Iteration 3500: Training accuracy 0.8109166666666666, Test accuracy 0.8098 and Training loss 0.43224770946394797\n",
            "Iteration 3600: Training accuracy 0.8121666666666667, Test accuracy 0.8084 and Training loss 0.42990862025472715\n",
            "Iteration 3700: Training accuracy 0.8134, Test accuracy 0.8008 and Training loss 0.42861095527792653\n",
            "Iteration 3800: Training accuracy 0.81395, Test accuracy 0.8069 and Training loss 0.42585378228291215\n",
            "Iteration 3900: Training accuracy 0.8129666666666666, Test accuracy 0.8114 and Training loss 0.42436491553488503\n",
            "Iteration 4000: Training accuracy 0.81485, Test accuracy 0.8081 and Training loss 0.42227409864125287\n",
            "Iteration 4100: Training accuracy 0.8155333333333333, Test accuracy 0.8063 and Training loss 0.4203031544663051\n",
            "Iteration 4200: Training accuracy 0.8161333333333334, Test accuracy 0.8039 and Training loss 0.41853685878711894\n",
            "Iteration 4300: Training accuracy 0.8148333333333333, Test accuracy 0.806 and Training loss 0.41647615576779384\n",
            "Iteration 4400: Training accuracy 0.8156333333333333, Test accuracy 0.8081 and Training loss 0.41464468374903496\n",
            "Iteration 4500: Training accuracy 0.81515, Test accuracy 0.8099 and Training loss 0.4131984314569324\n",
            "Iteration 4600: Training accuracy 0.8178333333333333, Test accuracy 0.8053 and Training loss 0.4115314654737067\n",
            "Iteration 4700: Training accuracy 0.8179666666666666, Test accuracy 0.8051 and Training loss 0.4101079324645044\n",
            "Iteration 4800: Training accuracy 0.8168666666666666, Test accuracy 0.8133 and Training loss 0.4083541715664717\n",
            "Iteration 4900: Training accuracy 0.8170833333333334, Test accuracy 0.816 and Training loss 0.4073261171688495\n",
            "Iteration 5000: Training accuracy 0.8182, Test accuracy 0.8144 and Training loss 0.4057512516843054\n",
            "Iteration 5100: Training accuracy 0.8193166666666667, Test accuracy 0.8129 and Training loss 0.40428653412630094\n",
            "Iteration 5200: Training accuracy 0.8197666666666666, Test accuracy 0.8147 and Training loss 0.40275097588453523\n",
            "Iteration 5300: Training accuracy 0.82015, Test accuracy 0.8148 and Training loss 0.4014888412065702\n",
            "Iteration 5400: Training accuracy 0.8209333333333333, Test accuracy 0.8095 and Training loss 0.39995185279763645\n",
            "Iteration 5500: Training accuracy 0.8213666666666667, Test accuracy 0.809 and Training loss 0.39854628249874274\n",
            "Iteration 5600: Training accuracy 0.8215333333333333, Test accuracy 0.813 and Training loss 0.3970769784793334\n",
            "Iteration 5700: Training accuracy 0.82225, Test accuracy 0.8153 and Training loss 0.39586847194503233\n",
            "Iteration 5800: Training accuracy 0.8225666666666667, Test accuracy 0.8179 and Training loss 0.39486803651985564\n",
            "Iteration 5900: Training accuracy 0.8230666666666666, Test accuracy 0.8193 and Training loss 0.3937456036511656\n",
            "Iteration 6000: Training accuracy 0.8245833333333333, Test accuracy 0.8116 and Training loss 0.39271497284790907\n",
            "Iteration 6100: Training accuracy 0.82615, Test accuracy 0.8124 and Training loss 0.39159501564411203\n",
            "Iteration 6200: Training accuracy 0.8258, Test accuracy 0.8167 and Training loss 0.39021700173664287\n",
            "Iteration 6300: Training accuracy 0.8260833333333333, Test accuracy 0.8129 and Training loss 0.3894299395276611\n",
            "Iteration 6400: Training accuracy 0.8269166666666666, Test accuracy 0.8154 and Training loss 0.3879598117677069\n",
            "Iteration 6500: Training accuracy 0.82645, Test accuracy 0.8074 and Training loss 0.3879738654390001\n",
            "Iteration 6600: Training accuracy 0.8276333333333333, Test accuracy 0.8106 and Training loss 0.3860515526175272\n",
            "Iteration 6700: Training accuracy 0.8285666666666667, Test accuracy 0.8171 and Training loss 0.38433540189351234\n",
            "Iteration 6800: Training accuracy 0.82865, Test accuracy 0.8151 and Training loss 0.38366314415274044\n",
            "Iteration 6900: Training accuracy 0.82835, Test accuracy 0.8203 and Training loss 0.38270842785764997\n",
            "Iteration 7000: Training accuracy 0.8292833333333334, Test accuracy 0.8146 and Training loss 0.3821188894811341\n",
            "Iteration 7100: Training accuracy 0.8312333333333334, Test accuracy 0.8191 and Training loss 0.380805639061388\n",
            "Iteration 7200: Training accuracy 0.83255, Test accuracy 0.8192 and Training loss 0.37989352372423996\n",
            "Iteration 7300: Training accuracy 0.83415, Test accuracy 0.8212 and Training loss 0.3792101065170537\n",
            "Iteration 7400: Training accuracy 0.8348333333333333, Test accuracy 0.8242 and Training loss 0.3781975415245322\n",
            "Iteration 7500: Training accuracy 0.8347333333333333, Test accuracy 0.8251 and Training loss 0.3771891050568604\n",
            "Iteration 7600: Training accuracy 0.8343833333333334, Test accuracy 0.8257 and Training loss 0.3759907403234623\n",
            "Iteration 7700: Training accuracy 0.8336166666666667, Test accuracy 0.8234 and Training loss 0.3751206080305315\n",
            "Iteration 7800: Training accuracy 0.8352666666666667, Test accuracy 0.8267 and Training loss 0.3741146039868752\n",
            "Iteration 7900: Training accuracy 0.8353833333333334, Test accuracy 0.8294 and Training loss 0.3735522100505542\n",
            "Iteration 8000: Training accuracy 0.8354833333333334, Test accuracy 0.8267 and Training loss 0.37228903270155056\n",
            "Iteration 8100: Training accuracy 0.83565, Test accuracy 0.8296 and Training loss 0.3717150843185254\n",
            "Iteration 8200: Training accuracy 0.8363166666666667, Test accuracy 0.8274 and Training loss 0.3708407734623603\n",
            "Iteration 8300: Training accuracy 0.83695, Test accuracy 0.8288 and Training loss 0.36996692824166166\n",
            "Iteration 8400: Training accuracy 0.8379166666666666, Test accuracy 0.8304 and Training loss 0.36949151628691096\n",
            "Iteration 8500: Training accuracy 0.8387833333333333, Test accuracy 0.8303 and Training loss 0.36851368846254645\n",
            "Iteration 8600: Training accuracy 0.8387, Test accuracy 0.8293 and Training loss 0.3676338218608256\n",
            "Iteration 8700: Training accuracy 0.8392333333333334, Test accuracy 0.8279 and Training loss 0.3669186721161979\n",
            "Iteration 8800: Training accuracy 0.8403666666666667, Test accuracy 0.8277 and Training loss 0.36640588001588315\n",
            "Iteration 8900: Training accuracy 0.8391833333333333, Test accuracy 0.8281 and Training loss 0.3653920756887064\n",
            "Iteration 9000: Training accuracy 0.8408333333333333, Test accuracy 0.8336 and Training loss 0.36479532652234864\n",
            "Iteration 9100: Training accuracy 0.8400166666666666, Test accuracy 0.8284 and Training loss 0.3640930994426731\n",
            "Iteration 9200: Training accuracy 0.8399166666666666, Test accuracy 0.8343 and Training loss 0.36371994556673926\n",
            "Iteration 9300: Training accuracy 0.83955, Test accuracy 0.8309 and Training loss 0.3628899443818199\n",
            "Iteration 9400: Training accuracy 0.8399, Test accuracy 0.8335 and Training loss 0.36252441201250396\n",
            "Iteration 9500: Training accuracy 0.8393333333333334, Test accuracy 0.8295 and Training loss 0.3616462812335407\n",
            "Iteration 9600: Training accuracy 0.84005, Test accuracy 0.8321 and Training loss 0.3609671159911311\n",
            "Iteration 9700: Training accuracy 0.8400833333333333, Test accuracy 0.8318 and Training loss 0.36027642361963447\n",
            "Iteration 9800: Training accuracy 0.8405166666666667, Test accuracy 0.829 and Training loss 0.3595885346830157\n",
            "Iteration 9900: Training accuracy 0.8413833333333334, Test accuracy 0.8351 and Training loss 0.3587406053870981\n",
            "Iteration 10000: Training accuracy 0.8408833333333333, Test accuracy 0.8368 and Training loss 0.3583753347370925\n",
            "Iteration 10100: Training accuracy 0.8422166666666666, Test accuracy 0.8373 and Training loss 0.35746278137047816\n",
            "Iteration 10200: Training accuracy 0.84315, Test accuracy 0.8341 and Training loss 0.3564908769540281\n",
            "Iteration 10300: Training accuracy 0.8431333333333333, Test accuracy 0.8344 and Training loss 0.3558979797776408\n",
            "Iteration 10400: Training accuracy 0.8438333333333333, Test accuracy 0.8375 and Training loss 0.3551485885738996\n",
            "Iteration 10500: Training accuracy 0.8436666666666667, Test accuracy 0.835 and Training loss 0.35458635679514633\n",
            "Iteration 10600: Training accuracy 0.8442166666666666, Test accuracy 0.8399 and Training loss 0.3543736566019533\n",
            "Iteration 10700: Training accuracy 0.8466333333333333, Test accuracy 0.8418 and Training loss 0.35336639125753583\n",
            "Iteration 10800: Training accuracy 0.8459666666666666, Test accuracy 0.841 and Training loss 0.3528624973344768\n",
            "Iteration 10900: Training accuracy 0.84725, Test accuracy 0.8394 and Training loss 0.35218205578793826\n",
            "Iteration 11000: Training accuracy 0.8473833333333334, Test accuracy 0.8343 and Training loss 0.35178206191638584\n",
            "Iteration 11100: Training accuracy 0.8473, Test accuracy 0.8433 and Training loss 0.3514420866089472\n",
            "Iteration 11200: Training accuracy 0.8480333333333333, Test accuracy 0.8419 and Training loss 0.3504527456693071\n",
            "Iteration 11300: Training accuracy 0.8468833333333333, Test accuracy 0.8391 and Training loss 0.35001330316180773\n",
            "Iteration 11400: Training accuracy 0.8473166666666667, Test accuracy 0.8394 and Training loss 0.3493519266112673\n",
            "Iteration 11500: Training accuracy 0.8476833333333333, Test accuracy 0.8431 and Training loss 0.34885403645849206\n",
            "Iteration 11600: Training accuracy 0.8493333333333334, Test accuracy 0.8423 and Training loss 0.3481020774959509\n",
            "Iteration 11700: Training accuracy 0.8507166666666667, Test accuracy 0.8405 and Training loss 0.3479262148470674\n",
            "Iteration 11800: Training accuracy 0.8502, Test accuracy 0.843 and Training loss 0.34699298825271463\n",
            "Iteration 11900: Training accuracy 0.85035, Test accuracy 0.8458 and Training loss 0.34642285988539734\n",
            "Iteration 12000: Training accuracy 0.8493, Test accuracy 0.8422 and Training loss 0.3459682373519065\n",
            "Iteration 12100: Training accuracy 0.84955, Test accuracy 0.8462 and Training loss 0.3454827947989165\n",
            "Iteration 12200: Training accuracy 0.8511166666666666, Test accuracy 0.8456 and Training loss 0.3448618363118955\n",
            "Iteration 12300: Training accuracy 0.8514333333333334, Test accuracy 0.846 and Training loss 0.3444209128816925\n",
            "Iteration 12400: Training accuracy 0.8517166666666667, Test accuracy 0.8496 and Training loss 0.34413979002225636\n",
            "Iteration 12500: Training accuracy 0.8497166666666667, Test accuracy 0.8511 and Training loss 0.3450915188251791\n",
            "Iteration 12600: Training accuracy 0.8508, Test accuracy 0.8499 and Training loss 0.34385712212954583\n",
            "Iteration 12700: Training accuracy 0.8520666666666666, Test accuracy 0.8472 and Training loss 0.34283837350704266\n",
            "Iteration 12800: Training accuracy 0.8522, Test accuracy 0.8487 and Training loss 0.3423124376440463\n",
            "Iteration 12900: Training accuracy 0.85055, Test accuracy 0.8438 and Training loss 0.3419427059849937\n",
            "Iteration 13000: Training accuracy 0.8493166666666667, Test accuracy 0.8413 and Training loss 0.3415234321805284\n",
            "Iteration 13100: Training accuracy 0.8496666666666667, Test accuracy 0.8402 and Training loss 0.34128497768063665\n",
            "Iteration 13200: Training accuracy 0.8499, Test accuracy 0.8462 and Training loss 0.340772275790514\n",
            "Iteration 13300: Training accuracy 0.8511333333333333, Test accuracy 0.8503 and Training loss 0.3413715926418627\n",
            "Iteration 13400: Training accuracy 0.85175, Test accuracy 0.8442 and Training loss 0.33957494787402237\n",
            "Iteration 13500: Training accuracy 0.8510666666666666, Test accuracy 0.8428 and Training loss 0.33964917369466163\n",
            "Iteration 13600: Training accuracy 0.85305, Test accuracy 0.8452 and Training loss 0.33883503198287374\n",
            "Iteration 13700: Training accuracy 0.8533, Test accuracy 0.8474 and Training loss 0.3384059801083056\n",
            "Iteration 13800: Training accuracy 0.8545, Test accuracy 0.8476 and Training loss 0.33787710783137265\n",
            "Iteration 13900: Training accuracy 0.85545, Test accuracy 0.8483 and Training loss 0.33739757717855223\n",
            "Iteration 14000: Training accuracy 0.857, Test accuracy 0.8517 and Training loss 0.33681476994079695\n",
            "Iteration 14100: Training accuracy 0.8569166666666667, Test accuracy 0.8505 and Training loss 0.33632110028819145\n",
            "Iteration 14200: Training accuracy 0.8544166666666667, Test accuracy 0.8444 and Training loss 0.33641118320320684\n",
            "Iteration 14300: Training accuracy 0.8543166666666666, Test accuracy 0.8463 and Training loss 0.3357101647134487\n",
            "Iteration 14400: Training accuracy 0.8570833333333333, Test accuracy 0.8478 and Training loss 0.3353803818634483\n",
            "Iteration 14500: Training accuracy 0.86075, Test accuracy 0.8553 and Training loss 0.3347854331808733\n",
            "Iteration 14600: Training accuracy 0.8584333333333334, Test accuracy 0.8485 and Training loss 0.33445103136674914\n",
            "Iteration 14700: Training accuracy 0.8578, Test accuracy 0.8503 and Training loss 0.33391671455500765\n",
            "Iteration 14800: Training accuracy 0.8576666666666667, Test accuracy 0.8509 and Training loss 0.3335291996093689\n",
            "Iteration 14900: Training accuracy 0.8579333333333333, Test accuracy 0.851 and Training loss 0.33318476313474726\n",
            "Iteration 15000: Training accuracy 0.8596, Test accuracy 0.8511 and Training loss 0.3327922775129007\n",
            "Iteration 15100: Training accuracy 0.85905, Test accuracy 0.8495 and Training loss 0.33265086140318345\n",
            "Iteration 15200: Training accuracy 0.8599166666666667, Test accuracy 0.8553 and Training loss 0.3322722422133955\n",
            "Iteration 15300: Training accuracy 0.8600833333333333, Test accuracy 0.8543 and Training loss 0.3316583364585483\n",
            "Iteration 15400: Training accuracy 0.8607666666666667, Test accuracy 0.8547 and Training loss 0.3313742106085401\n",
            "Iteration 15500: Training accuracy 0.8599166666666667, Test accuracy 0.8514 and Training loss 0.3318910411918922\n",
            "Iteration 15600: Training accuracy 0.8592166666666666, Test accuracy 0.8474 and Training loss 0.3319099852088615\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-197f18ed6cdc>:7: RuntimeWarning: overflow encountered in exp\n",
            "  return 1 / (1 + np.exp(-x))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 15700: Training accuracy 0.8627, Test accuracy 0.8568 and Training loss 0.3305657690340897\n",
            "Iteration 15800: Training accuracy 0.8623666666666666, Test accuracy 0.8576 and Training loss 0.3301150947384395\n",
            "Iteration 15900: Training accuracy 0.8626666666666667, Test accuracy 0.8608 and Training loss 0.3302260971512191\n",
            "Iteration 16000: Training accuracy 0.8597333333333333, Test accuracy 0.8536 and Training loss 0.3296411383325774\n",
            "Iteration 16100: Training accuracy 0.86335, Test accuracy 0.8588 and Training loss 0.329039805150133\n",
            "Iteration 16200: Training accuracy 0.864, Test accuracy 0.8579 and Training loss 0.32865674464768246\n",
            "Iteration 16300: Training accuracy 0.8636333333333334, Test accuracy 0.8572 and Training loss 0.3285513347137718\n",
            "Iteration 16400: Training accuracy 0.8647833333333333, Test accuracy 0.865 and Training loss 0.32846387732415516\n",
            "Iteration 16500: Training accuracy 0.86455, Test accuracy 0.8587 and Training loss 0.32779736116777214\n",
            "Iteration 16600: Training accuracy 0.8629333333333333, Test accuracy 0.8583 and Training loss 0.3274039496066538\n",
            "Iteration 16700: Training accuracy 0.8623333333333333, Test accuracy 0.8545 and Training loss 0.3274441602338104\n",
            "Iteration 16800: Training accuracy 0.8647833333333333, Test accuracy 0.8593 and Training loss 0.32684562010772544\n",
            "Iteration 16900: Training accuracy 0.86375, Test accuracy 0.857 and Training loss 0.32643343987038115\n",
            "Iteration 17000: Training accuracy 0.8663333333333333, Test accuracy 0.8658 and Training loss 0.32637446463112096\n",
            "Iteration 17100: Training accuracy 0.8648833333333333, Test accuracy 0.8598 and Training loss 0.3258593440799701\n",
            "Iteration 17200: Training accuracy 0.8656, Test accuracy 0.8612 and Training loss 0.32564150625457167\n",
            "Iteration 17300: Training accuracy 0.8659666666666667, Test accuracy 0.862 and Training loss 0.3252107955840449\n",
            "Iteration 17400: Training accuracy 0.8647666666666667, Test accuracy 0.8607 and Training loss 0.3248743292452293\n",
            "Iteration 17500: Training accuracy 0.8622166666666666, Test accuracy 0.8579 and Training loss 0.3251991447940395\n",
            "Iteration 17600: Training accuracy 0.86575, Test accuracy 0.8627 and Training loss 0.32424264196188446\n",
            "Iteration 17700: Training accuracy 0.8674, Test accuracy 0.8674 and Training loss 0.32393249272984115\n",
            "Iteration 17800: Training accuracy 0.8661333333333333, Test accuracy 0.8671 and Training loss 0.32415363610485\n",
            "Iteration 17900: Training accuracy 0.8659833333333333, Test accuracy 0.8671 and Training loss 0.3236084177878704\n",
            "Iteration 18000: Training accuracy 0.8631666666666666, Test accuracy 0.8615 and Training loss 0.3233931664354007\n",
            "Iteration 18100: Training accuracy 0.8655333333333334, Test accuracy 0.8661 and Training loss 0.3227855013338117\n",
            "Iteration 18200: Training accuracy 0.8653833333333333, Test accuracy 0.8636 and Training loss 0.32279777630307116\n",
            "Iteration 18300: Training accuracy 0.8655833333333334, Test accuracy 0.8641 and Training loss 0.32237911158276694\n",
            "Iteration 18400: Training accuracy 0.8633833333333333, Test accuracy 0.8607 and Training loss 0.323135084145716\n",
            "Iteration 18500: Training accuracy 0.8672166666666666, Test accuracy 0.8679 and Training loss 0.321767235373747\n",
            "Iteration 18600: Training accuracy 0.86645, Test accuracy 0.8681 and Training loss 0.3219606845272904\n",
            "Iteration 18700: Training accuracy 0.8666166666666667, Test accuracy 0.867 and Training loss 0.3209224068327706\n",
            "Iteration 18800: Training accuracy 0.8684, Test accuracy 0.8708 and Training loss 0.32067830083326765\n",
            "Iteration 18900: Training accuracy 0.8669666666666667, Test accuracy 0.8669 and Training loss 0.320401397278351\n",
            "Iteration 19000: Training accuracy 0.8655333333333334, Test accuracy 0.8636 and Training loss 0.3203126991953839\n",
            "Iteration 19100: Training accuracy 0.86225, Test accuracy 0.8567 and Training loss 0.3218433288429615\n",
            "Iteration 19200: Training accuracy 0.8653666666666666, Test accuracy 0.862 and Training loss 0.3199590759418392\n",
            "Iteration 19300: Training accuracy 0.8667666666666667, Test accuracy 0.8636 and Training loss 0.31965218531576184\n",
            "Iteration 19400: Training accuracy 0.8662166666666666, Test accuracy 0.8656 and Training loss 0.31946114814208015\n",
            "Iteration 19500: Training accuracy 0.8683666666666666, Test accuracy 0.8658 and Training loss 0.31891570856938134\n",
            "Iteration 19600: Training accuracy 0.8697333333333334, Test accuracy 0.8685 and Training loss 0.3187237838585917\n",
            "Iteration 19700: Training accuracy 0.8701833333333333, Test accuracy 0.8707 and Training loss 0.3187215115808242\n",
            "Iteration 19800: Training accuracy 0.86985, Test accuracy 0.8696 and Training loss 0.3180286975271612\n",
            "Iteration 19900: Training accuracy 0.8698, Test accuracy 0.8696 and Training loss 0.3177280386823214\n",
            "Iteration 20000: Training accuracy 0.8714166666666666, Test accuracy 0.8721 and Training loss 0.317761899226499\n",
            "Iteration 20100: Training accuracy 0.86995, Test accuracy 0.8695 and Training loss 0.31726218124270406\n",
            "Iteration 20200: Training accuracy 0.8682, Test accuracy 0.8651 and Training loss 0.31754351874184067\n",
            "Iteration 20300: Training accuracy 0.8690333333333333, Test accuracy 0.8654 and Training loss 0.31792623550021354\n",
            "Iteration 20400: Training accuracy 0.8720833333333333, Test accuracy 0.8724 and Training loss 0.3168027449312182\n",
            "Iteration 20500: Training accuracy 0.8741166666666667, Test accuracy 0.8746 and Training loss 0.316900734012839\n",
            "Iteration 20600: Training accuracy 0.8717666666666667, Test accuracy 0.8726 and Training loss 0.3164041760231352\n",
            "Iteration 20700: Training accuracy 0.8709166666666667, Test accuracy 0.8706 and Training loss 0.31661152109551294\n",
            "Iteration 20800: Training accuracy 0.8717333333333334, Test accuracy 0.8734 and Training loss 0.31593621775650776\n",
            "Iteration 20900: Training accuracy 0.8706166666666667, Test accuracy 0.8723 and Training loss 0.31551629947616994\n",
            "Iteration 21000: Training accuracy 0.8724166666666666, Test accuracy 0.8731 and Training loss 0.31526587966137165\n",
            "Iteration 21100: Training accuracy 0.8699, Test accuracy 0.8699 and Training loss 0.31594165306488975\n",
            "Iteration 21200: Training accuracy 0.8704833333333334, Test accuracy 0.8713 and Training loss 0.31477931839026063\n",
            "Iteration 21300: Training accuracy 0.8722166666666666, Test accuracy 0.8736 and Training loss 0.31463582159705267\n",
            "Iteration 21400: Training accuracy 0.8717166666666667, Test accuracy 0.8727 and Training loss 0.31440835031940967\n",
            "Iteration 21500: Training accuracy 0.8687666666666667, Test accuracy 0.8694 and Training loss 0.31453757401633925\n",
            "Iteration 21600: Training accuracy 0.8716666666666667, Test accuracy 0.873 and Training loss 0.3138465448593777\n",
            "Iteration 21700: Training accuracy 0.8708833333333333, Test accuracy 0.8736 and Training loss 0.3144294791816036\n",
            "Iteration 21800: Training accuracy 0.8719166666666667, Test accuracy 0.8712 and Training loss 0.31385298076176016\n",
            "Iteration 21900: Training accuracy 0.87315, Test accuracy 0.8749 and Training loss 0.31342047173213367\n",
            "Iteration 22000: Training accuracy 0.8715166666666667, Test accuracy 0.8716 and Training loss 0.31307582457378685\n",
            "Iteration 22100: Training accuracy 0.8730166666666667, Test accuracy 0.8744 and Training loss 0.3128307201061507\n",
            "Iteration 22200: Training accuracy 0.87005, Test accuracy 0.868 and Training loss 0.31290947077152986\n",
            "Iteration 22300: Training accuracy 0.8740166666666667, Test accuracy 0.8746 and Training loss 0.31315762370517375\n",
            "Iteration 22400: Training accuracy 0.8751833333333333, Test accuracy 0.8765 and Training loss 0.3126510024628733\n",
            "Iteration 22500: Training accuracy 0.875, Test accuracy 0.8741 and Training loss 0.31183308013010375\n",
            "Iteration 22600: Training accuracy 0.8748666666666667, Test accuracy 0.8751 and Training loss 0.31164699730385303\n",
            "Iteration 22700: Training accuracy 0.8705833333333334, Test accuracy 0.8692 and Training loss 0.3116426419045655\n",
            "Iteration 22800: Training accuracy 0.8718333333333333, Test accuracy 0.8687 and Training loss 0.31208616662971717\n",
            "Iteration 22900: Training accuracy 0.8748666666666667, Test accuracy 0.8737 and Training loss 0.31121088007896514\n",
            "Iteration 23000: Training accuracy 0.8761833333333333, Test accuracy 0.8769 and Training loss 0.3110731754505781\n",
            "Iteration 23100: Training accuracy 0.8731166666666667, Test accuracy 0.8733 and Training loss 0.3109573072606082\n",
            "Iteration 23200: Training accuracy 0.8738833333333333, Test accuracy 0.875 and Training loss 0.310609981310152\n",
            "Iteration 23300: Training accuracy 0.8752333333333333, Test accuracy 0.8758 and Training loss 0.3109397953317049\n",
            "Iteration 23400: Training accuracy 0.8740333333333333, Test accuracy 0.8731 and Training loss 0.3101955297005768\n",
            "Iteration 23500: Training accuracy 0.8747833333333334, Test accuracy 0.8745 and Training loss 0.30991952812678975\n",
            "Iteration 23600: Training accuracy 0.8771166666666667, Test accuracy 0.8781 and Training loss 0.30973720534800325\n",
            "Iteration 23700: Training accuracy 0.8767, Test accuracy 0.8775 and Training loss 0.3095331805593743\n",
            "Iteration 23800: Training accuracy 0.8760833333333333, Test accuracy 0.8763 and Training loss 0.30923726889016584\n",
            "Iteration 23900: Training accuracy 0.8758166666666667, Test accuracy 0.876 and Training loss 0.3089487247499768\n",
            "Iteration 24000: Training accuracy 0.8755666666666667, Test accuracy 0.8787 and Training loss 0.3110891316715956\n",
            "Iteration 24100: Training accuracy 0.8701333333333333, Test accuracy 0.8685 and Training loss 0.30909430648646086\n",
            "Iteration 24200: Training accuracy 0.87325, Test accuracy 0.8739 and Training loss 0.30873563351030825\n",
            "Iteration 24300: Training accuracy 0.8741833333333333, Test accuracy 0.8775 and Training loss 0.3102086058074682\n",
            "Iteration 24400: Training accuracy 0.8744333333333333, Test accuracy 0.8758 and Training loss 0.3090234214072573\n",
            "Iteration 24500: Training accuracy 0.8723833333333333, Test accuracy 0.8686 and Training loss 0.30930334629814793\n",
            "Iteration 24600: Training accuracy 0.8750166666666667, Test accuracy 0.8728 and Training loss 0.3086683101293214\n",
            "Iteration 24700: Training accuracy 0.87905, Test accuracy 0.8775 and Training loss 0.30783787019832787\n",
            "Iteration 24800: Training accuracy 0.8780833333333333, Test accuracy 0.8761 and Training loss 0.3084702275658284\n",
            "Iteration 24900: Training accuracy 0.8786333333333334, Test accuracy 0.877 and Training loss 0.30794833458301124\n",
            "Iteration 25000: Training accuracy 0.87535, Test accuracy 0.8728 and Training loss 0.30835263273480046\n",
            "Iteration 25100: Training accuracy 0.8747166666666667, Test accuracy 0.8727 and Training loss 0.308178808284366\n",
            "Iteration 25200: Training accuracy 0.87905, Test accuracy 0.8814 and Training loss 0.3075106064928708\n",
            "Iteration 25300: Training accuracy 0.87805, Test accuracy 0.8775 and Training loss 0.3072627823238218\n",
            "Iteration 25400: Training accuracy 0.8806833333333334, Test accuracy 0.8838 and Training loss 0.30757140505397496\n",
            "Iteration 25500: Training accuracy 0.8785166666666666, Test accuracy 0.8804 and Training loss 0.306871039869603\n",
            "Iteration 25600: Training accuracy 0.8778, Test accuracy 0.8805 and Training loss 0.3066112401824735\n",
            "Iteration 25700: Training accuracy 0.87395, Test accuracy 0.8723 and Training loss 0.30694938771628144\n",
            "Iteration 25800: Training accuracy 0.8756833333333334, Test accuracy 0.8743 and Training loss 0.30640957854097006\n",
            "Iteration 25900: Training accuracy 0.8768666666666667, Test accuracy 0.877 and Training loss 0.3057451579017609\n",
            "Iteration 26000: Training accuracy 0.8778833333333333, Test accuracy 0.8793 and Training loss 0.3054797981512721\n",
            "Iteration 26100: Training accuracy 0.8776666666666667, Test accuracy 0.8797 and Training loss 0.3055036524942274\n",
            "Iteration 26200: Training accuracy 0.87625, Test accuracy 0.8781 and Training loss 0.3052841226819671\n",
            "Iteration 26300: Training accuracy 0.8777166666666667, Test accuracy 0.8798 and Training loss 0.3051478039015005\n",
            "Iteration 26400: Training accuracy 0.8771166666666667, Test accuracy 0.8799 and Training loss 0.30498584172607823\n",
            "Iteration 26500: Training accuracy 0.8778833333333333, Test accuracy 0.8821 and Training loss 0.30500556811992824\n",
            "Iteration 26600: Training accuracy 0.8787166666666667, Test accuracy 0.882 and Training loss 0.30459459254520926\n",
            "Iteration 26700: Training accuracy 0.8770166666666667, Test accuracy 0.8808 and Training loss 0.30470118107309657\n",
            "Iteration 26800: Training accuracy 0.8775666666666667, Test accuracy 0.881 and Training loss 0.30451692289925414\n",
            "Iteration 26900: Training accuracy 0.8790833333333333, Test accuracy 0.8808 and Training loss 0.30398350089707243\n",
            "Iteration 27000: Training accuracy 0.8788666666666667, Test accuracy 0.8799 and Training loss 0.3038855847448284\n",
            "Iteration 27100: Training accuracy 0.8794833333333333, Test accuracy 0.8805 and Training loss 0.30425490288693086\n",
            "Iteration 27200: Training accuracy 0.87945, Test accuracy 0.8823 and Training loss 0.30396833521847233\n",
            "Iteration 27300: Training accuracy 0.8788833333333333, Test accuracy 0.8801 and Training loss 0.30322750301379614\n",
            "Iteration 27400: Training accuracy 0.87815, Test accuracy 0.8809 and Training loss 0.3031364145384561\n",
            "Iteration 27500: Training accuracy 0.8790666666666667, Test accuracy 0.8837 and Training loss 0.3040317383036946\n",
            "Iteration 27600: Training accuracy 0.8788333333333334, Test accuracy 0.8822 and Training loss 0.3028211152617361\n",
            "Iteration 27700: Training accuracy 0.8796333333333334, Test accuracy 0.8842 and Training loss 0.30335614965869895\n",
            "Iteration 27800: Training accuracy 0.87925, Test accuracy 0.8835 and Training loss 0.302357455170063\n",
            "Iteration 27900: Training accuracy 0.8757833333333334, Test accuracy 0.8799 and Training loss 0.30246677790200943\n",
            "Iteration 28000: Training accuracy 0.8769166666666667, Test accuracy 0.8803 and Training loss 0.3021233675263303\n",
            "Iteration 28100: Training accuracy 0.8759333333333333, Test accuracy 0.8784 and Training loss 0.30327443731923975\n",
            "Iteration 28200: Training accuracy 0.8786833333333334, Test accuracy 0.8824 and Training loss 0.3018247887438846\n",
            "Iteration 28300: Training accuracy 0.8813, Test accuracy 0.8871 and Training loss 0.30196200781551397\n",
            "Iteration 28400: Training accuracy 0.8804333333333333, Test accuracy 0.886 and Training loss 0.30164634709072863\n",
            "Iteration 28500: Training accuracy 0.8822, Test accuracy 0.8868 and Training loss 0.3013835494720196\n",
            "Iteration 28600: Training accuracy 0.88355, Test accuracy 0.889 and Training loss 0.30126809856290393\n",
            "Iteration 28700: Training accuracy 0.8830333333333333, Test accuracy 0.8878 and Training loss 0.30133070234613285\n",
            "Iteration 28800: Training accuracy 0.88415, Test accuracy 0.8909 and Training loss 0.3027379716999881\n",
            "Iteration 28900: Training accuracy 0.8836166666666667, Test accuracy 0.8883 and Training loss 0.30104125295861445\n",
            "Iteration 29000: Training accuracy 0.8828, Test accuracy 0.8865 and Training loss 0.3008899941311589\n",
            "Iteration 29100: Training accuracy 0.8806333333333334, Test accuracy 0.8836 and Training loss 0.3003532198300029\n",
            "Iteration 29200: Training accuracy 0.8813833333333333, Test accuracy 0.8838 and Training loss 0.3004217440267945\n",
            "Iteration 29300: Training accuracy 0.8843333333333333, Test accuracy 0.8875 and Training loss 0.30057855254406596\n",
            "Iteration 29400: Training accuracy 0.8829, Test accuracy 0.8857 and Training loss 0.3000672789130391\n",
            "Iteration 29500: Training accuracy 0.8823166666666666, Test accuracy 0.886 and Training loss 0.2998215479931214\n",
            "Iteration 29600: Training accuracy 0.8801833333333333, Test accuracy 0.8815 and Training loss 0.301125288220757\n",
            "Iteration 29700: Training accuracy 0.88525, Test accuracy 0.8885 and Training loss 0.2997945150467189\n",
            "Iteration 29800: Training accuracy 0.8865666666666666, Test accuracy 0.8921 and Training loss 0.30039277080110127\n",
            "Iteration 29900: Training accuracy 0.8841166666666667, Test accuracy 0.8904 and Training loss 0.2994979625104445\n",
            "Iteration 30000: Training accuracy 0.8834166666666666, Test accuracy 0.8886 and Training loss 0.29934571203051663\n",
            "Iteration 30100: Training accuracy 0.8848166666666667, Test accuracy 0.8912 and Training loss 0.2996964358574449\n",
            "Iteration 30200: Training accuracy 0.8814833333333333, Test accuracy 0.8882 and Training loss 0.2991350885032526\n",
            "Iteration 30300: Training accuracy 0.8838333333333334, Test accuracy 0.8911 and Training loss 0.2994030577674734\n",
            "Iteration 30400: Training accuracy 0.8827333333333334, Test accuracy 0.8871 and Training loss 0.2985401436980206\n",
            "Iteration 30500: Training accuracy 0.88195, Test accuracy 0.8883 and Training loss 0.29831291299592144\n",
            "Iteration 30600: Training accuracy 0.8836833333333334, Test accuracy 0.8891 and Training loss 0.29832376136567107\n",
            "Iteration 30700: Training accuracy 0.8862333333333333, Test accuracy 0.8916 and Training loss 0.2983392803398007\n",
            "Iteration 30800: Training accuracy 0.8831, Test accuracy 0.8866 and Training loss 0.29836187683308163\n",
            "Iteration 30900: Training accuracy 0.8815, Test accuracy 0.8864 and Training loss 0.2981481709280762\n",
            "Iteration 31000: Training accuracy 0.8819, Test accuracy 0.8877 and Training loss 0.29822585467421253\n",
            "Iteration 31100: Training accuracy 0.8834, Test accuracy 0.8907 and Training loss 0.29810511465766665\n",
            "Iteration 31200: Training accuracy 0.8832333333333333, Test accuracy 0.8894 and Training loss 0.29782017939936695\n",
            "Iteration 31300: Training accuracy 0.8809666666666667, Test accuracy 0.8876 and Training loss 0.2977176240877572\n",
            "Iteration 31400: Training accuracy 0.8807, Test accuracy 0.8888 and Training loss 0.29776208685624617\n",
            "Iteration 31500: Training accuracy 0.8832333333333333, Test accuracy 0.8905 and Training loss 0.297119486360721\n",
            "Iteration 31600: Training accuracy 0.88365, Test accuracy 0.8902 and Training loss 0.296875255225375\n",
            "Iteration 31700: Training accuracy 0.8840666666666667, Test accuracy 0.891 and Training loss 0.2971446446363161\n",
            "Iteration 31800: Training accuracy 0.8844666666666666, Test accuracy 0.8911 and Training loss 0.29683216138155033\n",
            "Iteration 31900: Training accuracy 0.8848666666666667, Test accuracy 0.8914 and Training loss 0.2966580040118324\n",
            "Iteration 32000: Training accuracy 0.8850166666666667, Test accuracy 0.8907 and Training loss 0.29659322299219015\n",
            "Iteration 32100: Training accuracy 0.8857666666666667, Test accuracy 0.8916 and Training loss 0.296273469412441\n",
            "Iteration 32200: Training accuracy 0.88485, Test accuracy 0.891 and Training loss 0.2962254358760269\n",
            "Iteration 32300: Training accuracy 0.8848, Test accuracy 0.8898 and Training loss 0.29596936637565674\n",
            "Iteration 32400: Training accuracy 0.8838, Test accuracy 0.8886 and Training loss 0.2961531043067938\n",
            "Iteration 32500: Training accuracy 0.88305, Test accuracy 0.8869 and Training loss 0.29700142790683187\n",
            "Iteration 32600: Training accuracy 0.8869666666666667, Test accuracy 0.8937 and Training loss 0.2958161168841738\n",
            "Iteration 32700: Training accuracy 0.8839, Test accuracy 0.8899 and Training loss 0.2955401821121782\n",
            "Iteration 32800: Training accuracy 0.8857, Test accuracy 0.8928 and Training loss 0.29524361579426867\n",
            "Iteration 32900: Training accuracy 0.8856166666666667, Test accuracy 0.8907 and Training loss 0.2952585364982774\n",
            "Iteration 33000: Training accuracy 0.88465, Test accuracy 0.89 and Training loss 0.2953235249773109\n",
            "Iteration 33100: Training accuracy 0.8849666666666667, Test accuracy 0.8894 and Training loss 0.29540736222113656\n",
            "Iteration 33200: Training accuracy 0.8864166666666666, Test accuracy 0.8932 and Training loss 0.2951989628426821\n",
            "Iteration 33300: Training accuracy 0.8852666666666666, Test accuracy 0.8937 and Training loss 0.2950579663571058\n",
            "Iteration 33400: Training accuracy 0.88565, Test accuracy 0.8915 and Training loss 0.2950899842075631\n",
            "Iteration 33500: Training accuracy 0.8859, Test accuracy 0.8922 and Training loss 0.29432919538509494\n",
            "Iteration 33600: Training accuracy 0.88435, Test accuracy 0.8903 and Training loss 0.29491168749796604\n",
            "Iteration 33700: Training accuracy 0.88485, Test accuracy 0.8918 and Training loss 0.2951788007795006\n",
            "Iteration 33800: Training accuracy 0.8866833333333334, Test accuracy 0.8935 and Training loss 0.2941230152108267\n",
            "Iteration 33900: Training accuracy 0.8848, Test accuracy 0.8905 and Training loss 0.29441592505311653\n",
            "Iteration 34000: Training accuracy 0.8879666666666667, Test accuracy 0.8939 and Training loss 0.29365017148723477\n",
            "Iteration 34100: Training accuracy 0.8867666666666667, Test accuracy 0.8912 and Training loss 0.29350636906654426\n",
            "Iteration 34200: Training accuracy 0.8879, Test accuracy 0.8959 and Training loss 0.29633777252614907\n",
            "Iteration 34300: Training accuracy 0.8869833333333333, Test accuracy 0.8929 and Training loss 0.29330316331398054\n",
            "Iteration 34400: Training accuracy 0.8865833333333333, Test accuracy 0.8919 and Training loss 0.29317540434899675\n",
            "Iteration 34500: Training accuracy 0.8852666666666666, Test accuracy 0.8899 and Training loss 0.29301971138439376\n",
            "Iteration 34600: Training accuracy 0.8833666666666666, Test accuracy 0.8877 and Training loss 0.2934406968414225\n",
            "Iteration 34700: Training accuracy 0.8823833333333333, Test accuracy 0.8868 and Training loss 0.2935267618307307\n",
            "Iteration 34800: Training accuracy 0.8823, Test accuracy 0.8849 and Training loss 0.29360548294441996\n",
            "Iteration 34900: Training accuracy 0.8827166666666667, Test accuracy 0.8868 and Training loss 0.2928988235707758\n",
            "Iteration 35000: Training accuracy 0.8874, Test accuracy 0.8921 and Training loss 0.29233685992628017\n",
            "Iteration 35100: Training accuracy 0.88825, Test accuracy 0.8926 and Training loss 0.29252534157007265\n",
            "Iteration 35200: Training accuracy 0.8879, Test accuracy 0.8941 and Training loss 0.2922694009752643\n",
            "Iteration 35300: Training accuracy 0.8847833333333334, Test accuracy 0.8883 and Training loss 0.29326811859581814\n",
            "Iteration 35400: Training accuracy 0.8882666666666666, Test accuracy 0.8942 and Training loss 0.29202851919450173\n",
            "Iteration 35500: Training accuracy 0.8892166666666667, Test accuracy 0.8957 and Training loss 0.292662836637913\n",
            "Iteration 35600: Training accuracy 0.8905166666666666, Test accuracy 0.897 and Training loss 0.2927118889080558\n",
            "Iteration 35700: Training accuracy 0.8891666666666667, Test accuracy 0.894 and Training loss 0.29190715659349464\n",
            "Iteration 35800: Training accuracy 0.8908166666666667, Test accuracy 0.8963 and Training loss 0.2914134976601485\n",
            "Iteration 35900: Training accuracy 0.8908333333333334, Test accuracy 0.8965 and Training loss 0.29135817035540623\n",
            "Iteration 36000: Training accuracy 0.8902166666666667, Test accuracy 0.8979 and Training loss 0.29155554688227125\n",
            "Iteration 36100: Training accuracy 0.8890666666666667, Test accuracy 0.895 and Training loss 0.2910674070403566\n",
            "Iteration 36200: Training accuracy 0.8868666666666667, Test accuracy 0.8927 and Training loss 0.2910080372414781\n",
            "Iteration 36300: Training accuracy 0.8889333333333334, Test accuracy 0.8953 and Training loss 0.2907544160605672\n",
            "Iteration 36400: Training accuracy 0.8859166666666667, Test accuracy 0.8935 and Training loss 0.2911373794216922\n",
            "Iteration 36500: Training accuracy 0.8853333333333333, Test accuracy 0.8925 and Training loss 0.2915122654493972\n",
            "Iteration 36600: Training accuracy 0.8900833333333333, Test accuracy 0.8945 and Training loss 0.290450106159373\n",
            "Iteration 36700: Training accuracy 0.8914666666666666, Test accuracy 0.8992 and Training loss 0.29115245158844794\n",
            "Iteration 36800: Training accuracy 0.8904666666666666, Test accuracy 0.8964 and Training loss 0.2901226426057688\n",
            "Iteration 36900: Training accuracy 0.8897166666666667, Test accuracy 0.8963 and Training loss 0.29029858855645524\n",
            "Iteration 37000: Training accuracy 0.8912166666666667, Test accuracy 0.8993 and Training loss 0.29007350384703473\n",
            "Iteration 37100: Training accuracy 0.8922, Test accuracy 0.8991 and Training loss 0.29000740672099995\n",
            "Iteration 37200: Training accuracy 0.89075, Test accuracy 0.8962 and Training loss 0.2905455076644598\n",
            "Iteration 37300: Training accuracy 0.8941333333333333, Test accuracy 0.8991 and Training loss 0.2897235118898532\n",
            "Iteration 37400: Training accuracy 0.8923666666666666, Test accuracy 0.8971 and Training loss 0.2897100598724094\n",
            "Iteration 37500: Training accuracy 0.8911333333333333, Test accuracy 0.897 and Training loss 0.2895924338625802\n",
            "Iteration 37600: Training accuracy 0.8931166666666667, Test accuracy 0.8987 and Training loss 0.2895446616403526\n",
            "Iteration 37700: Training accuracy 0.8920333333333333, Test accuracy 0.8984 and Training loss 0.2889690734464788\n",
            "Iteration 37800: Training accuracy 0.88815, Test accuracy 0.8941 and Training loss 0.2889217114883828\n",
            "Iteration 37900: Training accuracy 0.8877333333333334, Test accuracy 0.8939 and Training loss 0.2891600848877541\n",
            "Iteration 38000: Training accuracy 0.8902166666666667, Test accuracy 0.898 and Training loss 0.2890627248240136\n",
            "Iteration 38100: Training accuracy 0.88895, Test accuracy 0.8964 and Training loss 0.2885752215540913\n",
            "Iteration 38200: Training accuracy 0.8871, Test accuracy 0.8922 and Training loss 0.2893227178712405\n",
            "Iteration 38300: Training accuracy 0.88785, Test accuracy 0.8946 and Training loss 0.28824867356815054\n",
            "Iteration 38400: Training accuracy 0.89045, Test accuracy 0.8983 and Training loss 0.28927983752052533\n",
            "Iteration 38500: Training accuracy 0.8903333333333333, Test accuracy 0.8954 and Training loss 0.28798219140481796\n",
            "Iteration 38600: Training accuracy 0.8911833333333333, Test accuracy 0.8976 and Training loss 0.2882268426445787\n",
            "Iteration 38700: Training accuracy 0.8913, Test accuracy 0.899 and Training loss 0.2888689026161582\n",
            "Iteration 38800: Training accuracy 0.8938833333333334, Test accuracy 0.8994 and Training loss 0.2880012475044383\n",
            "Iteration 38900: Training accuracy 0.89265, Test accuracy 0.8975 and Training loss 0.28740440198643996\n",
            "Iteration 39000: Training accuracy 0.8909166666666667, Test accuracy 0.8971 and Training loss 0.2873438700411127\n",
            "Iteration 39100: Training accuracy 0.8933666666666666, Test accuracy 0.8998 and Training loss 0.28726026040536484\n",
            "Iteration 39200: Training accuracy 0.8921, Test accuracy 0.8979 and Training loss 0.28719645591876186\n",
            "Iteration 39300: Training accuracy 0.8923666666666666, Test accuracy 0.8987 and Training loss 0.2872081957441573\n",
            "Iteration 39400: Training accuracy 0.89125, Test accuracy 0.8982 and Training loss 0.288288473407421\n",
            "Iteration 39500: Training accuracy 0.8928333333333334, Test accuracy 0.9002 and Training loss 0.2867644045009672\n",
            "Iteration 39600: Training accuracy 0.8924333333333333, Test accuracy 0.9024 and Training loss 0.2870969568166938\n",
            "Iteration 39700: Training accuracy 0.89115, Test accuracy 0.8999 and Training loss 0.28701742791012913\n",
            "Iteration 39800: Training accuracy 0.8909333333333334, Test accuracy 0.8995 and Training loss 0.28698418909216555\n",
            "Iteration 39900: Training accuracy 0.89155, Test accuracy 0.9011 and Training loss 0.28623908132248194\n",
            "Iteration 40000: Training accuracy 0.8930333333333333, Test accuracy 0.9023 and Training loss 0.28619590191153516\n",
            "Iteration 40100: Training accuracy 0.89175, Test accuracy 0.9017 and Training loss 0.2862850959602048\n",
            "Iteration 40200: Training accuracy 0.8949333333333334, Test accuracy 0.9056 and Training loss 0.2865904965163953\n",
            "Iteration 40300: Training accuracy 0.8954333333333333, Test accuracy 0.9064 and Training loss 0.2859384547991353\n",
            "Iteration 40400: Training accuracy 0.8939666666666667, Test accuracy 0.9049 and Training loss 0.28576272369303\n",
            "Iteration 40500: Training accuracy 0.89495, Test accuracy 0.9069 and Training loss 0.28586818066587544\n",
            "Iteration 40600: Training accuracy 0.8948833333333334, Test accuracy 0.9049 and Training loss 0.2854408363956995\n",
            "Iteration 40700: Training accuracy 0.89565, Test accuracy 0.9038 and Training loss 0.2854213149718694\n",
            "Iteration 40800: Training accuracy 0.8941, Test accuracy 0.9035 and Training loss 0.2855936271982539\n",
            "Iteration 40900: Training accuracy 0.8966333333333333, Test accuracy 0.9075 and Training loss 0.28669625202638255\n",
            "Iteration 41000: Training accuracy 0.89425, Test accuracy 0.903 and Training loss 0.2849230106594287\n",
            "Iteration 41100: Training accuracy 0.8929166666666667, Test accuracy 0.9012 and Training loss 0.2846857798032776\n",
            "Iteration 41200: Training accuracy 0.8930333333333333, Test accuracy 0.902 and Training loss 0.28508276342584443\n",
            "Iteration 41300: Training accuracy 0.8904333333333333, Test accuracy 0.8975 and Training loss 0.2861787437205895\n",
            "Iteration 41400: Training accuracy 0.8923666666666666, Test accuracy 0.9009 and Training loss 0.28458085193796107\n",
            "Iteration 41500: Training accuracy 0.8920666666666667, Test accuracy 0.8999 and Training loss 0.28424894307550724\n",
            "Iteration 41600: Training accuracy 0.8920166666666667, Test accuracy 0.901 and Training loss 0.2841786702584713\n",
            "Iteration 41700: Training accuracy 0.8951833333333333, Test accuracy 0.9038 and Training loss 0.2840693780580371\n",
            "Iteration 41800: Training accuracy 0.8931833333333333, Test accuracy 0.9006 and Training loss 0.2839806958705158\n",
            "Iteration 41900: Training accuracy 0.8918666666666667, Test accuracy 0.8992 and Training loss 0.2844528041021854\n",
            "Iteration 42000: Training accuracy 0.8914333333333333, Test accuracy 0.8997 and Training loss 0.28354471688874905\n",
            "Iteration 42100: Training accuracy 0.89265, Test accuracy 0.9021 and Training loss 0.28375291329654023\n",
            "Iteration 42200: Training accuracy 0.8911166666666667, Test accuracy 0.9001 and Training loss 0.2833771518741198\n",
            "Iteration 42300: Training accuracy 0.8916, Test accuracy 0.9005 and Training loss 0.28338938442381256\n",
            "Iteration 42400: Training accuracy 0.89125, Test accuracy 0.9001 and Training loss 0.2834125900800004\n",
            "Iteration 42500: Training accuracy 0.8912166666666667, Test accuracy 0.8998 and Training loss 0.2831377846516892\n",
            "Iteration 42600: Training accuracy 0.8914, Test accuracy 0.9003 and Training loss 0.28312840656064625\n",
            "Iteration 42700: Training accuracy 0.8917166666666667, Test accuracy 0.9001 and Training loss 0.283346732094222\n",
            "Iteration 42800: Training accuracy 0.8940333333333333, Test accuracy 0.9018 and Training loss 0.28278103990017345\n",
            "Iteration 42900: Training accuracy 0.89435, Test accuracy 0.9021 and Training loss 0.28251980306455093\n",
            "Iteration 43000: Training accuracy 0.8944, Test accuracy 0.9024 and Training loss 0.2825432138822172\n",
            "Iteration 43100: Training accuracy 0.8900833333333333, Test accuracy 0.8973 and Training loss 0.28456313932316024\n",
            "Iteration 43200: Training accuracy 0.8925833333333333, Test accuracy 0.9012 and Training loss 0.2823682155215955\n",
            "Iteration 43300: Training accuracy 0.8943833333333333, Test accuracy 0.9026 and Training loss 0.2820592864906345\n",
            "Iteration 43400: Training accuracy 0.8947333333333334, Test accuracy 0.9042 and Training loss 0.2832229517849469\n",
            "Iteration 43500: Training accuracy 0.89615, Test accuracy 0.9051 and Training loss 0.28306684316454694\n",
            "Iteration 43600: Training accuracy 0.8961833333333333, Test accuracy 0.905 and Training loss 0.2825113451912628\n",
            "Iteration 43700: Training accuracy 0.89475, Test accuracy 0.9036 and Training loss 0.28174871005479607\n",
            "Iteration 43800: Training accuracy 0.8959166666666667, Test accuracy 0.9046 and Training loss 0.28135230196407807\n",
            "Iteration 43900: Training accuracy 0.89575, Test accuracy 0.9039 and Training loss 0.2815842033086499\n",
            "Iteration 44000: Training accuracy 0.8974666666666666, Test accuracy 0.9054 and Training loss 0.28143222902006204\n",
            "Iteration 44100: Training accuracy 0.8967, Test accuracy 0.9047 and Training loss 0.2810905849080275\n",
            "Iteration 44200: Training accuracy 0.8934166666666666, Test accuracy 0.9007 and Training loss 0.28251888610232545\n",
            "Iteration 44300: Training accuracy 0.8976, Test accuracy 0.9044 and Training loss 0.2811630677605659\n",
            "Iteration 44400: Training accuracy 0.89805, Test accuracy 0.9056 and Training loss 0.2807589210794154\n",
            "Iteration 44500: Training accuracy 0.8974833333333333, Test accuracy 0.9037 and Training loss 0.2809839221532272\n",
            "Iteration 44600: Training accuracy 0.8991833333333333, Test accuracy 0.9073 and Training loss 0.28030032120454507\n",
            "Iteration 44700: Training accuracy 0.8979833333333334, Test accuracy 0.9063 and Training loss 0.28030112516654165\n",
            "Iteration 44800: Training accuracy 0.8991833333333333, Test accuracy 0.9076 and Training loss 0.27993210776002597\n",
            "Iteration 44900: Training accuracy 0.8966, Test accuracy 0.9032 and Training loss 0.28089000843484463\n",
            "Iteration 45000: Training accuracy 0.9004666666666666, Test accuracy 0.9078 and Training loss 0.2798464022913318\n",
            "Iteration 45100: Training accuracy 0.89905, Test accuracy 0.9077 and Training loss 0.2795254124946876\n",
            "Iteration 45200: Training accuracy 0.8977, Test accuracy 0.9073 and Training loss 0.2794039925148418\n",
            "Iteration 45300: Training accuracy 0.8968666666666667, Test accuracy 0.9061 and Training loss 0.27941332020797405\n",
            "Iteration 45400: Training accuracy 0.8965666666666666, Test accuracy 0.9046 and Training loss 0.27914927359607666\n",
            "Iteration 45500: Training accuracy 0.8978, Test accuracy 0.9049 and Training loss 0.2791761600099757\n",
            "Iteration 45600: Training accuracy 0.8964333333333333, Test accuracy 0.9044 and Training loss 0.27898679133386456\n",
            "Iteration 45700: Training accuracy 0.8983, Test accuracy 0.9064 and Training loss 0.27956642499220546\n",
            "Iteration 45800: Training accuracy 0.89885, Test accuracy 0.907 and Training loss 0.2790668553119871\n",
            "Iteration 45900: Training accuracy 0.8980833333333333, Test accuracy 0.9067 and Training loss 0.27848084531421635\n",
            "Iteration 46000: Training accuracy 0.8974333333333333, Test accuracy 0.905 and Training loss 0.2788077207033753\n",
            "Iteration 46100: Training accuracy 0.8982, Test accuracy 0.906 and Training loss 0.2782347315304748\n",
            "Iteration 46200: Training accuracy 0.89865, Test accuracy 0.9061 and Training loss 0.27810445310684156\n",
            "Iteration 46300: Training accuracy 0.8980166666666667, Test accuracy 0.9061 and Training loss 0.27797502054435597\n",
            "Iteration 46400: Training accuracy 0.8986166666666666, Test accuracy 0.9077 and Training loss 0.2796753025392167\n",
            "Iteration 46500: Training accuracy 0.8946333333333333, Test accuracy 0.9053 and Training loss 0.27789819197156446\n",
            "Iteration 46600: Training accuracy 0.8952, Test accuracy 0.9058 and Training loss 0.2777440651954776\n",
            "Iteration 46700: Training accuracy 0.8976666666666666, Test accuracy 0.9071 and Training loss 0.27749852994808477\n",
            "Iteration 46800: Training accuracy 0.8969333333333334, Test accuracy 0.9062 and Training loss 0.2777207516560514\n",
            "Iteration 46900: Training accuracy 0.8977333333333334, Test accuracy 0.9068 and Training loss 0.2773878997477039\n",
            "Iteration 47000: Training accuracy 0.8955833333333333, Test accuracy 0.9062 and Training loss 0.2772776802462065\n",
            "Iteration 47100: Training accuracy 0.8963, Test accuracy 0.9071 and Training loss 0.2774698868521355\n",
            "Iteration 47200: Training accuracy 0.8963833333333333, Test accuracy 0.9083 and Training loss 0.27686833787349746\n",
            "Iteration 47300: Training accuracy 0.8971166666666667, Test accuracy 0.908 and Training loss 0.276885048163549\n",
            "Iteration 47400: Training accuracy 0.8956, Test accuracy 0.9069 and Training loss 0.2765836218213007\n",
            "Iteration 47500: Training accuracy 0.8968666666666667, Test accuracy 0.9068 and Training loss 0.27735638889360203\n",
            "Iteration 47600: Training accuracy 0.8986333333333333, Test accuracy 0.9088 and Training loss 0.27706982750068043\n",
            "Iteration 47700: Training accuracy 0.8987, Test accuracy 0.9085 and Training loss 0.27608784801151354\n",
            "Iteration 47800: Training accuracy 0.8970166666666667, Test accuracy 0.9069 and Training loss 0.2765682313760951\n",
            "Iteration 47900: Training accuracy 0.8957166666666667, Test accuracy 0.9053 and Training loss 0.27656425954568603\n",
            "Iteration 48000: Training accuracy 0.8989666666666667, Test accuracy 0.909 and Training loss 0.27569363975081035\n",
            "Iteration 48100: Training accuracy 0.8972333333333333, Test accuracy 0.9063 and Training loss 0.2760737398050786\n",
            "Iteration 48200: Training accuracy 0.8966666666666666, Test accuracy 0.904 and Training loss 0.2769284245690029\n",
            "Iteration 48300: Training accuracy 0.90015, Test accuracy 0.9072 and Training loss 0.2759497013111792\n",
            "Iteration 48400: Training accuracy 0.8976, Test accuracy 0.9038 and Training loss 0.2765436932319526\n",
            "Iteration 48500: Training accuracy 0.90035, Test accuracy 0.9077 and Training loss 0.27558144365194415\n",
            "Iteration 48600: Training accuracy 0.90145, Test accuracy 0.9113 and Training loss 0.27499859925873316\n",
            "Iteration 48700: Training accuracy 0.9027333333333334, Test accuracy 0.9105 and Training loss 0.2759990689685815\n",
            "Iteration 48800: Training accuracy 0.90135, Test accuracy 0.9103 and Training loss 0.27477456451331134\n",
            "Iteration 48900: Training accuracy 0.8985666666666666, Test accuracy 0.9062 and Training loss 0.27535202299263745\n",
            "Iteration 49000: Training accuracy 0.8976166666666666, Test accuracy 0.904 and Training loss 0.2761824946251667\n",
            "Iteration 49100: Training accuracy 0.90135, Test accuracy 0.9089 and Training loss 0.2741722887084648\n",
            "Iteration 49200: Training accuracy 0.90095, Test accuracy 0.9078 and Training loss 0.2740876526349779\n",
            "Iteration 49300: Training accuracy 0.9016833333333333, Test accuracy 0.9101 and Training loss 0.27411674150841675\n",
            "Iteration 49400: Training accuracy 0.9031666666666667, Test accuracy 0.9109 and Training loss 0.2741490159480797\n",
            "Iteration 49500: Training accuracy 0.9014333333333333, Test accuracy 0.91 and Training loss 0.2739446776223352\n",
            "Iteration 49600: Training accuracy 0.9003333333333333, Test accuracy 0.9105 and Training loss 0.27372163110337816\n",
            "Iteration 49700: Training accuracy 0.8995833333333333, Test accuracy 0.9096 and Training loss 0.27320426848068324\n",
            "Iteration 49800: Training accuracy 0.8977333333333334, Test accuracy 0.9085 and Training loss 0.2732590434801424\n",
            "Iteration 49900: Training accuracy 0.8969166666666667, Test accuracy 0.9057 and Training loss 0.2735625802850871\n",
            "Iteration 50000: Training accuracy 0.89845, Test accuracy 0.9099 and Training loss 0.27310883681435116\n",
            "Iteration 50100: Training accuracy 0.8990166666666667, Test accuracy 0.9091 and Training loss 0.2731973855667453\n",
            "Iteration 50200: Training accuracy 0.8997833333333334, Test accuracy 0.9099 and Training loss 0.2725860643065361\n",
            "Iteration 50300: Training accuracy 0.8980166666666667, Test accuracy 0.9067 and Training loss 0.2727043993456758\n",
            "Iteration 50400: Training accuracy 0.90125, Test accuracy 0.9099 and Training loss 0.2731824301602659\n",
            "Iteration 50500: Training accuracy 0.9000166666666667, Test accuracy 0.9084 and Training loss 0.27213118995926866\n",
            "Iteration 50600: Training accuracy 0.9019666666666667, Test accuracy 0.9092 and Training loss 0.2723908290896361\n",
            "Iteration 50700: Training accuracy 0.89965, Test accuracy 0.9079 and Training loss 0.27272409413874954\n",
            "Iteration 50800: Training accuracy 0.8994166666666666, Test accuracy 0.9082 and Training loss 0.27167669751955204\n",
            "Iteration 50900: Training accuracy 0.9016333333333333, Test accuracy 0.9106 and Training loss 0.2716663165508871\n",
            "Iteration 51000: Training accuracy 0.9005833333333333, Test accuracy 0.9105 and Training loss 0.2720126915588959\n",
            "Iteration 51100: Training accuracy 0.9001833333333333, Test accuracy 0.9105 and Training loss 0.27239926980304136\n",
            "Iteration 51200: Training accuracy 0.9004, Test accuracy 0.9103 and Training loss 0.2713696142729767\n",
            "Iteration 51300: Training accuracy 0.9011, Test accuracy 0.9108 and Training loss 0.2712770687289738\n",
            "Iteration 51400: Training accuracy 0.9020833333333333, Test accuracy 0.9119 and Training loss 0.2706964143477242\n",
            "Iteration 51500: Training accuracy 0.9025333333333333, Test accuracy 0.9129 and Training loss 0.27074623757644234\n",
            "Iteration 51600: Training accuracy 0.90115, Test accuracy 0.9112 and Training loss 0.2701830036314654\n",
            "Iteration 51700: Training accuracy 0.9033, Test accuracy 0.9127 and Training loss 0.27032097363924024\n",
            "Iteration 51800: Training accuracy 0.9022333333333333, Test accuracy 0.9121 and Training loss 0.2703619268789637\n",
            "Iteration 51900: Training accuracy 0.9036666666666666, Test accuracy 0.9143 and Training loss 0.2697074260469347\n",
            "Iteration 52000: Training accuracy 0.9024833333333333, Test accuracy 0.9121 and Training loss 0.26980283599075666\n",
            "Iteration 52100: Training accuracy 0.9037333333333334, Test accuracy 0.912 and Training loss 0.270827218291935\n",
            "Iteration 52200: Training accuracy 0.90305, Test accuracy 0.9134 and Training loss 0.26918237771511516\n",
            "Iteration 52300: Training accuracy 0.9031666666666667, Test accuracy 0.9128 and Training loss 0.26912489741520035\n",
            "Iteration 52400: Training accuracy 0.9023833333333333, Test accuracy 0.9132 and Training loss 0.26899197829925103\n",
            "Iteration 52500: Training accuracy 0.9025833333333333, Test accuracy 0.9122 and Training loss 0.2691352889512139\n",
            "Iteration 52600: Training accuracy 0.9022666666666667, Test accuracy 0.9113 and Training loss 0.2689403643303754\n",
            "Iteration 52700: Training accuracy 0.9012166666666667, Test accuracy 0.9102 and Training loss 0.26919565754678904\n",
            "Iteration 52800: Training accuracy 0.90405, Test accuracy 0.9127 and Training loss 0.2685033861847825\n",
            "Iteration 52900: Training accuracy 0.9041333333333333, Test accuracy 0.9124 and Training loss 0.2687242567884825\n",
            "Iteration 53000: Training accuracy 0.9029, Test accuracy 0.9121 and Training loss 0.2682614175167548\n",
            "Iteration 53100: Training accuracy 0.9040166666666667, Test accuracy 0.9132 and Training loss 0.26791319724904245\n",
            "Iteration 53200: Training accuracy 0.9033833333333333, Test accuracy 0.9127 and Training loss 0.2679166644190447\n",
            "Iteration 53300: Training accuracy 0.90565, Test accuracy 0.9128 and Training loss 0.26808381197008896\n",
            "Iteration 53400: Training accuracy 0.90385, Test accuracy 0.9125 and Training loss 0.26761727250087775\n",
            "Iteration 53500: Training accuracy 0.904, Test accuracy 0.9135 and Training loss 0.2675162005106236\n",
            "Iteration 53600: Training accuracy 0.9048, Test accuracy 0.9134 and Training loss 0.26707959533704445\n",
            "Iteration 53700: Training accuracy 0.9045833333333333, Test accuracy 0.9133 and Training loss 0.2671847251362719\n",
            "Iteration 53800: Training accuracy 0.9024833333333333, Test accuracy 0.9114 and Training loss 0.26831037993918927\n",
            "Iteration 53900: Training accuracy 0.9011333333333333, Test accuracy 0.9116 and Training loss 0.26697965965109177\n",
            "Iteration 54000: Training accuracy 0.90105, Test accuracy 0.9108 and Training loss 0.26688240523085854\n",
            "Iteration 54100: Training accuracy 0.8988666666666667, Test accuracy 0.9096 and Training loss 0.2674503060503352\n",
            "Iteration 54200: Training accuracy 0.89835, Test accuracy 0.9079 and Training loss 0.26826065724187836\n",
            "Iteration 54300: Training accuracy 0.90065, Test accuracy 0.9094 and Training loss 0.266664487101446\n",
            "Iteration 54400: Training accuracy 0.8994, Test accuracy 0.9101 and Training loss 0.26683299181764947\n",
            "Iteration 54500: Training accuracy 0.9007833333333334, Test accuracy 0.9121 and Training loss 0.2663224425651993\n",
            "Iteration 54600: Training accuracy 0.9009833333333334, Test accuracy 0.9121 and Training loss 0.26617212741079804\n",
            "Iteration 54700: Training accuracy 0.9012166666666667, Test accuracy 0.9107 and Training loss 0.2659380423834729\n",
            "Iteration 54800: Training accuracy 0.9017, Test accuracy 0.9119 and Training loss 0.26539939193305584\n",
            "Iteration 54900: Training accuracy 0.902, Test accuracy 0.9108 and Training loss 0.2652854518808912\n",
            "Iteration 55000: Training accuracy 0.90245, Test accuracy 0.9112 and Training loss 0.26517110413994055\n",
            "Iteration 55100: Training accuracy 0.9011, Test accuracy 0.9105 and Training loss 0.2660994535408144\n",
            "Iteration 55200: Training accuracy 0.9039833333333334, Test accuracy 0.9131 and Training loss 0.2648822982416314\n",
            "Iteration 55300: Training accuracy 0.9046833333333333, Test accuracy 0.9133 and Training loss 0.26515637027628214\n",
            "Iteration 55400: Training accuracy 0.9035, Test accuracy 0.9126 and Training loss 0.2646935478125713\n",
            "Iteration 55500: Training accuracy 0.9018833333333334, Test accuracy 0.911 and Training loss 0.26492503665157696\n",
            "Iteration 55600: Training accuracy 0.9039, Test accuracy 0.9136 and Training loss 0.26437806150443643\n",
            "Iteration 55700: Training accuracy 0.9049833333333334, Test accuracy 0.9125 and Training loss 0.2639712995888939\n",
            "Iteration 55800: Training accuracy 0.90665, Test accuracy 0.9146 and Training loss 0.26382190529764205\n",
            "Iteration 55900: Training accuracy 0.9069, Test accuracy 0.9142 and Training loss 0.26384373839766845\n",
            "Iteration 56000: Training accuracy 0.90715, Test accuracy 0.9139 and Training loss 0.2637715421571832\n",
            "Iteration 56100: Training accuracy 0.9074666666666666, Test accuracy 0.9133 and Training loss 0.2639897292137611\n",
            "Iteration 56200: Training accuracy 0.9073166666666667, Test accuracy 0.9131 and Training loss 0.2642503289703951\n",
            "Iteration 56300: Training accuracy 0.9074166666666666, Test accuracy 0.9135 and Training loss 0.26413638270968454\n",
            "Iteration 56400: Training accuracy 0.9059333333333334, Test accuracy 0.9133 and Training loss 0.2632517274317871\n",
            "Iteration 56500: Training accuracy 0.9048333333333334, Test accuracy 0.913 and Training loss 0.2633033434880637\n",
            "Iteration 56600: Training accuracy 0.9022833333333333, Test accuracy 0.9132 and Training loss 0.2632152840605068\n",
            "Iteration 56700: Training accuracy 0.9047333333333333, Test accuracy 0.9128 and Training loss 0.2629890010122258\n",
            "Iteration 56800: Training accuracy 0.9039166666666667, Test accuracy 0.9136 and Training loss 0.26334257433440383\n",
            "Iteration 56900: Training accuracy 0.9058666666666667, Test accuracy 0.9134 and Training loss 0.26253191264362\n",
            "Iteration 57000: Training accuracy 0.9056, Test accuracy 0.9139 and Training loss 0.26232196091002596\n",
            "Iteration 57100: Training accuracy 0.9038, Test accuracy 0.9134 and Training loss 0.2632139137136674\n",
            "Iteration 57200: Training accuracy 0.9071, Test accuracy 0.9139 and Training loss 0.2619420904711282\n",
            "Iteration 57300: Training accuracy 0.9082, Test accuracy 0.9152 and Training loss 0.26206981321599987\n",
            "Iteration 57400: Training accuracy 0.9068, Test accuracy 0.9153 and Training loss 0.2615875805248968\n",
            "Iteration 57500: Training accuracy 0.9049666666666667, Test accuracy 0.9131 and Training loss 0.26210821896137815\n",
            "Iteration 57600: Training accuracy 0.9061666666666667, Test accuracy 0.9133 and Training loss 0.2612706288978297\n",
            "Iteration 57700: Training accuracy 0.9055833333333333, Test accuracy 0.9128 and Training loss 0.26130902439745524\n",
            "Iteration 57800: Training accuracy 0.9068333333333334, Test accuracy 0.914 and Training loss 0.26075387239288006\n",
            "Iteration 57900: Training accuracy 0.9091666666666667, Test accuracy 0.9162 and Training loss 0.2609735163567191\n",
            "Iteration 58000: Training accuracy 0.9099666666666667, Test accuracy 0.9168 and Training loss 0.2619054899408529\n",
            "Iteration 58100: Training accuracy 0.9088833333333334, Test accuracy 0.9165 and Training loss 0.26045003589012417\n",
            "Iteration 58200: Training accuracy 0.9081666666666667, Test accuracy 0.9158 and Training loss 0.26055691350191096\n",
            "Iteration 58300: Training accuracy 0.90805, Test accuracy 0.9152 and Training loss 0.26084449212768857\n",
            "Iteration 58400: Training accuracy 0.90575, Test accuracy 0.9139 and Training loss 0.26017351916684855\n",
            "Iteration 58500: Training accuracy 0.907, Test accuracy 0.9144 and Training loss 0.2599588625397577\n",
            "Iteration 58600: Training accuracy 0.90675, Test accuracy 0.914 and Training loss 0.2599546718435013\n",
            "Iteration 58700: Training accuracy 0.9078333333333334, Test accuracy 0.9162 and Training loss 0.25946272760761996\n",
            "Iteration 58800: Training accuracy 0.90905, Test accuracy 0.9161 and Training loss 0.25985156441201046\n",
            "Iteration 58900: Training accuracy 0.91035, Test accuracy 0.9167 and Training loss 0.2615321141120098\n",
            "Iteration 59000: Training accuracy 0.9096333333333333, Test accuracy 0.9169 and Training loss 0.2590241202062805\n",
            "Iteration 59100: Training accuracy 0.9099166666666667, Test accuracy 0.9168 and Training loss 0.2592807068333845\n",
            "Iteration 59200: Training accuracy 0.908, Test accuracy 0.9157 and Training loss 0.2594523857249154\n",
            "Iteration 59300: Training accuracy 0.9086333333333333, Test accuracy 0.9153 and Training loss 0.25851009390487956\n",
            "Iteration 59400: Training accuracy 0.9092833333333333, Test accuracy 0.917 and Training loss 0.2585395631735256\n",
            "Iteration 59500: Training accuracy 0.9096333333333333, Test accuracy 0.9174 and Training loss 0.25833963521568115\n",
            "Iteration 59600: Training accuracy 0.9088666666666667, Test accuracy 0.917 and Training loss 0.2581104733449205\n",
            "Iteration 59700: Training accuracy 0.91, Test accuracy 0.9168 and Training loss 0.2580193276924248\n",
            "Iteration 59800: Training accuracy 0.9104666666666666, Test accuracy 0.9158 and Training loss 0.259080310035716\n",
            "Iteration 59900: Training accuracy 0.9118, Test accuracy 0.918 and Training loss 0.25778040155512905\n",
            "Iteration 60000: Training accuracy 0.9103833333333333, Test accuracy 0.9172 and Training loss 0.2582427770218463\n",
            "Final test accuracy for k = 5: 0.9172\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training with k = 40\n",
            "Iteration 0: Training accuracy 0.5151333333333333, test accuracy 0.5124 and Training loss 0.6931573324385174\n",
            "Iteration 100: Training accuracy 0.6717333333333333, Test accuracy 0.6966 and Training loss 0.6917457785632445\n",
            "Iteration 200: Training accuracy 0.7155166666666667, Test accuracy 0.7341 and Training loss 0.6898439537921688\n",
            "Iteration 300: Training accuracy 0.6809666666666667, Test accuracy 0.7062 and Training loss 0.6877480396687119\n",
            "Iteration 400: Training accuracy 0.6894, Test accuracy 0.7154 and Training loss 0.6853214655389898\n",
            "Iteration 500: Training accuracy 0.6984166666666667, Test accuracy 0.7218 and Training loss 0.6831562482839315\n",
            "Iteration 600: Training accuracy 0.6994833333333333, Test accuracy 0.7239 and Training loss 0.6806596139552532\n",
            "Iteration 700: Training accuracy 0.7041833333333334, Test accuracy 0.7298 and Training loss 0.6780739014723471\n",
            "Iteration 800: Training accuracy 0.7195, Test accuracy 0.7418 and Training loss 0.6752733969414272\n",
            "Iteration 900: Training accuracy 0.7305166666666667, Test accuracy 0.7541 and Training loss 0.6723807827409772\n",
            "Iteration 1000: Training accuracy 0.71945, Test accuracy 0.7449 and Training loss 0.6691602023658674\n",
            "Iteration 1100: Training accuracy 0.71905, Test accuracy 0.7438 and Training loss 0.6655156377735157\n",
            "Iteration 1200: Training accuracy 0.7221, Test accuracy 0.7483 and Training loss 0.6620277212734281\n",
            "Iteration 1300: Training accuracy 0.7221833333333333, Test accuracy 0.7479 and Training loss 0.6581365365964971\n",
            "Iteration 1400: Training accuracy 0.7220166666666666, Test accuracy 0.748 and Training loss 0.6540157217302536\n",
            "Iteration 1500: Training accuracy 0.729, Test accuracy 0.7547 and Training loss 0.6496397789855968\n",
            "Iteration 1600: Training accuracy 0.7303, Test accuracy 0.7557 and Training loss 0.6450060301803459\n",
            "Iteration 1700: Training accuracy 0.7259, Test accuracy 0.7483 and Training loss 0.6402636274506203\n",
            "Iteration 1800: Training accuracy 0.7292, Test accuracy 0.752 and Training loss 0.6349974757749015\n",
            "Iteration 1900: Training accuracy 0.7355833333333334, Test accuracy 0.7577 and Training loss 0.6290766185373633\n",
            "Iteration 2000: Training accuracy 0.74505, Test accuracy 0.7658 and Training loss 0.6232144381857678\n",
            "Iteration 2100: Training accuracy 0.75625, Test accuracy 0.7735 and Training loss 0.6162531516152997\n",
            "Iteration 2200: Training accuracy 0.75745, Test accuracy 0.774 and Training loss 0.6096229341283851\n",
            "Iteration 2300: Training accuracy 0.7565166666666666, Test accuracy 0.7745 and Training loss 0.6031789456234378\n",
            "Iteration 2400: Training accuracy 0.7641833333333333, Test accuracy 0.7794 and Training loss 0.5962631457830514\n",
            "Iteration 2500: Training accuracy 0.7692833333333333, Test accuracy 0.7809 and Training loss 0.5891648316193735\n",
            "Iteration 2600: Training accuracy 0.7751666666666667, Test accuracy 0.7848 and Training loss 0.5819112933114102\n",
            "Iteration 2700: Training accuracy 0.7753333333333333, Test accuracy 0.7848 and Training loss 0.5749743108813237\n",
            "Iteration 2800: Training accuracy 0.7757833333333334, Test accuracy 0.7865 and Training loss 0.5679303615281268\n",
            "Iteration 2900: Training accuracy 0.77275, Test accuracy 0.7847 and Training loss 0.5609178072207412\n",
            "Iteration 3000: Training accuracy 0.7736166666666666, Test accuracy 0.7867 and Training loss 0.5541889396836316\n",
            "Iteration 3100: Training accuracy 0.7752166666666667, Test accuracy 0.7866 and Training loss 0.5469285361177978\n",
            "Iteration 3200: Training accuracy 0.7762166666666667, Test accuracy 0.7872 and Training loss 0.5403457095081349\n",
            "Iteration 3300: Training accuracy 0.77955, Test accuracy 0.7874 and Training loss 0.5337080123008845\n",
            "Iteration 3400: Training accuracy 0.7842333333333333, Test accuracy 0.7874 and Training loss 0.5284710924167676\n",
            "Iteration 3500: Training accuracy 0.7822666666666667, Test accuracy 0.7892 and Training loss 0.5219088888853542\n",
            "Iteration 3600: Training accuracy 0.7842833333333333, Test accuracy 0.79 and Training loss 0.5164657201228396\n",
            "Iteration 3700: Training accuracy 0.7854, Test accuracy 0.7911 and Training loss 0.5107677167496432\n",
            "Iteration 3800: Training accuracy 0.7859333333333334, Test accuracy 0.7916 and Training loss 0.5053590732576503\n",
            "Iteration 3900: Training accuracy 0.7853, Test accuracy 0.7915 and Training loss 0.49997376803165494\n",
            "Iteration 4000: Training accuracy 0.7880666666666667, Test accuracy 0.7924 and Training loss 0.49506989707450183\n",
            "Iteration 4100: Training accuracy 0.7873833333333333, Test accuracy 0.7944 and Training loss 0.4907264363839248\n",
            "Iteration 4200: Training accuracy 0.7898, Test accuracy 0.7945 and Training loss 0.48705076693431243\n",
            "Iteration 4300: Training accuracy 0.7903166666666667, Test accuracy 0.7952 and Training loss 0.48295566927437666\n",
            "Iteration 4400: Training accuracy 0.7916833333333333, Test accuracy 0.7938 and Training loss 0.47931314854362206\n",
            "Iteration 4500: Training accuracy 0.7929666666666667, Test accuracy 0.7945 and Training loss 0.47552821405151946\n",
            "Iteration 4600: Training accuracy 0.79355, Test accuracy 0.7948 and Training loss 0.4717573681916339\n",
            "Iteration 4700: Training accuracy 0.7958166666666666, Test accuracy 0.7964 and Training loss 0.46806519283831466\n",
            "Iteration 4800: Training accuracy 0.7961666666666667, Test accuracy 0.7972 and Training loss 0.4649361859685832\n",
            "Iteration 4900: Training accuracy 0.79645, Test accuracy 0.798 and Training loss 0.46203010912927106\n",
            "Iteration 5000: Training accuracy 0.79705, Test accuracy 0.7991 and Training loss 0.45882476195621213\n",
            "Iteration 5100: Training accuracy 0.7982833333333333, Test accuracy 0.7941 and Training loss 0.45650681510981145\n",
            "Iteration 5200: Training accuracy 0.7991166666666667, Test accuracy 0.7971 and Training loss 0.4535741793389855\n",
            "Iteration 5300: Training accuracy 0.7999, Test accuracy 0.7977 and Training loss 0.4509303924295401\n",
            "Iteration 5400: Training accuracy 0.8007833333333333, Test accuracy 0.8038 and Training loss 0.4480831344996712\n",
            "Iteration 5500: Training accuracy 0.8004333333333333, Test accuracy 0.8058 and Training loss 0.445690642466814\n",
            "Iteration 5600: Training accuracy 0.80195, Test accuracy 0.8048 and Training loss 0.44274581318251666\n",
            "Iteration 5700: Training accuracy 0.8041833333333334, Test accuracy 0.8 and Training loss 0.4404880748825088\n",
            "Iteration 5800: Training accuracy 0.8034666666666667, Test accuracy 0.8066 and Training loss 0.4381713449581742\n",
            "Iteration 5900: Training accuracy 0.8040666666666667, Test accuracy 0.8079 and Training loss 0.43602717772534416\n",
            "Iteration 6000: Training accuracy 0.8064666666666667, Test accuracy 0.8053 and Training loss 0.43315435420821596\n",
            "Iteration 6100: Training accuracy 0.8083, Test accuracy 0.8041 and Training loss 0.4313062403044163\n",
            "Iteration 6200: Training accuracy 0.80755, Test accuracy 0.8086 and Training loss 0.4292570799219675\n",
            "Iteration 6300: Training accuracy 0.8099666666666666, Test accuracy 0.8037 and Training loss 0.42712480997790564\n",
            "Iteration 6400: Training accuracy 0.8100333333333334, Test accuracy 0.8051 and Training loss 0.42498285647707357\n",
            "Iteration 6500: Training accuracy 0.8119666666666666, Test accuracy 0.8047 and Training loss 0.42284122370533667\n",
            "Iteration 6600: Training accuracy 0.8131666666666667, Test accuracy 0.8055 and Training loss 0.4209245393135054\n",
            "Iteration 6700: Training accuracy 0.8142, Test accuracy 0.8049 and Training loss 0.41904372640850446\n",
            "Iteration 6800: Training accuracy 0.8144666666666667, Test accuracy 0.8058 and Training loss 0.4173297794245284\n",
            "Iteration 6900: Training accuracy 0.8154333333333333, Test accuracy 0.8073 and Training loss 0.4153109464492791\n",
            "Iteration 7000: Training accuracy 0.8159666666666666, Test accuracy 0.8116 and Training loss 0.41349702766230634\n",
            "Iteration 7100: Training accuracy 0.8174333333333333, Test accuracy 0.809 and Training loss 0.41168419543815205\n",
            "Iteration 7200: Training accuracy 0.8189, Test accuracy 0.8083 and Training loss 0.41027537453611057\n",
            "Iteration 7300: Training accuracy 0.8201, Test accuracy 0.8135 and Training loss 0.4084833524696793\n",
            "Iteration 7400: Training accuracy 0.8212, Test accuracy 0.8168 and Training loss 0.4069492713147714\n",
            "Iteration 7500: Training accuracy 0.8226, Test accuracy 0.8162 and Training loss 0.4053520610050525\n",
            "Iteration 7600: Training accuracy 0.8231666666666667, Test accuracy 0.8175 and Training loss 0.40370763039036067\n",
            "Iteration 7700: Training accuracy 0.8231833333333334, Test accuracy 0.8196 and Training loss 0.40216356293967015\n",
            "Iteration 7800: Training accuracy 0.8232333333333334, Test accuracy 0.8238 and Training loss 0.4012134409662598\n",
            "Iteration 7900: Training accuracy 0.8246333333333333, Test accuracy 0.8197 and Training loss 0.3990412658438502\n",
            "Iteration 8000: Training accuracy 0.82635, Test accuracy 0.8171 and Training loss 0.39767913294234597\n",
            "Iteration 8100: Training accuracy 0.826, Test accuracy 0.8172 and Training loss 0.39619355734409506\n",
            "Iteration 8200: Training accuracy 0.8275333333333333, Test accuracy 0.8195 and Training loss 0.39477523845364704\n",
            "Iteration 8300: Training accuracy 0.82895, Test accuracy 0.8195 and Training loss 0.3933164044717182\n",
            "Iteration 8400: Training accuracy 0.8304666666666667, Test accuracy 0.8193 and Training loss 0.39181491297178744\n",
            "Iteration 8500: Training accuracy 0.8309666666666666, Test accuracy 0.8218 and Training loss 0.39045618003163546\n",
            "Iteration 8600: Training accuracy 0.8320333333333333, Test accuracy 0.8234 and Training loss 0.3889051334845995\n",
            "Iteration 8700: Training accuracy 0.8318666666666666, Test accuracy 0.8234 and Training loss 0.38796049739728156\n",
            "Iteration 8800: Training accuracy 0.8326666666666667, Test accuracy 0.8235 and Training loss 0.38671896112995247\n",
            "Iteration 8900: Training accuracy 0.8340833333333333, Test accuracy 0.8261 and Training loss 0.38525138509821943\n",
            "Iteration 9000: Training accuracy 0.8342, Test accuracy 0.8317 and Training loss 0.3845106275506376\n",
            "Iteration 9100: Training accuracy 0.8348666666666666, Test accuracy 0.8223 and Training loss 0.38315342691226995\n",
            "Iteration 9200: Training accuracy 0.8370333333333333, Test accuracy 0.8276 and Training loss 0.38152503561214895\n",
            "Iteration 9300: Training accuracy 0.8384833333333334, Test accuracy 0.8308 and Training loss 0.38027931963755407\n",
            "Iteration 9400: Training accuracy 0.8393666666666667, Test accuracy 0.8277 and Training loss 0.3790808247461937\n",
            "Iteration 9500: Training accuracy 0.8408666666666667, Test accuracy 0.8282 and Training loss 0.3777470328634274\n",
            "Iteration 9600: Training accuracy 0.8421166666666666, Test accuracy 0.8307 and Training loss 0.37658995350747754\n",
            "Iteration 9700: Training accuracy 0.8419333333333333, Test accuracy 0.8366 and Training loss 0.3760842529016459\n",
            "Iteration 9800: Training accuracy 0.8424333333333334, Test accuracy 0.8376 and Training loss 0.3751263125588293\n",
            "Iteration 9900: Training accuracy 0.8427333333333333, Test accuracy 0.8304 and Training loss 0.3736919208724157\n",
            "Iteration 10000: Training accuracy 0.8435333333333334, Test accuracy 0.8296 and Training loss 0.37276966189861865\n",
            "Iteration 10100: Training accuracy 0.8449, Test accuracy 0.8305 and Training loss 0.3718158235863387\n",
            "Iteration 10200: Training accuracy 0.8463166666666667, Test accuracy 0.8325 and Training loss 0.3706313395344464\n",
            "Iteration 10300: Training accuracy 0.8458, Test accuracy 0.8324 and Training loss 0.3693208188756192\n",
            "Iteration 10400: Training accuracy 0.8456833333333333, Test accuracy 0.838 and Training loss 0.36813316496370546\n",
            "Iteration 10500: Training accuracy 0.8465, Test accuracy 0.8387 and Training loss 0.36704245608031905\n",
            "Iteration 10600: Training accuracy 0.8466166666666667, Test accuracy 0.8407 and Training loss 0.36616283220742274\n",
            "Iteration 10700: Training accuracy 0.8468, Test accuracy 0.8405 and Training loss 0.3649193904644817\n",
            "Iteration 10800: Training accuracy 0.8481166666666666, Test accuracy 0.8406 and Training loss 0.36370204623991415\n",
            "Iteration 10900: Training accuracy 0.8486166666666667, Test accuracy 0.8436 and Training loss 0.3629715420370756\n",
            "Iteration 11000: Training accuracy 0.8493666666666667, Test accuracy 0.8407 and Training loss 0.3617957527371503\n",
            "Iteration 11100: Training accuracy 0.8495666666666667, Test accuracy 0.8432 and Training loss 0.3607712314993237\n",
            "Iteration 11200: Training accuracy 0.8498333333333333, Test accuracy 0.8464 and Training loss 0.360337504169562\n",
            "Iteration 11300: Training accuracy 0.8502666666666666, Test accuracy 0.8474 and Training loss 0.3592560366048415\n",
            "Iteration 11400: Training accuracy 0.8511333333333333, Test accuracy 0.8426 and Training loss 0.35765058691381474\n",
            "Iteration 11500: Training accuracy 0.8520833333333333, Test accuracy 0.8442 and Training loss 0.3565650712685077\n",
            "Iteration 11600: Training accuracy 0.85165, Test accuracy 0.8431 and Training loss 0.35568399293246794\n",
            "Iteration 11700: Training accuracy 0.85275, Test accuracy 0.8415 and Training loss 0.3547097291796944\n",
            "Iteration 11800: Training accuracy 0.8530166666666666, Test accuracy 0.8404 and Training loss 0.35428981332052406\n",
            "Iteration 11900: Training accuracy 0.8534833333333334, Test accuracy 0.8495 and Training loss 0.3532516445381187\n",
            "Iteration 12000: Training accuracy 0.8540833333333333, Test accuracy 0.8478 and Training loss 0.35208963285674794\n",
            "Iteration 12100: Training accuracy 0.8554666666666667, Test accuracy 0.8464 and Training loss 0.350878095668743\n",
            "Iteration 12200: Training accuracy 0.8550666666666666, Test accuracy 0.8466 and Training loss 0.3499994733512484\n",
            "Iteration 12300: Training accuracy 0.8562333333333333, Test accuracy 0.8495 and Training loss 0.3490177518676446\n",
            "Iteration 12400: Training accuracy 0.8559166666666667, Test accuracy 0.8516 and Training loss 0.34880043129199484\n",
            "Iteration 12500: Training accuracy 0.8560166666666666, Test accuracy 0.8545 and Training loss 0.3483808200012283\n",
            "Iteration 12600: Training accuracy 0.8566166666666667, Test accuracy 0.8486 and Training loss 0.3465398933154889\n",
            "Iteration 12700: Training accuracy 0.8569833333333333, Test accuracy 0.8483 and Training loss 0.34602647131576797\n",
            "Iteration 12800: Training accuracy 0.8582, Test accuracy 0.8516 and Training loss 0.34475713054070645\n",
            "Iteration 12900: Training accuracy 0.8582166666666666, Test accuracy 0.8499 and Training loss 0.3440853775170785\n",
            "Iteration 13000: Training accuracy 0.8591, Test accuracy 0.8506 and Training loss 0.34331874856283534\n",
            "Iteration 13100: Training accuracy 0.8591, Test accuracy 0.8543 and Training loss 0.34237951959647567\n",
            "Iteration 13200: Training accuracy 0.8594166666666667, Test accuracy 0.8572 and Training loss 0.34173819742685585\n",
            "Iteration 13300: Training accuracy 0.8608833333333333, Test accuracy 0.8562 and Training loss 0.34066825866928985\n",
            "Iteration 13400: Training accuracy 0.8605, Test accuracy 0.8513 and Training loss 0.3404758599180809\n",
            "Iteration 13500: Training accuracy 0.8613, Test accuracy 0.8571 and Training loss 0.33895717906995854\n",
            "Iteration 13600: Training accuracy 0.8619, Test accuracy 0.8554 and Training loss 0.33818128762204597\n",
            "Iteration 13700: Training accuracy 0.8628833333333333, Test accuracy 0.8607 and Training loss 0.3371471626445062\n",
            "Iteration 13800: Training accuracy 0.8634166666666667, Test accuracy 0.8673 and Training loss 0.3371919983937087\n",
            "Iteration 13900: Training accuracy 0.8641833333333333, Test accuracy 0.865 and Training loss 0.3357158471294459\n",
            "Iteration 14000: Training accuracy 0.86405, Test accuracy 0.857 and Training loss 0.33507656565552396\n",
            "Iteration 14100: Training accuracy 0.8646, Test accuracy 0.8563 and Training loss 0.33437719953313827\n",
            "Iteration 14200: Training accuracy 0.8646166666666667, Test accuracy 0.8592 and Training loss 0.3334424267545912\n",
            "Iteration 14300: Training accuracy 0.8659333333333333, Test accuracy 0.8634 and Training loss 0.33224887467745334\n",
            "Iteration 14400: Training accuracy 0.8668166666666667, Test accuracy 0.8671 and Training loss 0.33140688615254515\n",
            "Iteration 14500: Training accuracy 0.8670166666666667, Test accuracy 0.8652 and Training loss 0.3305050065339086\n",
            "Iteration 14600: Training accuracy 0.8672666666666666, Test accuracy 0.8636 and Training loss 0.32983532695780454\n",
            "Iteration 14700: Training accuracy 0.8676166666666667, Test accuracy 0.8633 and Training loss 0.3292277066608309\n",
            "Iteration 14800: Training accuracy 0.8691666666666666, Test accuracy 0.8674 and Training loss 0.3280709434183961\n",
            "Iteration 14900: Training accuracy 0.8696666666666667, Test accuracy 0.8653 and Training loss 0.32757225975212495\n",
            "Iteration 15000: Training accuracy 0.8706, Test accuracy 0.8709 and Training loss 0.3264194195921889\n",
            "Iteration 15100: Training accuracy 0.87015, Test accuracy 0.87 and Training loss 0.3256258473513876\n",
            "Iteration 15200: Training accuracy 0.87125, Test accuracy 0.8714 and Training loss 0.32465400132001293\n",
            "Iteration 15300: Training accuracy 0.8715666666666667, Test accuracy 0.8738 and Training loss 0.32425201989199387\n",
            "Iteration 15400: Training accuracy 0.8724333333333333, Test accuracy 0.8756 and Training loss 0.32345128815975405\n",
            "Iteration 15500: Training accuracy 0.8736833333333334, Test accuracy 0.8738 and Training loss 0.32224072742596255\n",
            "Iteration 15600: Training accuracy 0.8735333333333334, Test accuracy 0.8716 and Training loss 0.3215187244747072\n",
            "Iteration 15700: Training accuracy 0.8743, Test accuracy 0.872 and Training loss 0.3206588926795595\n",
            "Iteration 15800: Training accuracy 0.87455, Test accuracy 0.8719 and Training loss 0.319841162946995\n",
            "Iteration 15900: Training accuracy 0.8752, Test accuracy 0.8742 and Training loss 0.3189606436954416\n",
            "Iteration 16000: Training accuracy 0.8753333333333333, Test accuracy 0.8717 and Training loss 0.3179650429817239\n",
            "Iteration 16100: Training accuracy 0.8745333333333334, Test accuracy 0.8654 and Training loss 0.319022159018463\n",
            "Iteration 16200: Training accuracy 0.8761166666666667, Test accuracy 0.8728 and Training loss 0.316280273737642\n",
            "Iteration 16300: Training accuracy 0.8764833333333333, Test accuracy 0.8739 and Training loss 0.3152992082186967\n",
            "Iteration 16400: Training accuracy 0.8756666666666667, Test accuracy 0.8709 and Training loss 0.3148659577886469\n",
            "Iteration 16500: Training accuracy 0.8767, Test accuracy 0.8725 and Training loss 0.3142230203014039\n",
            "Iteration 16600: Training accuracy 0.8772833333333333, Test accuracy 0.879 and Training loss 0.31330865074128966\n",
            "Iteration 16700: Training accuracy 0.8773166666666666, Test accuracy 0.8761 and Training loss 0.31216934320527284\n",
            "Iteration 16800: Training accuracy 0.8777333333333334, Test accuracy 0.8784 and Training loss 0.31146205709674046\n",
            "Iteration 16900: Training accuracy 0.8781, Test accuracy 0.8798 and Training loss 0.31071747776049724\n",
            "Iteration 17000: Training accuracy 0.8779666666666667, Test accuracy 0.8775 and Training loss 0.30984340949958067\n",
            "Iteration 17100: Training accuracy 0.8782, Test accuracy 0.8782 and Training loss 0.3091397192307932\n",
            "Iteration 17200: Training accuracy 0.8786, Test accuracy 0.8817 and Training loss 0.30874214603317224\n",
            "Iteration 17300: Training accuracy 0.8799, Test accuracy 0.8818 and Training loss 0.3077890522352806\n",
            "Iteration 17400: Training accuracy 0.8803333333333333, Test accuracy 0.8851 and Training loss 0.30719992794990797\n",
            "Iteration 17500: Training accuracy 0.8803666666666666, Test accuracy 0.8837 and Training loss 0.30616576664051265\n",
            "Iteration 17600: Training accuracy 0.8811166666666667, Test accuracy 0.8848 and Training loss 0.30530109583508275\n",
            "Iteration 17700: Training accuracy 0.8815333333333333, Test accuracy 0.8819 and Training loss 0.3049742419326198\n",
            "Iteration 17800: Training accuracy 0.8816, Test accuracy 0.8832 and Training loss 0.30396110679240984\n",
            "Iteration 17900: Training accuracy 0.882, Test accuracy 0.8861 and Training loss 0.3028819302486265\n",
            "Iteration 18000: Training accuracy 0.88195, Test accuracy 0.886 and Training loss 0.30205144243360815\n",
            "Iteration 18100: Training accuracy 0.8819833333333333, Test accuracy 0.8847 and Training loss 0.30135977073732284\n",
            "Iteration 18200: Training accuracy 0.8826333333333334, Test accuracy 0.8856 and Training loss 0.3006535901063031\n",
            "Iteration 18300: Training accuracy 0.8820666666666667, Test accuracy 0.8835 and Training loss 0.3001253241595571\n",
            "Iteration 18400: Training accuracy 0.8829833333333333, Test accuracy 0.883 and Training loss 0.29941278883804623\n",
            "Iteration 18500: Training accuracy 0.8837166666666667, Test accuracy 0.8862 and Training loss 0.29847471123778646\n",
            "Iteration 18600: Training accuracy 0.8841666666666667, Test accuracy 0.8863 and Training loss 0.2977006136376851\n",
            "Iteration 18700: Training accuracy 0.8842, Test accuracy 0.888 and Training loss 0.2970270636984289\n",
            "Iteration 18800: Training accuracy 0.88545, Test accuracy 0.8897 and Training loss 0.29625381192313727\n",
            "Iteration 18900: Training accuracy 0.8856, Test accuracy 0.8895 and Training loss 0.29574224310777986\n",
            "Iteration 19000: Training accuracy 0.8854166666666666, Test accuracy 0.8886 and Training loss 0.29494605707061894\n",
            "Iteration 19100: Training accuracy 0.8854, Test accuracy 0.8905 and Training loss 0.2947138604016078\n",
            "Iteration 19200: Training accuracy 0.8871333333333333, Test accuracy 0.8912 and Training loss 0.29342522556850487\n",
            "Iteration 19300: Training accuracy 0.8876333333333334, Test accuracy 0.8887 and Training loss 0.29311606705353965\n",
            "Iteration 19400: Training accuracy 0.88795, Test accuracy 0.892 and Training loss 0.29195847873703296\n",
            "Iteration 19500: Training accuracy 0.8883833333333333, Test accuracy 0.8944 and Training loss 0.2919647889456844\n",
            "Iteration 19600: Training accuracy 0.8886666666666667, Test accuracy 0.8941 and Training loss 0.29110938136945125\n",
            "Iteration 19700: Training accuracy 0.88885, Test accuracy 0.8925 and Training loss 0.29012408586498367\n",
            "Iteration 19800: Training accuracy 0.8895166666666666, Test accuracy 0.8933 and Training loss 0.2895578923526992\n",
            "Iteration 19900: Training accuracy 0.8894, Test accuracy 0.8931 and Training loss 0.2887363842202519\n",
            "Iteration 20000: Training accuracy 0.8891, Test accuracy 0.8959 and Training loss 0.2889614796273362\n",
            "Iteration 20100: Training accuracy 0.8902, Test accuracy 0.8943 and Training loss 0.2873228763968635\n",
            "Iteration 20200: Training accuracy 0.8909, Test accuracy 0.8927 and Training loss 0.28702668896188566\n",
            "Iteration 20300: Training accuracy 0.89045, Test accuracy 0.8949 and Training loss 0.2858849374736326\n",
            "Iteration 20400: Training accuracy 0.8909666666666667, Test accuracy 0.8932 and Training loss 0.28556152296850923\n",
            "Iteration 20500: Training accuracy 0.8913666666666666, Test accuracy 0.8969 and Training loss 0.2846273182352783\n",
            "Iteration 20600: Training accuracy 0.8916666666666667, Test accuracy 0.8951 and Training loss 0.2841754023857439\n",
            "Iteration 20700: Training accuracy 0.89205, Test accuracy 0.8954 and Training loss 0.2831869932716871\n",
            "Iteration 20800: Training accuracy 0.8921666666666667, Test accuracy 0.8951 and Training loss 0.2828701630289784\n",
            "Iteration 20900: Training accuracy 0.8926, Test accuracy 0.8948 and Training loss 0.2819356924533415\n",
            "Iteration 21000: Training accuracy 0.8917, Test accuracy 0.8971 and Training loss 0.2816707240922341\n",
            "Iteration 21100: Training accuracy 0.89295, Test accuracy 0.895 and Training loss 0.28052818856883893\n",
            "Iteration 21200: Training accuracy 0.89305, Test accuracy 0.8952 and Training loss 0.27971870991048503\n",
            "Iteration 21300: Training accuracy 0.8940166666666667, Test accuracy 0.8971 and Training loss 0.27911275588849555\n",
            "Iteration 21400: Training accuracy 0.8945666666666666, Test accuracy 0.8975 and Training loss 0.27843054804930056\n",
            "Iteration 21500: Training accuracy 0.8946166666666666, Test accuracy 0.8968 and Training loss 0.2779863275535194\n",
            "Iteration 21600: Training accuracy 0.8938, Test accuracy 0.8991 and Training loss 0.2777783299813185\n",
            "Iteration 21700: Training accuracy 0.8938333333333334, Test accuracy 0.8996 and Training loss 0.2775657413381393\n",
            "Iteration 21800: Training accuracy 0.8959666666666667, Test accuracy 0.8989 and Training loss 0.27641016158535753\n",
            "Iteration 21900: Training accuracy 0.8961666666666667, Test accuracy 0.9003 and Training loss 0.27558947234696285\n",
            "Iteration 22000: Training accuracy 0.8965333333333333, Test accuracy 0.8996 and Training loss 0.2751240071981854\n",
            "Iteration 22100: Training accuracy 0.8967833333333334, Test accuracy 0.8999 and Training loss 0.2744830821436041\n",
            "Iteration 22200: Training accuracy 0.89685, Test accuracy 0.9 and Training loss 0.27375468205218373\n",
            "Iteration 22300: Training accuracy 0.8964666666666666, Test accuracy 0.901 and Training loss 0.27329983161195154\n",
            "Iteration 22400: Training accuracy 0.8979166666666667, Test accuracy 0.901 and Training loss 0.27246311149442726\n",
            "Iteration 22500: Training accuracy 0.89805, Test accuracy 0.9013 and Training loss 0.2717556481732874\n",
            "Iteration 22600: Training accuracy 0.8963, Test accuracy 0.9007 and Training loss 0.2716531801735351\n",
            "Iteration 22700: Training accuracy 0.8973833333333333, Test accuracy 0.8997 and Training loss 0.27086869607422404\n",
            "Iteration 22800: Training accuracy 0.8979166666666667, Test accuracy 0.9011 and Training loss 0.27032607284601134\n",
            "Iteration 22900: Training accuracy 0.89855, Test accuracy 0.9008 and Training loss 0.269777600792354\n",
            "Iteration 23000: Training accuracy 0.8988666666666667, Test accuracy 0.9006 and Training loss 0.269193161463594\n",
            "Iteration 23100: Training accuracy 0.8993333333333333, Test accuracy 0.9017 and Training loss 0.2686980197111024\n",
            "Iteration 23200: Training accuracy 0.89915, Test accuracy 0.902 and Training loss 0.2679845285952601\n",
            "Iteration 23300: Training accuracy 0.8985, Test accuracy 0.9031 and Training loss 0.2677139805376318\n",
            "Iteration 23400: Training accuracy 0.8992666666666667, Test accuracy 0.9003 and Training loss 0.2681771831838302\n",
            "Iteration 23500: Training accuracy 0.8991833333333333, Test accuracy 0.9028 and Training loss 0.26642490070084257\n",
            "Iteration 23600: Training accuracy 0.8992333333333333, Test accuracy 0.9031 and Training loss 0.2658904795760339\n",
            "Iteration 23700: Training accuracy 0.8999333333333334, Test accuracy 0.9018 and Training loss 0.26604936738092955\n",
            "Iteration 23800: Training accuracy 0.9009166666666667, Test accuracy 0.9034 and Training loss 0.26475579343925554\n",
            "Iteration 23900: Training accuracy 0.9004166666666666, Test accuracy 0.9037 and Training loss 0.2642492892599382\n",
            "Iteration 24000: Training accuracy 0.90055, Test accuracy 0.9039 and Training loss 0.263944124939529\n",
            "Iteration 24100: Training accuracy 0.9010833333333333, Test accuracy 0.9044 and Training loss 0.2631121799981658\n",
            "Iteration 24200: Training accuracy 0.90085, Test accuracy 0.9045 and Training loss 0.2627246059261289\n",
            "Iteration 24300: Training accuracy 0.9015833333333333, Test accuracy 0.9053 and Training loss 0.26207918242063344\n",
            "Iteration 24400: Training accuracy 0.9013166666666667, Test accuracy 0.9051 and Training loss 0.26176788011691\n",
            "Iteration 24500: Training accuracy 0.9020333333333334, Test accuracy 0.9055 and Training loss 0.2611647233559003\n",
            "Iteration 24600: Training accuracy 0.9025333333333333, Test accuracy 0.9051 and Training loss 0.2614804382652857\n",
            "Iteration 24700: Training accuracy 0.9022333333333333, Test accuracy 0.9056 and Training loss 0.26047545256970656\n",
            "Iteration 24800: Training accuracy 0.903, Test accuracy 0.9064 and Training loss 0.259754061546476\n",
            "Iteration 24900: Training accuracy 0.90295, Test accuracy 0.9059 and Training loss 0.25960515257039274\n",
            "Iteration 25000: Training accuracy 0.9033833333333333, Test accuracy 0.9069 and Training loss 0.25889707089250424\n",
            "Iteration 25100: Training accuracy 0.9035833333333333, Test accuracy 0.9079 and Training loss 0.25807377643531637\n",
            "Iteration 25200: Training accuracy 0.9038, Test accuracy 0.9073 and Training loss 0.25809157027844554\n",
            "Iteration 25300: Training accuracy 0.9038166666666667, Test accuracy 0.9081 and Training loss 0.257136619115399\n",
            "Iteration 25400: Training accuracy 0.9033333333333333, Test accuracy 0.9082 and Training loss 0.2568213205027746\n",
            "Iteration 25500: Training accuracy 0.9043333333333333, Test accuracy 0.9083 and Training loss 0.25623600643906796\n",
            "Iteration 25600: Training accuracy 0.90455, Test accuracy 0.9086 and Training loss 0.2558170458374032\n",
            "Iteration 25700: Training accuracy 0.90415, Test accuracy 0.9082 and Training loss 0.25535594561705577\n",
            "Iteration 25800: Training accuracy 0.9047833333333334, Test accuracy 0.9094 and Training loss 0.2549449426412179\n",
            "Iteration 25900: Training accuracy 0.90505, Test accuracy 0.9091 and Training loss 0.25446617504614094\n",
            "Iteration 26000: Training accuracy 0.90475, Test accuracy 0.9102 and Training loss 0.2540389978953815\n",
            "Iteration 26100: Training accuracy 0.90565, Test accuracy 0.9092 and Training loss 0.2533677620803611\n",
            "Iteration 26200: Training accuracy 0.9054833333333333, Test accuracy 0.9091 and Training loss 0.25305648503490785\n",
            "Iteration 26300: Training accuracy 0.90605, Test accuracy 0.9069 and Training loss 0.2527673056655727\n",
            "Iteration 26400: Training accuracy 0.9061333333333333, Test accuracy 0.908 and Training loss 0.2524249327768802\n",
            "Iteration 26500: Training accuracy 0.9060166666666667, Test accuracy 0.9083 and Training loss 0.25237406393834766\n",
            "Iteration 26600: Training accuracy 0.9063, Test accuracy 0.9082 and Training loss 0.2523823670121606\n",
            "Iteration 26700: Training accuracy 0.9073333333333333, Test accuracy 0.9102 and Training loss 0.25038568890036506\n",
            "Iteration 26800: Training accuracy 0.9071333333333333, Test accuracy 0.9093 and Training loss 0.24999234437202028\n",
            "Iteration 26900: Training accuracy 0.9082166666666667, Test accuracy 0.9103 and Training loss 0.24966349472837565\n",
            "Iteration 27000: Training accuracy 0.9085, Test accuracy 0.9106 and Training loss 0.24907506265492077\n",
            "Iteration 27100: Training accuracy 0.9084333333333333, Test accuracy 0.9109 and Training loss 0.24860584777235709\n",
            "Iteration 27200: Training accuracy 0.9088, Test accuracy 0.911 and Training loss 0.24819834681432404\n",
            "Iteration 27300: Training accuracy 0.9087833333333334, Test accuracy 0.9113 and Training loss 0.2476010819382117\n",
            "Iteration 27400: Training accuracy 0.90945, Test accuracy 0.9114 and Training loss 0.24697878383925984\n",
            "Iteration 27500: Training accuracy 0.9095666666666666, Test accuracy 0.912 and Training loss 0.24651941091244156\n",
            "Iteration 27600: Training accuracy 0.9094166666666667, Test accuracy 0.9119 and Training loss 0.24636851043990943\n",
            "Iteration 27700: Training accuracy 0.9094666666666666, Test accuracy 0.912 and Training loss 0.2458722013149899\n",
            "Iteration 27800: Training accuracy 0.91, Test accuracy 0.9118 and Training loss 0.24518818485040256\n",
            "Iteration 27900: Training accuracy 0.90935, Test accuracy 0.9115 and Training loss 0.2450008972384745\n",
            "Iteration 28000: Training accuracy 0.9093833333333333, Test accuracy 0.9115 and Training loss 0.2446756492705097\n",
            "Iteration 28100: Training accuracy 0.9092666666666667, Test accuracy 0.9119 and Training loss 0.24406621265428977\n",
            "Iteration 28200: Training accuracy 0.9097166666666666, Test accuracy 0.9109 and Training loss 0.24405784203459993\n",
            "Iteration 28300: Training accuracy 0.9097166666666666, Test accuracy 0.9127 and Training loss 0.24366441105162734\n",
            "Iteration 28400: Training accuracy 0.9108333333333334, Test accuracy 0.9129 and Training loss 0.2426794436518662\n",
            "Iteration 28500: Training accuracy 0.9108166666666667, Test accuracy 0.9128 and Training loss 0.24237471099498492\n",
            "Iteration 28600: Training accuracy 0.9107, Test accuracy 0.9114 and Training loss 0.24236037183540818\n",
            "Iteration 28700: Training accuracy 0.9109166666666667, Test accuracy 0.9125 and Training loss 0.2415930643165562\n",
            "Iteration 28800: Training accuracy 0.91135, Test accuracy 0.9127 and Training loss 0.24112094850788807\n",
            "Iteration 28900: Training accuracy 0.9114, Test accuracy 0.913 and Training loss 0.2406328749179533\n",
            "Iteration 29000: Training accuracy 0.91165, Test accuracy 0.9135 and Training loss 0.24030018347925503\n",
            "Iteration 29100: Training accuracy 0.9116833333333333, Test accuracy 0.9132 and Training loss 0.2398601293388736\n",
            "Iteration 29200: Training accuracy 0.912, Test accuracy 0.9145 and Training loss 0.23972423887363054\n",
            "Iteration 29300: Training accuracy 0.9119833333333334, Test accuracy 0.914 and Training loss 0.23934669180003298\n",
            "Iteration 29400: Training accuracy 0.9121333333333334, Test accuracy 0.9136 and Training loss 0.2388601214525861\n",
            "Iteration 29500: Training accuracy 0.9124, Test accuracy 0.9139 and Training loss 0.23822184131285906\n",
            "Iteration 29600: Training accuracy 0.9124833333333333, Test accuracy 0.9153 and Training loss 0.23829472357239612\n",
            "Iteration 29700: Training accuracy 0.9127333333333333, Test accuracy 0.9162 and Training loss 0.23785036567570378\n",
            "Iteration 29800: Training accuracy 0.9132333333333333, Test accuracy 0.9155 and Training loss 0.23698264669623478\n",
            "Iteration 29900: Training accuracy 0.9133333333333333, Test accuracy 0.9158 and Training loss 0.2365019761679098\n",
            "Iteration 30000: Training accuracy 0.9132666666666667, Test accuracy 0.9157 and Training loss 0.23618765152752141\n",
            "Iteration 30100: Training accuracy 0.9124833333333333, Test accuracy 0.9143 and Training loss 0.23653962398984724\n",
            "Iteration 30200: Training accuracy 0.9132833333333333, Test accuracy 0.9148 and Training loss 0.23544931007985556\n",
            "Iteration 30300: Training accuracy 0.9130833333333334, Test accuracy 0.9151 and Training loss 0.23534912916420989\n",
            "Iteration 30400: Training accuracy 0.9132833333333333, Test accuracy 0.9158 and Training loss 0.2348593653732365\n",
            "Iteration 30500: Training accuracy 0.9137833333333333, Test accuracy 0.9164 and Training loss 0.23410005232820785\n",
            "Iteration 30600: Training accuracy 0.9139, Test accuracy 0.9156 and Training loss 0.23390264815092254\n",
            "Iteration 30700: Training accuracy 0.9136333333333333, Test accuracy 0.913 and Training loss 0.2338845391921372\n",
            "Iteration 30800: Training accuracy 0.9132833333333333, Test accuracy 0.9125 and Training loss 0.23430799478679354\n",
            "Iteration 30900: Training accuracy 0.91375, Test accuracy 0.9144 and Training loss 0.23314814330059513\n",
            "Iteration 31000: Training accuracy 0.91395, Test accuracy 0.9173 and Training loss 0.23258548233497878\n",
            "Iteration 31100: Training accuracy 0.91465, Test accuracy 0.9178 and Training loss 0.23202181546481643\n",
            "Iteration 31200: Training accuracy 0.9151, Test accuracy 0.9172 and Training loss 0.23151419734960554\n",
            "Iteration 31300: Training accuracy 0.9154, Test accuracy 0.9175 and Training loss 0.2310202843803514\n",
            "Iteration 31400: Training accuracy 0.9154166666666667, Test accuracy 0.9174 and Training loss 0.23062539072143876\n",
            "Iteration 31500: Training accuracy 0.9158666666666667, Test accuracy 0.9165 and Training loss 0.23008876016956728\n",
            "Iteration 31600: Training accuracy 0.9159, Test accuracy 0.918 and Training loss 0.2299443862136598\n",
            "Iteration 31700: Training accuracy 0.9157666666666666, Test accuracy 0.9184 and Training loss 0.22946850176710487\n",
            "Iteration 31800: Training accuracy 0.9159833333333334, Test accuracy 0.9168 and Training loss 0.22935753215724602\n",
            "Iteration 31900: Training accuracy 0.9154833333333333, Test accuracy 0.9125 and Training loss 0.23053268900580687\n",
            "Iteration 32000: Training accuracy 0.91615, Test accuracy 0.9176 and Training loss 0.22935282482054747\n",
            "Iteration 32100: Training accuracy 0.9165333333333333, Test accuracy 0.918 and Training loss 0.22791657939901666\n",
            "Iteration 32200: Training accuracy 0.91685, Test accuracy 0.9166 and Training loss 0.22758189296794865\n",
            "Iteration 32300: Training accuracy 0.9167833333333333, Test accuracy 0.9179 and Training loss 0.22744469470784417\n",
            "Iteration 32400: Training accuracy 0.9176666666666666, Test accuracy 0.9182 and Training loss 0.22690094183191234\n",
            "Iteration 32500: Training accuracy 0.9174833333333333, Test accuracy 0.9193 and Training loss 0.22681394860948884\n",
            "Iteration 32600: Training accuracy 0.9177, Test accuracy 0.9191 and Training loss 0.22614295999656592\n",
            "Iteration 32700: Training accuracy 0.9176666666666666, Test accuracy 0.919 and Training loss 0.22585241201807543\n",
            "Iteration 32800: Training accuracy 0.9178833333333334, Test accuracy 0.9207 and Training loss 0.22552933521425927\n",
            "Iteration 32900: Training accuracy 0.91825, Test accuracy 0.9191 and Training loss 0.22493346766114425\n",
            "Iteration 33000: Training accuracy 0.9178, Test accuracy 0.9169 and Training loss 0.22478596580533255\n",
            "Iteration 33100: Training accuracy 0.9176833333333333, Test accuracy 0.9194 and Training loss 0.22580960236897524\n",
            "Iteration 33200: Training accuracy 0.9185333333333333, Test accuracy 0.9189 and Training loss 0.22380186804115693\n",
            "Iteration 33300: Training accuracy 0.9187666666666666, Test accuracy 0.9206 and Training loss 0.22381588631321728\n",
            "Iteration 33400: Training accuracy 0.9189, Test accuracy 0.9194 and Training loss 0.2230361690616549\n",
            "Iteration 33500: Training accuracy 0.9185, Test accuracy 0.9202 and Training loss 0.22313506109853812\n",
            "Iteration 33600: Training accuracy 0.9187166666666666, Test accuracy 0.9213 and Training loss 0.22295962459510643\n",
            "Iteration 33700: Training accuracy 0.9187166666666666, Test accuracy 0.9201 and Training loss 0.22222609834454674\n",
            "Iteration 33800: Training accuracy 0.9190166666666667, Test accuracy 0.9214 and Training loss 0.22180588265403445\n",
            "Iteration 33900: Training accuracy 0.919, Test accuracy 0.9215 and Training loss 0.22142295625662767\n",
            "Iteration 34000: Training accuracy 0.91945, Test accuracy 0.9193 and Training loss 0.22121177205706116\n",
            "Iteration 34100: Training accuracy 0.9193166666666667, Test accuracy 0.9181 and Training loss 0.22071148973361565\n",
            "Iteration 34200: Training accuracy 0.92, Test accuracy 0.9196 and Training loss 0.2201863191882308\n",
            "Iteration 34300: Training accuracy 0.92045, Test accuracy 0.9193 and Training loss 0.21999295788203843\n",
            "Iteration 34400: Training accuracy 0.9205666666666666, Test accuracy 0.9202 and Training loss 0.2197274029432498\n",
            "Iteration 34500: Training accuracy 0.92055, Test accuracy 0.921 and Training loss 0.2191229109914702\n",
            "Iteration 34600: Training accuracy 0.9206666666666666, Test accuracy 0.9196 and Training loss 0.21890921831919477\n",
            "Iteration 34700: Training accuracy 0.9208166666666666, Test accuracy 0.9197 and Training loss 0.218377998353214\n",
            "Iteration 34800: Training accuracy 0.9208833333333334, Test accuracy 0.9187 and Training loss 0.21823575879463802\n",
            "Iteration 34900: Training accuracy 0.9208833333333334, Test accuracy 0.9184 and Training loss 0.21791333353011522\n",
            "Iteration 35000: Training accuracy 0.9213166666666667, Test accuracy 0.9182 and Training loss 0.21750056957870179\n",
            "Iteration 35100: Training accuracy 0.92195, Test accuracy 0.9214 and Training loss 0.2171137484446102\n",
            "Iteration 35200: Training accuracy 0.92165, Test accuracy 0.9226 and Training loss 0.21800338659692464\n",
            "Iteration 35300: Training accuracy 0.9225333333333333, Test accuracy 0.9213 and Training loss 0.21621477473407222\n",
            "Iteration 35400: Training accuracy 0.9226333333333333, Test accuracy 0.9204 and Training loss 0.21595290390218458\n",
            "Iteration 35500: Training accuracy 0.92275, Test accuracy 0.9208 and Training loss 0.2155238552542705\n",
            "Iteration 35600: Training accuracy 0.9220333333333334, Test accuracy 0.9178 and Training loss 0.2156431235637802\n",
            "Iteration 35700: Training accuracy 0.9225166666666667, Test accuracy 0.9202 and Training loss 0.21494360880530178\n",
            "Iteration 35800: Training accuracy 0.92245, Test accuracy 0.9193 and Training loss 0.21478400092970362\n",
            "Iteration 35900: Training accuracy 0.9226333333333333, Test accuracy 0.9186 and Training loss 0.2145705098668183\n",
            "Iteration 36000: Training accuracy 0.9231166666666667, Test accuracy 0.9203 and Training loss 0.2139102716880569\n",
            "Iteration 36100: Training accuracy 0.9232833333333333, Test accuracy 0.9198 and Training loss 0.2135843866704505\n",
            "Iteration 36200: Training accuracy 0.9232166666666667, Test accuracy 0.9192 and Training loss 0.21342621778238108\n",
            "Iteration 36300: Training accuracy 0.9234833333333333, Test accuracy 0.9207 and Training loss 0.2128443481142698\n",
            "Iteration 36400: Training accuracy 0.9229, Test accuracy 0.9185 and Training loss 0.21333325789479524\n",
            "Iteration 36500: Training accuracy 0.9239166666666667, Test accuracy 0.9222 and Training loss 0.21214549310089065\n",
            "Iteration 36600: Training accuracy 0.9240833333333334, Test accuracy 0.9242 and Training loss 0.21246558288874146\n",
            "Iteration 36700: Training accuracy 0.9244166666666667, Test accuracy 0.9225 and Training loss 0.21164694602431097\n",
            "Iteration 36800: Training accuracy 0.9248666666666666, Test accuracy 0.9223 and Training loss 0.21106025834551206\n",
            "Iteration 36900: Training accuracy 0.9248, Test accuracy 0.9225 and Training loss 0.21080154689601965\n",
            "Iteration 37000: Training accuracy 0.92505, Test accuracy 0.9233 and Training loss 0.21053461599995235\n",
            "Iteration 37100: Training accuracy 0.9250666666666667, Test accuracy 0.9229 and Training loss 0.21011016968763646\n",
            "Iteration 37200: Training accuracy 0.92505, Test accuracy 0.9226 and Training loss 0.20999925772901054\n",
            "Iteration 37300: Training accuracy 0.9253166666666667, Test accuracy 0.9232 and Training loss 0.20948751101147434\n",
            "Iteration 37400: Training accuracy 0.9253166666666667, Test accuracy 0.9253 and Training loss 0.2095164442126696\n",
            "Iteration 37500: Training accuracy 0.9253666666666667, Test accuracy 0.9245 and Training loss 0.20918286863442262\n",
            "Iteration 37600: Training accuracy 0.9254833333333333, Test accuracy 0.924 and Training loss 0.20848656279233577\n",
            "Iteration 37700: Training accuracy 0.9253833333333333, Test accuracy 0.9242 and Training loss 0.2081182554797005\n",
            "Iteration 37800: Training accuracy 0.9252333333333334, Test accuracy 0.9231 and Training loss 0.20818362271261637\n",
            "Iteration 37900: Training accuracy 0.9257333333333333, Test accuracy 0.9229 and Training loss 0.2075903906124725\n",
            "Iteration 38000: Training accuracy 0.9256666666666666, Test accuracy 0.9223 and Training loss 0.2076416571470115\n",
            "Iteration 38100: Training accuracy 0.9248833333333333, Test accuracy 0.9207 and Training loss 0.20855527637076768\n",
            "Iteration 38200: Training accuracy 0.9261666666666667, Test accuracy 0.923 and Training loss 0.20652701413083763\n",
            "Iteration 38300: Training accuracy 0.92655, Test accuracy 0.9226 and Training loss 0.20644772269497683\n",
            "Iteration 38400: Training accuracy 0.9270666666666667, Test accuracy 0.9233 and Training loss 0.20585210510308327\n",
            "Iteration 38500: Training accuracy 0.9271166666666667, Test accuracy 0.924 and Training loss 0.20562655439820565\n",
            "Iteration 38600: Training accuracy 0.9273, Test accuracy 0.9242 and Training loss 0.2054382769127071\n",
            "Iteration 38700: Training accuracy 0.9281, Test accuracy 0.926 and Training loss 0.20490348141412282\n",
            "Iteration 38800: Training accuracy 0.9278833333333333, Test accuracy 0.9258 and Training loss 0.20454679477132381\n",
            "Iteration 38900: Training accuracy 0.9277, Test accuracy 0.927 and Training loss 0.20469133564079012\n",
            "Iteration 39000: Training accuracy 0.92795, Test accuracy 0.927 and Training loss 0.20413661444926037\n",
            "Iteration 39100: Training accuracy 0.9281166666666667, Test accuracy 0.9254 and Training loss 0.20365409881225735\n",
            "Iteration 39200: Training accuracy 0.9283333333333333, Test accuracy 0.9261 and Training loss 0.20323068624407706\n",
            "Iteration 39300: Training accuracy 0.9286, Test accuracy 0.9249 and Training loss 0.20281614788172866\n",
            "Iteration 39400: Training accuracy 0.92855, Test accuracy 0.9252 and Training loss 0.20255439960211108\n",
            "Iteration 39500: Training accuracy 0.9284833333333333, Test accuracy 0.9248 and Training loss 0.20212718852933012\n",
            "Iteration 39600: Training accuracy 0.9284666666666667, Test accuracy 0.9274 and Training loss 0.20187040682586485\n",
            "Iteration 39700: Training accuracy 0.9288333333333333, Test accuracy 0.9258 and Training loss 0.20155016423103767\n",
            "Iteration 39800: Training accuracy 0.9284833333333333, Test accuracy 0.9266 and Training loss 0.2016903799068015\n",
            "Iteration 39900: Training accuracy 0.9290166666666667, Test accuracy 0.9262 and Training loss 0.20113724806147168\n",
            "Iteration 40000: Training accuracy 0.9293666666666667, Test accuracy 0.9256 and Training loss 0.20071988211149008\n",
            "Iteration 40100: Training accuracy 0.9294166666666667, Test accuracy 0.9252 and Training loss 0.20042105649543435\n",
            "Iteration 40200: Training accuracy 0.9293833333333333, Test accuracy 0.9272 and Training loss 0.200523657344466\n",
            "Iteration 40300: Training accuracy 0.9293166666666667, Test accuracy 0.9267 and Training loss 0.20067190903550933\n",
            "Iteration 40400: Training accuracy 0.9300333333333334, Test accuracy 0.9262 and Training loss 0.19934421572393976\n",
            "Iteration 40500: Training accuracy 0.9298833333333333, Test accuracy 0.9249 and Training loss 0.19906282593587651\n",
            "Iteration 40600: Training accuracy 0.9298, Test accuracy 0.9246 and Training loss 0.1990248941866857\n",
            "Iteration 40700: Training accuracy 0.92995, Test accuracy 0.9251 and Training loss 0.19849047943737771\n",
            "Iteration 40800: Training accuracy 0.9298333333333333, Test accuracy 0.9247 and Training loss 0.19824519150389242\n",
            "Iteration 40900: Training accuracy 0.93, Test accuracy 0.9258 and Training loss 0.19805086140788566\n",
            "Iteration 41000: Training accuracy 0.9302, Test accuracy 0.9263 and Training loss 0.19773547607714204\n",
            "Iteration 41100: Training accuracy 0.9305, Test accuracy 0.9277 and Training loss 0.19742051854691625\n",
            "Iteration 41200: Training accuracy 0.9305666666666667, Test accuracy 0.9252 and Training loss 0.19729253793512522\n",
            "Iteration 41300: Training accuracy 0.9307666666666666, Test accuracy 0.9251 and Training loss 0.19653571427439098\n",
            "Iteration 41400: Training accuracy 0.93105, Test accuracy 0.9261 and Training loss 0.19633844368405515\n",
            "Iteration 41500: Training accuracy 0.93045, Test accuracy 0.9235 and Training loss 0.19643491070534624\n",
            "Iteration 41600: Training accuracy 0.9309, Test accuracy 0.9244 and Training loss 0.19589326802683438\n",
            "Iteration 41700: Training accuracy 0.9312833333333334, Test accuracy 0.9263 and Training loss 0.19567389457857662\n",
            "Iteration 41800: Training accuracy 0.93165, Test accuracy 0.9276 and Training loss 0.1954571225166351\n",
            "Iteration 41900: Training accuracy 0.9310333333333334, Test accuracy 0.9287 and Training loss 0.19598744041137697\n",
            "Iteration 42000: Training accuracy 0.93165, Test accuracy 0.9264 and Training loss 0.19467292625127045\n",
            "Iteration 42100: Training accuracy 0.9319, Test accuracy 0.9276 and Training loss 0.19441947533773457\n",
            "Iteration 42200: Training accuracy 0.9318, Test accuracy 0.9287 and Training loss 0.19483559208839554\n",
            "Iteration 42300: Training accuracy 0.9322166666666667, Test accuracy 0.9256 and Training loss 0.1938684110432961\n",
            "Iteration 42400: Training accuracy 0.9326333333333333, Test accuracy 0.9255 and Training loss 0.1935660187927069\n",
            "Iteration 42500: Training accuracy 0.9321833333333334, Test accuracy 0.9283 and Training loss 0.19370177319408505\n",
            "Iteration 42600: Training accuracy 0.9325166666666667, Test accuracy 0.9286 and Training loss 0.19308450767099078\n",
            "Iteration 42700: Training accuracy 0.9324166666666667, Test accuracy 0.927 and Training loss 0.19277426177170373\n",
            "Iteration 42800: Training accuracy 0.93115, Test accuracy 0.922 and Training loss 0.19401323542415594\n",
            "Iteration 42900: Training accuracy 0.9328666666666666, Test accuracy 0.9264 and Training loss 0.19226334292812985\n",
            "Iteration 43000: Training accuracy 0.9329166666666666, Test accuracy 0.9267 and Training loss 0.19184387996735908\n",
            "Iteration 43100: Training accuracy 0.9327, Test accuracy 0.9291 and Training loss 0.19291017136783717\n",
            "Iteration 43200: Training accuracy 0.9333666666666667, Test accuracy 0.929 and Training loss 0.19127480459359567\n",
            "Iteration 43300: Training accuracy 0.9332666666666667, Test accuracy 0.9296 and Training loss 0.19128771710914713\n",
            "Iteration 43400: Training accuracy 0.9337333333333333, Test accuracy 0.9275 and Training loss 0.1905671470942412\n",
            "Iteration 43500: Training accuracy 0.9335, Test accuracy 0.9266 and Training loss 0.19065000997087836\n",
            "Iteration 43600: Training accuracy 0.9343166666666667, Test accuracy 0.9282 and Training loss 0.19000414017590359\n",
            "Iteration 43700: Training accuracy 0.9336, Test accuracy 0.9289 and Training loss 0.1907269444296947\n",
            "Iteration 43800: Training accuracy 0.9339833333333334, Test accuracy 0.9283 and Training loss 0.18975626990298136\n",
            "Iteration 43900: Training accuracy 0.9341166666666667, Test accuracy 0.9291 and Training loss 0.18949659277795203\n",
            "Iteration 44000: Training accuracy 0.9340333333333334, Test accuracy 0.9287 and Training loss 0.18936636698041975\n",
            "Iteration 44100: Training accuracy 0.93355, Test accuracy 0.9238 and Training loss 0.18958572426238074\n",
            "Iteration 44200: Training accuracy 0.9337166666666666, Test accuracy 0.9247 and Training loss 0.18885063241733646\n",
            "Iteration 44300: Training accuracy 0.9344666666666667, Test accuracy 0.9277 and Training loss 0.1880953706811193\n",
            "Iteration 44400: Training accuracy 0.9342333333333334, Test accuracy 0.9268 and Training loss 0.18804744454352926\n",
            "Iteration 44500: Training accuracy 0.9344333333333333, Test accuracy 0.9285 and Training loss 0.18768879065879754\n",
            "Iteration 44600: Training accuracy 0.9342, Test accuracy 0.9289 and Training loss 0.18768004443126238\n",
            "Iteration 44700: Training accuracy 0.9343, Test accuracy 0.9292 and Training loss 0.1871670298567193\n",
            "Iteration 44800: Training accuracy 0.9343, Test accuracy 0.9303 and Training loss 0.18721762387882046\n",
            "Iteration 44900: Training accuracy 0.9345166666666667, Test accuracy 0.9303 and Training loss 0.1866121524314824\n",
            "Iteration 45000: Training accuracy 0.9348, Test accuracy 0.931 and Training loss 0.18742940433219404\n",
            "Iteration 45100: Training accuracy 0.93535, Test accuracy 0.9293 and Training loss 0.1858848647733855\n",
            "Iteration 45200: Training accuracy 0.9356, Test accuracy 0.9303 and Training loss 0.18556049354431603\n",
            "Iteration 45300: Training accuracy 0.9354833333333333, Test accuracy 0.9283 and Training loss 0.18519374548561432\n",
            "Iteration 45400: Training accuracy 0.9356333333333333, Test accuracy 0.9287 and Training loss 0.18494921228555242\n",
            "Iteration 45500: Training accuracy 0.93595, Test accuracy 0.9307 and Training loss 0.18525070781070804\n",
            "Iteration 45600: Training accuracy 0.9363666666666667, Test accuracy 0.9311 and Training loss 0.18479638006345478\n",
            "Iteration 45700: Training accuracy 0.9362833333333334, Test accuracy 0.9306 and Training loss 0.1844152262925699\n",
            "Iteration 45800: Training accuracy 0.9361, Test accuracy 0.9265 and Training loss 0.18415882926069674\n",
            "Iteration 45900: Training accuracy 0.9365333333333333, Test accuracy 0.9282 and Training loss 0.1837086546562061\n",
            "Iteration 46000: Training accuracy 0.9365, Test accuracy 0.9296 and Training loss 0.183435344621798\n",
            "Iteration 46100: Training accuracy 0.93715, Test accuracy 0.9315 and Training loss 0.18332979504323632\n",
            "Iteration 46200: Training accuracy 0.93735, Test accuracy 0.9278 and Training loss 0.18281819957949205\n",
            "Iteration 46300: Training accuracy 0.9372666666666667, Test accuracy 0.9291 and Training loss 0.18254079935778983\n",
            "Iteration 46400: Training accuracy 0.9366, Test accuracy 0.926 and Training loss 0.1829223953729159\n",
            "Iteration 46500: Training accuracy 0.93745, Test accuracy 0.9285 and Training loss 0.18215380285725663\n",
            "Iteration 46600: Training accuracy 0.93755, Test accuracy 0.9286 and Training loss 0.18169666894840958\n",
            "Iteration 46700: Training accuracy 0.9374833333333333, Test accuracy 0.9278 and Training loss 0.181599036754882\n",
            "Iteration 46800: Training accuracy 0.93795, Test accuracy 0.9266 and Training loss 0.18131000648171708\n",
            "Iteration 46900: Training accuracy 0.9375666666666667, Test accuracy 0.9257 and Training loss 0.18136506651608486\n",
            "Iteration 47000: Training accuracy 0.9380833333333334, Test accuracy 0.929 and Training loss 0.18069103264036704\n",
            "Iteration 47100: Training accuracy 0.93785, Test accuracy 0.9319 and Training loss 0.18114817697501015\n",
            "Iteration 47200: Training accuracy 0.9383333333333334, Test accuracy 0.9305 and Training loss 0.18065541159349652\n",
            "Iteration 47300: Training accuracy 0.9388, Test accuracy 0.925 and Training loss 0.18016237973473598\n",
            "Iteration 47400: Training accuracy 0.9381166666666667, Test accuracy 0.9221 and Training loss 0.18072989392553515\n",
            "Iteration 47500: Training accuracy 0.9379, Test accuracy 0.9232 and Training loss 0.1800219723054582\n",
            "Iteration 47600: Training accuracy 0.93865, Test accuracy 0.9277 and Training loss 0.17913091287089106\n",
            "Iteration 47700: Training accuracy 0.9385, Test accuracy 0.9325 and Training loss 0.17980901531364105\n",
            "Iteration 47800: Training accuracy 0.9389666666666666, Test accuracy 0.9286 and Training loss 0.1786471989108743\n",
            "Iteration 47900: Training accuracy 0.9384, Test accuracy 0.9262 and Training loss 0.17872422433358412\n",
            "Iteration 48000: Training accuracy 0.9393833333333333, Test accuracy 0.9283 and Training loss 0.17808337254431517\n",
            "Iteration 48100: Training accuracy 0.9394666666666667, Test accuracy 0.9304 and Training loss 0.17821152940621648\n",
            "Iteration 48200: Training accuracy 0.9397833333333333, Test accuracy 0.9317 and Training loss 0.1781557529555062\n",
            "Iteration 48300: Training accuracy 0.9399333333333333, Test accuracy 0.9317 and Training loss 0.17782416166527762\n",
            "Iteration 48400: Training accuracy 0.9402166666666667, Test accuracy 0.9301 and Training loss 0.1771174650792637\n",
            "Iteration 48500: Training accuracy 0.9398166666666666, Test accuracy 0.9313 and Training loss 0.17683277781926957\n",
            "Iteration 48600: Training accuracy 0.9402833333333334, Test accuracy 0.9306 and Training loss 0.17659352503740705\n",
            "Iteration 48700: Training accuracy 0.9397166666666666, Test accuracy 0.9279 and Training loss 0.17655494202117536\n",
            "Iteration 48800: Training accuracy 0.9399666666666666, Test accuracy 0.9303 and Training loss 0.17623197618933165\n",
            "Iteration 48900: Training accuracy 0.9400333333333334, Test accuracy 0.9304 and Training loss 0.17587260142067335\n",
            "Iteration 49000: Training accuracy 0.9405833333333333, Test accuracy 0.9314 and Training loss 0.17567620885763277\n",
            "Iteration 49100: Training accuracy 0.9404166666666667, Test accuracy 0.9304 and Training loss 0.1754349460333796\n",
            "Iteration 49200: Training accuracy 0.9393666666666667, Test accuracy 0.9272 and Training loss 0.1757719494147555\n",
            "Iteration 49300: Training accuracy 0.9401333333333334, Test accuracy 0.9318 and Training loss 0.17519012326435804\n",
            "Iteration 49400: Training accuracy 0.9401, Test accuracy 0.9317 and Training loss 0.1750330506831041\n",
            "Iteration 49500: Training accuracy 0.9406166666666667, Test accuracy 0.9317 and Training loss 0.17456521213235765\n",
            "Iteration 49600: Training accuracy 0.9404833333333333, Test accuracy 0.9316 and Training loss 0.17440430207467414\n",
            "Iteration 49700: Training accuracy 0.9406333333333333, Test accuracy 0.9328 and Training loss 0.17428798670119663\n",
            "Iteration 49800: Training accuracy 0.9410166666666666, Test accuracy 0.9316 and Training loss 0.1739916974135439\n",
            "Iteration 49900: Training accuracy 0.9404, Test accuracy 0.93 and Training loss 0.17374555833475333\n",
            "Iteration 50000: Training accuracy 0.9406166666666667, Test accuracy 0.9296 and Training loss 0.17342068457836946\n",
            "Iteration 50100: Training accuracy 0.9410833333333334, Test accuracy 0.9311 and Training loss 0.1731418999499967\n",
            "Iteration 50200: Training accuracy 0.9404166666666667, Test accuracy 0.9255 and Training loss 0.17363171557570575\n",
            "Iteration 50300: Training accuracy 0.9409333333333333, Test accuracy 0.9263 and Training loss 0.17330376593567057\n",
            "Iteration 50400: Training accuracy 0.9415666666666667, Test accuracy 0.928 and Training loss 0.17263697642750078\n",
            "Iteration 50500: Training accuracy 0.9400666666666667, Test accuracy 0.9242 and Training loss 0.17369024051643125\n",
            "Iteration 50600: Training accuracy 0.94145, Test accuracy 0.9273 and Training loss 0.17218531821931632\n",
            "Iteration 50700: Training accuracy 0.9417333333333333, Test accuracy 0.9297 and Training loss 0.17163076652405182\n",
            "Iteration 50800: Training accuracy 0.94215, Test accuracy 0.9308 and Training loss 0.17137613639815436\n",
            "Iteration 50900: Training accuracy 0.9421833333333334, Test accuracy 0.9314 and Training loss 0.17111860669137968\n",
            "Iteration 51000: Training accuracy 0.94175, Test accuracy 0.9335 and Training loss 0.17190092210664537\n",
            "Iteration 51100: Training accuracy 0.9419333333333333, Test accuracy 0.928 and Training loss 0.17086452507447675\n",
            "Iteration 51200: Training accuracy 0.9423333333333334, Test accuracy 0.9306 and Training loss 0.17056057091009122\n",
            "Iteration 51300: Training accuracy 0.9424833333333333, Test accuracy 0.9311 and Training loss 0.1703187437485945\n",
            "Iteration 51400: Training accuracy 0.9424333333333333, Test accuracy 0.9301 and Training loss 0.17012913650306338\n",
            "Iteration 51500: Training accuracy 0.94275, Test accuracy 0.932 and Training loss 0.169871375139917\n",
            "Iteration 51600: Training accuracy 0.9426833333333333, Test accuracy 0.9308 and Training loss 0.16976086840029683\n",
            "Iteration 51700: Training accuracy 0.94285, Test accuracy 0.9316 and Training loss 0.1694481379240645\n",
            "Iteration 51800: Training accuracy 0.9429166666666666, Test accuracy 0.9311 and Training loss 0.16941851155130724\n",
            "Iteration 51900: Training accuracy 0.9427, Test accuracy 0.9296 and Training loss 0.16921055845325958\n",
            "Iteration 52000: Training accuracy 0.9428833333333333, Test accuracy 0.9327 and Training loss 0.16877667721981887\n",
            "Iteration 52100: Training accuracy 0.9431166666666667, Test accuracy 0.9311 and Training loss 0.16850529792110924\n",
            "Iteration 52200: Training accuracy 0.9426833333333333, Test accuracy 0.9279 and Training loss 0.1687891756872627\n",
            "Iteration 52300: Training accuracy 0.9428333333333333, Test accuracy 0.9317 and Training loss 0.16839121092364237\n",
            "Iteration 52400: Training accuracy 0.9433333333333334, Test accuracy 0.9323 and Training loss 0.1680975134641975\n",
            "Iteration 52500: Training accuracy 0.9435, Test accuracy 0.9317 and Training loss 0.16774195253491664\n",
            "Iteration 52600: Training accuracy 0.9434, Test accuracy 0.9329 and Training loss 0.16758383018554002\n",
            "Iteration 52700: Training accuracy 0.9436, Test accuracy 0.9329 and Training loss 0.16730861933608254\n",
            "Iteration 52800: Training accuracy 0.9435166666666667, Test accuracy 0.9327 and Training loss 0.1670723885064858\n",
            "Iteration 52900: Training accuracy 0.9435, Test accuracy 0.9311 and Training loss 0.16708991888605892\n",
            "Iteration 53000: Training accuracy 0.9436, Test accuracy 0.932 and Training loss 0.16671445688160885\n",
            "Iteration 53100: Training accuracy 0.94385, Test accuracy 0.931 and Training loss 0.16664601682191088\n",
            "Iteration 53200: Training accuracy 0.94405, Test accuracy 0.9327 and Training loss 0.16641392768201071\n",
            "Iteration 53300: Training accuracy 0.9437333333333333, Test accuracy 0.9344 and Training loss 0.16648408044216995\n",
            "Iteration 53400: Training accuracy 0.9438833333333333, Test accuracy 0.9312 and Training loss 0.16574518088698798\n",
            "Iteration 53500: Training accuracy 0.9441333333333334, Test accuracy 0.9331 and Training loss 0.16561624996230354\n",
            "Iteration 53600: Training accuracy 0.94405, Test accuracy 0.9329 and Training loss 0.1654256797610984\n",
            "Iteration 53700: Training accuracy 0.9441166666666667, Test accuracy 0.934 and Training loss 0.16559023576742002\n",
            "Iteration 53800: Training accuracy 0.9438666666666666, Test accuracy 0.9342 and Training loss 0.16570321166426255\n",
            "Iteration 53900: Training accuracy 0.9442833333333334, Test accuracy 0.9312 and Training loss 0.16521210226905153\n",
            "Iteration 54000: Training accuracy 0.94455, Test accuracy 0.9306 and Training loss 0.1646663905282506\n",
            "Iteration 54100: Training accuracy 0.9441333333333334, Test accuracy 0.9337 and Training loss 0.16477124905227017\n",
            "Iteration 54200: Training accuracy 0.9445833333333333, Test accuracy 0.9317 and Training loss 0.1640859437584525\n",
            "Iteration 54300: Training accuracy 0.9444666666666667, Test accuracy 0.9316 and Training loss 0.1639686392691147\n",
            "Iteration 54400: Training accuracy 0.9444166666666667, Test accuracy 0.9282 and Training loss 0.16442390911532748\n",
            "Iteration 54500: Training accuracy 0.9435166666666667, Test accuracy 0.927 and Training loss 0.16496281208519462\n",
            "Iteration 54600: Training accuracy 0.9447, Test accuracy 0.9336 and Training loss 0.16338563089141772\n",
            "Iteration 54700: Training accuracy 0.9447666666666666, Test accuracy 0.9299 and Training loss 0.1635089409030753\n",
            "Iteration 54800: Training accuracy 0.9445333333333333, Test accuracy 0.9309 and Training loss 0.1633091402271745\n",
            "Iteration 54900: Training accuracy 0.9434333333333333, Test accuracy 0.9349 and Training loss 0.1645109572886998\n",
            "Iteration 55000: Training accuracy 0.9445166666666667, Test accuracy 0.9342 and Training loss 0.16299055671084697\n",
            "Iteration 55100: Training accuracy 0.9447666666666666, Test accuracy 0.9293 and Training loss 0.16264513436817343\n",
            "Iteration 55200: Training accuracy 0.9447666666666666, Test accuracy 0.9344 and Training loss 0.16296165286196723\n",
            "Iteration 55300: Training accuracy 0.9452166666666667, Test accuracy 0.9314 and Training loss 0.16211748655175964\n",
            "Iteration 55400: Training accuracy 0.9452333333333334, Test accuracy 0.9329 and Training loss 0.1618700015031133\n",
            "Iteration 55500: Training accuracy 0.9447333333333333, Test accuracy 0.9298 and Training loss 0.16195623691848618\n",
            "Iteration 55600: Training accuracy 0.945, Test accuracy 0.933 and Training loss 0.161517421322307\n",
            "Iteration 55700: Training accuracy 0.9451833333333334, Test accuracy 0.9331 and Training loss 0.16154360190438452\n",
            "Iteration 55800: Training accuracy 0.94535, Test accuracy 0.9333 and Training loss 0.16116512947950076\n",
            "Iteration 55900: Training accuracy 0.9451166666666667, Test accuracy 0.9338 and Training loss 0.16154630787961563\n",
            "Iteration 56000: Training accuracy 0.9452833333333334, Test accuracy 0.9297 and Training loss 0.1610178539855751\n",
            "Iteration 56100: Training accuracy 0.9454833333333333, Test accuracy 0.9317 and Training loss 0.16055341520421418\n",
            "Iteration 56200: Training accuracy 0.9462666666666667, Test accuracy 0.9307 and Training loss 0.16052450002410473\n",
            "Iteration 56300: Training accuracy 0.94545, Test accuracy 0.9297 and Training loss 0.16047839629818303\n",
            "Iteration 56400: Training accuracy 0.9450666666666667, Test accuracy 0.936 and Training loss 0.16108865926433144\n",
            "Iteration 56500: Training accuracy 0.9461166666666667, Test accuracy 0.9334 and Training loss 0.16000598294120313\n",
            "Iteration 56600: Training accuracy 0.9461666666666667, Test accuracy 0.9323 and Training loss 0.15958338810117814\n",
            "Iteration 56700: Training accuracy 0.9461166666666667, Test accuracy 0.9339 and Training loss 0.15950922410530588\n",
            "Iteration 56800: Training accuracy 0.9458666666666666, Test accuracy 0.9349 and Training loss 0.1595951571828819\n",
            "Iteration 56900: Training accuracy 0.9464166666666667, Test accuracy 0.9326 and Training loss 0.1590458381996004\n",
            "Iteration 57000: Training accuracy 0.9461166666666667, Test accuracy 0.9357 and Training loss 0.15911602285220935\n",
            "Iteration 57100: Training accuracy 0.9460833333333334, Test accuracy 0.9361 and Training loss 0.15911189778033452\n",
            "Iteration 57200: Training accuracy 0.9459166666666666, Test accuracy 0.9332 and Training loss 0.15858231958420593\n",
            "Iteration 57300: Training accuracy 0.9460333333333333, Test accuracy 0.9336 and Training loss 0.1584201058945093\n",
            "Iteration 57400: Training accuracy 0.94655, Test accuracy 0.9347 and Training loss 0.15817278639983828\n",
            "Iteration 57500: Training accuracy 0.9464, Test accuracy 0.9367 and Training loss 0.15835197084089805\n",
            "Iteration 57600: Training accuracy 0.9459833333333333, Test accuracy 0.938 and Training loss 0.15912635187364624\n",
            "Iteration 57700: Training accuracy 0.9467333333333333, Test accuracy 0.9323 and Training loss 0.15788041093560343\n",
            "Iteration 57800: Training accuracy 0.9467833333333333, Test accuracy 0.9327 and Training loss 0.15746088583538573\n",
            "Iteration 57900: Training accuracy 0.94705, Test accuracy 0.9334 and Training loss 0.15718318728981814\n",
            "Iteration 58000: Training accuracy 0.9471833333333334, Test accuracy 0.9321 and Training loss 0.15731524075963682\n",
            "Iteration 58100: Training accuracy 0.94755, Test accuracy 0.9348 and Training loss 0.15690849539332274\n",
            "Iteration 58200: Training accuracy 0.9466, Test accuracy 0.9387 and Training loss 0.15826138235979736\n",
            "Iteration 58300: Training accuracy 0.9476833333333333, Test accuracy 0.9313 and Training loss 0.15681229195114596\n",
            "Iteration 58400: Training accuracy 0.9468, Test accuracy 0.9387 and Training loss 0.15791482831657971\n",
            "Iteration 58500: Training accuracy 0.9478166666666666, Test accuracy 0.9355 and Training loss 0.15663165744471783\n",
            "Iteration 58600: Training accuracy 0.9473333333333334, Test accuracy 0.9299 and Training loss 0.15645141244341954\n",
            "Iteration 58700: Training accuracy 0.9471166666666667, Test accuracy 0.9291 and Training loss 0.15672074132540992\n",
            "Iteration 58800: Training accuracy 0.94715, Test accuracy 0.9278 and Training loss 0.15680967530516474\n",
            "Iteration 58900: Training accuracy 0.9470666666666666, Test accuracy 0.928 and Training loss 0.1565822973124312\n",
            "Iteration 59000: Training accuracy 0.9476666666666667, Test accuracy 0.9316 and Training loss 0.15551697531187678\n",
            "Iteration 59100: Training accuracy 0.9477833333333333, Test accuracy 0.9325 and Training loss 0.15522254661082477\n",
            "Iteration 59200: Training accuracy 0.9475833333333333, Test accuracy 0.9324 and Training loss 0.15518521611836894\n",
            "Iteration 59300: Training accuracy 0.9478166666666666, Test accuracy 0.9344 and Training loss 0.15485815669941333\n",
            "Iteration 59400: Training accuracy 0.9477333333333333, Test accuracy 0.9314 and Training loss 0.1551303046093114\n",
            "Iteration 59500: Training accuracy 0.9476, Test accuracy 0.932 and Training loss 0.1545774346011919\n",
            "Iteration 59600: Training accuracy 0.9479166666666666, Test accuracy 0.9302 and Training loss 0.1545937452268086\n",
            "Iteration 59700: Training accuracy 0.9479833333333333, Test accuracy 0.9318 and Training loss 0.15405643218259268\n",
            "Iteration 59800: Training accuracy 0.9478833333333333, Test accuracy 0.9343 and Training loss 0.1543407853840634\n",
            "Iteration 59900: Training accuracy 0.9477, Test accuracy 0.9346 and Training loss 0.1544326173463381\n",
            "Iteration 60000: Training accuracy 0.9480833333333333, Test accuracy 0.9313 and Training loss 0.15368140478137712\n",
            "Final test accuracy for k = 40: 0.9313\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training with k = 200\n",
            "Iteration 0: Training accuracy 0.4655166666666667, test accuracy 0.4326 and Training loss 0.6931951249217263\n",
            "Iteration 100: Training accuracy 0.5067833333333334, Test accuracy 0.5114 and Training loss 0.6930107208267342\n",
            "Iteration 200: Training accuracy 0.5447, Test accuracy 0.5676 and Training loss 0.6928054238751753\n",
            "Iteration 300: Training accuracy 0.6014166666666667, Test accuracy 0.6256 and Training loss 0.6926040229165052\n",
            "Iteration 400: Training accuracy 0.6552666666666667, Test accuracy 0.6814 and Training loss 0.6923890072993393\n",
            "Iteration 500: Training accuracy 0.6846, Test accuracy 0.7025 and Training loss 0.692152314333421\n",
            "Iteration 600: Training accuracy 0.7308, Test accuracy 0.7395 and Training loss 0.6918982901423401\n",
            "Iteration 700: Training accuracy 0.7306833333333334, Test accuracy 0.7382 and Training loss 0.6915734153867416\n",
            "Iteration 800: Training accuracy 0.7485, Test accuracy 0.7525 and Training loss 0.6912444464064825\n",
            "Iteration 900: Training accuracy 0.7572166666666666, Test accuracy 0.761 and Training loss 0.6908848523938873\n",
            "Iteration 1000: Training accuracy 0.7504166666666666, Test accuracy 0.7542 and Training loss 0.6904587338359852\n",
            "Iteration 1100: Training accuracy 0.7477666666666667, Test accuracy 0.7497 and Training loss 0.68997346457045\n",
            "Iteration 1200: Training accuracy 0.7494, Test accuracy 0.7456 and Training loss 0.6895241113536725\n",
            "Iteration 1300: Training accuracy 0.7549833333333333, Test accuracy 0.7543 and Training loss 0.6889844959584033\n",
            "Iteration 1400: Training accuracy 0.7621166666666667, Test accuracy 0.7614 and Training loss 0.6883418179241292\n",
            "Iteration 1500: Training accuracy 0.7574333333333333, Test accuracy 0.7577 and Training loss 0.6875994637289645\n",
            "Iteration 1600: Training accuracy 0.7552166666666666, Test accuracy 0.756 and Training loss 0.6867885815553725\n",
            "Iteration 1700: Training accuracy 0.7562, Test accuracy 0.7567 and Training loss 0.6859114048748265\n",
            "Iteration 1800: Training accuracy 0.7517333333333334, Test accuracy 0.7518 and Training loss 0.6848601679791042\n",
            "Iteration 1900: Training accuracy 0.7560666666666667, Test accuracy 0.7556 and Training loss 0.6838216739771081\n",
            "Iteration 2000: Training accuracy 0.7555666666666667, Test accuracy 0.755 and Training loss 0.6826823680883991\n",
            "Iteration 2100: Training accuracy 0.7607666666666667, Test accuracy 0.7609 and Training loss 0.6813854209287316\n",
            "Iteration 2200: Training accuracy 0.76035, Test accuracy 0.7601 and Training loss 0.6798464731230658\n",
            "Iteration 2300: Training accuracy 0.7602666666666666, Test accuracy 0.7591 and Training loss 0.6781128526052154\n",
            "Iteration 2400: Training accuracy 0.7606833333333334, Test accuracy 0.7594 and Training loss 0.6761412216101903\n",
            "Iteration 2500: Training accuracy 0.7614333333333333, Test accuracy 0.7587 and Training loss 0.6739968324630002\n",
            "Iteration 2600: Training accuracy 0.7668, Test accuracy 0.7685 and Training loss 0.671738413901862\n",
            "Iteration 2700: Training accuracy 0.7658166666666667, Test accuracy 0.7671 and Training loss 0.6690191148858098\n",
            "Iteration 2800: Training accuracy 0.7637166666666667, Test accuracy 0.7636 and Training loss 0.6662275813895064\n",
            "Iteration 2900: Training accuracy 0.7644833333333333, Test accuracy 0.766 and Training loss 0.6630996149613468\n",
            "Iteration 3000: Training accuracy 0.7672166666666667, Test accuracy 0.7684 and Training loss 0.6597898666227714\n",
            "Iteration 3100: Training accuracy 0.7662833333333333, Test accuracy 0.7658 and Training loss 0.656077260970601\n",
            "Iteration 3200: Training accuracy 0.7676166666666666, Test accuracy 0.7687 and Training loss 0.651938444516902\n",
            "Iteration 3300: Training accuracy 0.7675666666666666, Test accuracy 0.7691 and Training loss 0.6475338940800414\n",
            "Iteration 3400: Training accuracy 0.76845, Test accuracy 0.7701 and Training loss 0.6428671672851144\n",
            "Iteration 3500: Training accuracy 0.7692666666666667, Test accuracy 0.7721 and Training loss 0.6378175106552455\n",
            "Iteration 3600: Training accuracy 0.77055, Test accuracy 0.7741 and Training loss 0.6332603152705112\n",
            "Iteration 3700: Training accuracy 0.7713833333333333, Test accuracy 0.7751 and Training loss 0.6278858265200413\n",
            "Iteration 3800: Training accuracy 0.7729666666666667, Test accuracy 0.7744 and Training loss 0.622023468771926\n",
            "Iteration 3900: Training accuracy 0.7725666666666666, Test accuracy 0.7776 and Training loss 0.6156216452195282\n",
            "Iteration 4000: Training accuracy 0.7734833333333333, Test accuracy 0.7775 and Training loss 0.6096780040603773\n",
            "Iteration 4100: Training accuracy 0.77365, Test accuracy 0.7785 and Training loss 0.6029895996723853\n",
            "Iteration 4200: Training accuracy 0.7732333333333333, Test accuracy 0.7803 and Training loss 0.5958128538457153\n",
            "Iteration 4300: Training accuracy 0.7749333333333334, Test accuracy 0.7811 and Training loss 0.5886649042285328\n",
            "Iteration 4400: Training accuracy 0.7749, Test accuracy 0.781 and Training loss 0.5821844836995566\n",
            "Iteration 4500: Training accuracy 0.7768833333333334, Test accuracy 0.7833 and Training loss 0.5746085563911322\n",
            "Iteration 4600: Training accuracy 0.77645, Test accuracy 0.7834 and Training loss 0.5677119775161802\n",
            "Iteration 4700: Training accuracy 0.77705, Test accuracy 0.7831 and Training loss 0.5599857174463287\n",
            "Iteration 4800: Training accuracy 0.77815, Test accuracy 0.7837 and Training loss 0.5534072737184158\n",
            "Iteration 4900: Training accuracy 0.7785333333333333, Test accuracy 0.7847 and Training loss 0.5470654266127858\n",
            "Iteration 5000: Training accuracy 0.7797, Test accuracy 0.7858 and Training loss 0.540557352991695\n",
            "Iteration 5100: Training accuracy 0.7813166666666667, Test accuracy 0.7865 and Training loss 0.5348210278206693\n",
            "Iteration 5200: Training accuracy 0.78205, Test accuracy 0.7869 and Training loss 0.5288700227468494\n",
            "Iteration 5300: Training accuracy 0.7819666666666667, Test accuracy 0.7887 and Training loss 0.5230173664842296\n",
            "Iteration 5400: Training accuracy 0.7827833333333334, Test accuracy 0.7891 and Training loss 0.517286467184888\n",
            "Iteration 5500: Training accuracy 0.7841833333333333, Test accuracy 0.79 and Training loss 0.5118240558673208\n",
            "Iteration 5600: Training accuracy 0.7836166666666666, Test accuracy 0.7912 and Training loss 0.5066300028450053\n",
            "Iteration 5700: Training accuracy 0.7860333333333334, Test accuracy 0.7934 and Training loss 0.501597131299783\n",
            "Iteration 5800: Training accuracy 0.7864666666666666, Test accuracy 0.795 and Training loss 0.4971284944236762\n",
            "Iteration 5900: Training accuracy 0.7884, Test accuracy 0.7935 and Training loss 0.4925307897262382\n",
            "Iteration 6000: Training accuracy 0.7891, Test accuracy 0.7957 and Training loss 0.48835712796040476\n",
            "Iteration 6100: Training accuracy 0.7897333333333333, Test accuracy 0.797 and Training loss 0.48416659676638507\n",
            "Iteration 6200: Training accuracy 0.7915666666666666, Test accuracy 0.7957 and Training loss 0.48024338855433024\n",
            "Iteration 6300: Training accuracy 0.79275, Test accuracy 0.7962 and Training loss 0.476296874322131\n",
            "Iteration 6400: Training accuracy 0.79535, Test accuracy 0.7939 and Training loss 0.47371594832066316\n",
            "Iteration 6500: Training accuracy 0.7963666666666667, Test accuracy 0.7961 and Training loss 0.46994372886026214\n",
            "Iteration 6600: Training accuracy 0.7973166666666667, Test accuracy 0.7958 and Training loss 0.46698593348732365\n",
            "Iteration 6700: Training accuracy 0.7988166666666666, Test accuracy 0.7985 and Training loss 0.4631428521738739\n",
            "Iteration 6800: Training accuracy 0.8006833333333333, Test accuracy 0.7972 and Training loss 0.4600778808163461\n",
            "Iteration 6900: Training accuracy 0.8017833333333333, Test accuracy 0.7968 and Training loss 0.457310108272279\n",
            "Iteration 7000: Training accuracy 0.8027333333333333, Test accuracy 0.796 and Training loss 0.45483374823050904\n",
            "Iteration 7100: Training accuracy 0.8041333333333334, Test accuracy 0.8011 and Training loss 0.4513491332042922\n",
            "Iteration 7200: Training accuracy 0.80305, Test accuracy 0.8072 and Training loss 0.44828992997398703\n",
            "Iteration 7300: Training accuracy 0.8042333333333334, Test accuracy 0.8084 and Training loss 0.44608645536273844\n",
            "Iteration 7400: Training accuracy 0.8056333333333333, Test accuracy 0.8105 and Training loss 0.44364258810200313\n",
            "Iteration 7500: Training accuracy 0.80765, Test accuracy 0.8078 and Training loss 0.44087387690429686\n",
            "Iteration 7600: Training accuracy 0.8083833333333333, Test accuracy 0.8094 and Training loss 0.4387873434367087\n",
            "Iteration 7700: Training accuracy 0.8091666666666667, Test accuracy 0.809 and Training loss 0.4363779563340821\n",
            "Iteration 7800: Training accuracy 0.81005, Test accuracy 0.8089 and Training loss 0.43409372502621946\n",
            "Iteration 7900: Training accuracy 0.8090333333333334, Test accuracy 0.8137 and Training loss 0.4326415265858424\n",
            "Iteration 8000: Training accuracy 0.8124, Test accuracy 0.8132 and Training loss 0.42978319575121426\n",
            "Iteration 8100: Training accuracy 0.8135833333333333, Test accuracy 0.811 and Training loss 0.4276338720225932\n",
            "Iteration 8200: Training accuracy 0.8145666666666667, Test accuracy 0.8078 and Training loss 0.4259878619391795\n",
            "Iteration 8300: Training accuracy 0.81465, Test accuracy 0.8123 and Training loss 0.4238553558317252\n",
            "Iteration 8400: Training accuracy 0.8145166666666667, Test accuracy 0.8139 and Training loss 0.4218989875085502\n",
            "Iteration 8500: Training accuracy 0.8156, Test accuracy 0.8148 and Training loss 0.42028598003813467\n",
            "Iteration 8600: Training accuracy 0.8160666666666667, Test accuracy 0.8177 and Training loss 0.4185327985297376\n",
            "Iteration 8700: Training accuracy 0.8181833333333334, Test accuracy 0.811 and Training loss 0.41666187297192203\n",
            "Iteration 8800: Training accuracy 0.8190166666666666, Test accuracy 0.811 and Training loss 0.4151093476893943\n",
            "Iteration 8900: Training accuracy 0.8195333333333333, Test accuracy 0.8105 and Training loss 0.4134453521056554\n",
            "Iteration 9000: Training accuracy 0.8212, Test accuracy 0.8129 and Training loss 0.41159901722595527\n",
            "Iteration 9100: Training accuracy 0.8223, Test accuracy 0.8145 and Training loss 0.4101342867641268\n",
            "Iteration 9200: Training accuracy 0.8231333333333334, Test accuracy 0.8138 and Training loss 0.4085395110898245\n",
            "Iteration 9300: Training accuracy 0.8239833333333333, Test accuracy 0.8147 and Training loss 0.40685072138405415\n",
            "Iteration 9400: Training accuracy 0.8242166666666667, Test accuracy 0.8186 and Training loss 0.4056250676170928\n",
            "Iteration 9500: Training accuracy 0.8258666666666666, Test accuracy 0.8132 and Training loss 0.4042446233233757\n",
            "Iteration 9600: Training accuracy 0.8261, Test accuracy 0.8193 and Training loss 0.4026150344483478\n",
            "Iteration 9700: Training accuracy 0.8269166666666666, Test accuracy 0.8197 and Training loss 0.40101281107649045\n",
            "Iteration 9800: Training accuracy 0.82745, Test accuracy 0.8203 and Training loss 0.3996214402335583\n",
            "Iteration 9900: Training accuracy 0.8279666666666666, Test accuracy 0.8213 and Training loss 0.39831237969978217\n",
            "Iteration 10000: Training accuracy 0.8291, Test accuracy 0.822 and Training loss 0.397058654464811\n",
            "Iteration 10100: Training accuracy 0.8309, Test accuracy 0.8203 and Training loss 0.3957125481138152\n",
            "Iteration 10200: Training accuracy 0.8308833333333333, Test accuracy 0.8243 and Training loss 0.39453513414640146\n",
            "Iteration 10300: Training accuracy 0.8319166666666666, Test accuracy 0.8259 and Training loss 0.39346029149118916\n",
            "Iteration 10400: Training accuracy 0.8321, Test accuracy 0.8264 and Training loss 0.39209266670349935\n",
            "Iteration 10500: Training accuracy 0.8330333333333333, Test accuracy 0.824 and Training loss 0.39064811673453237\n",
            "Iteration 10600: Training accuracy 0.8340833333333333, Test accuracy 0.8228 and Training loss 0.38958526015510353\n",
            "Iteration 10700: Training accuracy 0.8334166666666667, Test accuracy 0.8287 and Training loss 0.38871966821479165\n",
            "Iteration 10800: Training accuracy 0.8349666666666666, Test accuracy 0.821 and Training loss 0.38714090750068436\n",
            "Iteration 10900: Training accuracy 0.8355166666666667, Test accuracy 0.8239 and Training loss 0.3857164779551759\n",
            "Iteration 11000: Training accuracy 0.8366, Test accuracy 0.8284 and Training loss 0.3847450522051971\n",
            "Iteration 11100: Training accuracy 0.8376833333333333, Test accuracy 0.8297 and Training loss 0.3834938824347771\n",
            "Iteration 11200: Training accuracy 0.8379666666666666, Test accuracy 0.8273 and Training loss 0.3824090099652293\n",
            "Iteration 11300: Training accuracy 0.8384833333333334, Test accuracy 0.8298 and Training loss 0.3813100492539318\n",
            "Iteration 11400: Training accuracy 0.8392833333333334, Test accuracy 0.8284 and Training loss 0.380158585796768\n",
            "Iteration 11500: Training accuracy 0.83935, Test accuracy 0.8327 and Training loss 0.378996327140254\n",
            "Iteration 11600: Training accuracy 0.8394, Test accuracy 0.8327 and Training loss 0.37803494429867157\n",
            "Iteration 11700: Training accuracy 0.8399166666666666, Test accuracy 0.8349 and Training loss 0.3771945854747308\n",
            "Iteration 11800: Training accuracy 0.8404, Test accuracy 0.8309 and Training loss 0.3759883970705184\n",
            "Iteration 11900: Training accuracy 0.8408333333333333, Test accuracy 0.8333 and Training loss 0.374868220474515\n",
            "Iteration 12000: Training accuracy 0.84055, Test accuracy 0.8378 and Training loss 0.37424105012952036\n",
            "Iteration 12100: Training accuracy 0.8413833333333334, Test accuracy 0.8303 and Training loss 0.37335554267971965\n",
            "Iteration 12200: Training accuracy 0.8412666666666667, Test accuracy 0.8323 and Training loss 0.3722041129589872\n",
            "Iteration 12300: Training accuracy 0.8424166666666667, Test accuracy 0.8368 and Training loss 0.3708815469803463\n",
            "Iteration 12400: Training accuracy 0.843, Test accuracy 0.83 and Training loss 0.3702899587071953\n",
            "Iteration 12500: Training accuracy 0.8429833333333333, Test accuracy 0.8413 and Training loss 0.36939633741690775\n",
            "Iteration 12600: Training accuracy 0.8434166666666667, Test accuracy 0.842 and Training loss 0.36858220441709066\n",
            "Iteration 12700: Training accuracy 0.8455666666666667, Test accuracy 0.8402 and Training loss 0.3669191235908833\n",
            "Iteration 12800: Training accuracy 0.8463, Test accuracy 0.8377 and Training loss 0.3659195875642233\n",
            "Iteration 12900: Training accuracy 0.8461166666666666, Test accuracy 0.8383 and Training loss 0.36500020385472937\n",
            "Iteration 13000: Training accuracy 0.8461333333333333, Test accuracy 0.8348 and Training loss 0.36454877656180107\n",
            "Iteration 13100: Training accuracy 0.8469333333333333, Test accuracy 0.8387 and Training loss 0.36339424977612067\n",
            "Iteration 13200: Training accuracy 0.8472, Test accuracy 0.8415 and Training loss 0.36249478117454553\n",
            "Iteration 13300: Training accuracy 0.8472833333333334, Test accuracy 0.8381 and Training loss 0.3617327639661932\n",
            "Iteration 13400: Training accuracy 0.8479666666666666, Test accuracy 0.8385 and Training loss 0.3604393855356946\n",
            "Iteration 13500: Training accuracy 0.8486, Test accuracy 0.8406 and Training loss 0.35938322060191635\n",
            "Iteration 13600: Training accuracy 0.8502333333333333, Test accuracy 0.8432 and Training loss 0.358346899456146\n",
            "Iteration 13700: Training accuracy 0.8507833333333333, Test accuracy 0.8448 and Training loss 0.3576618440612137\n",
            "Iteration 13800: Training accuracy 0.8508666666666667, Test accuracy 0.8421 and Training loss 0.3566236126835726\n",
            "Iteration 13900: Training accuracy 0.8514666666666667, Test accuracy 0.8391 and Training loss 0.3561660391762036\n",
            "Iteration 14000: Training accuracy 0.8518833333333333, Test accuracy 0.8403 and Training loss 0.3550106243184319\n",
            "Iteration 14100: Training accuracy 0.85295, Test accuracy 0.8444 and Training loss 0.35409806088969054\n",
            "Iteration 14200: Training accuracy 0.8534833333333334, Test accuracy 0.8461 and Training loss 0.353089061669755\n",
            "Iteration 14300: Training accuracy 0.85415, Test accuracy 0.8462 and Training loss 0.35215144863965997\n",
            "Iteration 14400: Training accuracy 0.8551833333333333, Test accuracy 0.8463 and Training loss 0.35124635426873974\n",
            "Iteration 14500: Training accuracy 0.8556, Test accuracy 0.8504 and Training loss 0.3507684157652452\n",
            "Iteration 14600: Training accuracy 0.8561833333333333, Test accuracy 0.8529 and Training loss 0.3503637204333735\n",
            "Iteration 14700: Training accuracy 0.8569333333333333, Test accuracy 0.8485 and Training loss 0.34849685236081296\n",
            "Iteration 14800: Training accuracy 0.85685, Test accuracy 0.8458 and Training loss 0.34782834940457047\n",
            "Iteration 14900: Training accuracy 0.8579666666666667, Test accuracy 0.8534 and Training loss 0.34673348165629564\n",
            "Iteration 15000: Training accuracy 0.8582, Test accuracy 0.8543 and Training loss 0.3459272901191603\n",
            "Iteration 15100: Training accuracy 0.8578666666666667, Test accuracy 0.8523 and Training loss 0.34493267276272277\n",
            "Iteration 15200: Training accuracy 0.858, Test accuracy 0.8548 and Training loss 0.34434479526819584\n",
            "Iteration 15300: Training accuracy 0.8585333333333334, Test accuracy 0.8575 and Training loss 0.34380624546569233\n",
            "Iteration 15400: Training accuracy 0.8592, Test accuracy 0.8518 and Training loss 0.34229246452633316\n",
            "Iteration 15500: Training accuracy 0.8606, Test accuracy 0.8531 and Training loss 0.3413603064862653\n",
            "Iteration 15600: Training accuracy 0.8605333333333334, Test accuracy 0.8512 and Training loss 0.3407656948519049\n",
            "Iteration 15700: Training accuracy 0.8603166666666666, Test accuracy 0.8611 and Training loss 0.3400941790667763\n",
            "Iteration 15800: Training accuracy 0.86175, Test accuracy 0.8579 and Training loss 0.33863586203550555\n",
            "Iteration 15900: Training accuracy 0.8616666666666667, Test accuracy 0.8622 and Training loss 0.3380233789053176\n",
            "Iteration 16000: Training accuracy 0.863, Test accuracy 0.8589 and Training loss 0.3368378158379654\n",
            "Iteration 16100: Training accuracy 0.8632666666666666, Test accuracy 0.8628 and Training loss 0.3361077709830955\n",
            "Iteration 16200: Training accuracy 0.86425, Test accuracy 0.8636 and Training loss 0.33524422175006313\n",
            "Iteration 16300: Training accuracy 0.8652166666666666, Test accuracy 0.8608 and Training loss 0.33435024570342686\n",
            "Iteration 16400: Training accuracy 0.8654166666666666, Test accuracy 0.861 and Training loss 0.3333867933950235\n",
            "Iteration 16500: Training accuracy 0.8650333333333333, Test accuracy 0.867 and Training loss 0.33258194766473914\n",
            "Iteration 16600: Training accuracy 0.8655833333333334, Test accuracy 0.8668 and Training loss 0.33177870183315783\n",
            "Iteration 16700: Training accuracy 0.8673333333333333, Test accuracy 0.8621 and Training loss 0.33086974551173215\n",
            "Iteration 16800: Training accuracy 0.8673666666666666, Test accuracy 0.8599 and Training loss 0.33048246923451685\n",
            "Iteration 16900: Training accuracy 0.8678, Test accuracy 0.8627 and Training loss 0.32909830291293807\n",
            "Iteration 17000: Training accuracy 0.8675833333333334, Test accuracy 0.8688 and Training loss 0.3281137491870086\n",
            "Iteration 17100: Training accuracy 0.8686333333333334, Test accuracy 0.8677 and Training loss 0.3271207291949137\n",
            "Iteration 17200: Training accuracy 0.8701166666666666, Test accuracy 0.8676 and Training loss 0.32625972081265436\n",
            "Iteration 17300: Training accuracy 0.8699, Test accuracy 0.8718 and Training loss 0.32552695705952645\n",
            "Iteration 17400: Training accuracy 0.8712666666666666, Test accuracy 0.8671 and Training loss 0.3246547634446327\n",
            "Iteration 17500: Training accuracy 0.8715333333333334, Test accuracy 0.8711 and Training loss 0.3235815985858349\n",
            "Iteration 17600: Training accuracy 0.8714833333333334, Test accuracy 0.8729 and Training loss 0.32262190055792206\n",
            "Iteration 17700: Training accuracy 0.8727166666666667, Test accuracy 0.87 and Training loss 0.3216010365397874\n",
            "Iteration 17800: Training accuracy 0.8732666666666666, Test accuracy 0.8696 and Training loss 0.32080020657852787\n",
            "Iteration 17900: Training accuracy 0.873, Test accuracy 0.8712 and Training loss 0.3198972543960459\n",
            "Iteration 18000: Training accuracy 0.8736833333333334, Test accuracy 0.8731 and Training loss 0.3188834615272194\n",
            "Iteration 18100: Training accuracy 0.8744666666666666, Test accuracy 0.8694 and Training loss 0.3184864447296588\n",
            "Iteration 18200: Training accuracy 0.8740666666666667, Test accuracy 0.8674 and Training loss 0.3178766599337518\n",
            "Iteration 18300: Training accuracy 0.8742833333333333, Test accuracy 0.8718 and Training loss 0.31647407106497744\n",
            "Iteration 18400: Training accuracy 0.8745, Test accuracy 0.8738 and Training loss 0.3156490105421425\n",
            "Iteration 18500: Training accuracy 0.8746833333333334, Test accuracy 0.875 and Training loss 0.31466732865102653\n",
            "Iteration 18600: Training accuracy 0.8736666666666667, Test accuracy 0.8807 and Training loss 0.31511169111722676\n",
            "Iteration 18700: Training accuracy 0.87565, Test accuracy 0.8781 and Training loss 0.3129452471106089\n",
            "Iteration 18800: Training accuracy 0.8759, Test accuracy 0.879 and Training loss 0.3122006845181806\n",
            "Iteration 18900: Training accuracy 0.8770333333333333, Test accuracy 0.8796 and Training loss 0.3112391431574244\n",
            "Iteration 19000: Training accuracy 0.8765666666666667, Test accuracy 0.8808 and Training loss 0.31079365497184397\n",
            "Iteration 19100: Training accuracy 0.8776, Test accuracy 0.881 and Training loss 0.3095598932539287\n",
            "Iteration 19200: Training accuracy 0.87785, Test accuracy 0.8795 and Training loss 0.30915084741560933\n",
            "Iteration 19300: Training accuracy 0.8784, Test accuracy 0.881 and Training loss 0.30804594155588855\n",
            "Iteration 19400: Training accuracy 0.88, Test accuracy 0.8859 and Training loss 0.30668031406961666\n",
            "Iteration 19500: Training accuracy 0.88065, Test accuracy 0.8852 and Training loss 0.3057165418225383\n",
            "Iteration 19600: Training accuracy 0.8809666666666667, Test accuracy 0.8877 and Training loss 0.30501319129473137\n",
            "Iteration 19700: Training accuracy 0.8809166666666667, Test accuracy 0.8887 and Training loss 0.3047855741496507\n",
            "Iteration 19800: Training accuracy 0.88195, Test accuracy 0.8869 and Training loss 0.30310044062080405\n",
            "Iteration 19900: Training accuracy 0.8819833333333333, Test accuracy 0.8881 and Training loss 0.30222421687495066\n",
            "Iteration 20000: Training accuracy 0.8831333333333333, Test accuracy 0.8898 and Training loss 0.3019063049913455\n",
            "Iteration 20100: Training accuracy 0.88305, Test accuracy 0.8879 and Training loss 0.3005541416618858\n",
            "Iteration 20200: Training accuracy 0.8831666666666667, Test accuracy 0.8876 and Training loss 0.29980287868364475\n",
            "Iteration 20300: Training accuracy 0.8837166666666667, Test accuracy 0.8873 and Training loss 0.29885276016029977\n",
            "Iteration 20400: Training accuracy 0.8839666666666667, Test accuracy 0.8884 and Training loss 0.29827265423153315\n",
            "Iteration 20500: Training accuracy 0.8839333333333333, Test accuracy 0.8886 and Training loss 0.29779207952199854\n",
            "Iteration 20600: Training accuracy 0.8849833333333333, Test accuracy 0.8899 and Training loss 0.29674828720444973\n",
            "Iteration 20700: Training accuracy 0.8855833333333333, Test accuracy 0.8888 and Training loss 0.29567559427370804\n",
            "Iteration 20800: Training accuracy 0.8858666666666667, Test accuracy 0.8895 and Training loss 0.29483809489666896\n",
            "Iteration 20900: Training accuracy 0.8862166666666667, Test accuracy 0.8884 and Training loss 0.29402624148575734\n",
            "Iteration 21000: Training accuracy 0.8864333333333333, Test accuracy 0.8908 and Training loss 0.29392335794116364\n",
            "Iteration 21100: Training accuracy 0.8867833333333334, Test accuracy 0.8911 and Training loss 0.2931662726428013\n",
            "Iteration 21200: Training accuracy 0.8873666666666666, Test accuracy 0.8907 and Training loss 0.2915724835459031\n",
            "Iteration 21300: Training accuracy 0.8877166666666667, Test accuracy 0.8913 and Training loss 0.2908722743587338\n",
            "Iteration 21400: Training accuracy 0.8886166666666667, Test accuracy 0.8923 and Training loss 0.29023022653983094\n",
            "Iteration 21500: Training accuracy 0.8894, Test accuracy 0.891 and Training loss 0.2892204853599788\n",
            "Iteration 21600: Training accuracy 0.8898, Test accuracy 0.8923 and Training loss 0.2883961177774579\n",
            "Iteration 21700: Training accuracy 0.8901333333333333, Test accuracy 0.8945 and Training loss 0.28775901037789675\n",
            "Iteration 21800: Training accuracy 0.8905166666666666, Test accuracy 0.8935 and Training loss 0.2868258516919932\n",
            "Iteration 21900: Training accuracy 0.8914166666666666, Test accuracy 0.8936 and Training loss 0.2860487185383721\n",
            "Iteration 22000: Training accuracy 0.8913166666666666, Test accuracy 0.8935 and Training loss 0.28535248468075836\n",
            "Iteration 22100: Training accuracy 0.8919666666666667, Test accuracy 0.8932 and Training loss 0.2848009559431751\n",
            "Iteration 22200: Training accuracy 0.8919333333333334, Test accuracy 0.8937 and Training loss 0.28416327838842015\n",
            "Iteration 22300: Training accuracy 0.8925166666666666, Test accuracy 0.8967 and Training loss 0.2831970576002799\n",
            "Iteration 22400: Training accuracy 0.8930333333333333, Test accuracy 0.895 and Training loss 0.2828690641374382\n",
            "Iteration 22500: Training accuracy 0.8928666666666667, Test accuracy 0.8962 and Training loss 0.2817475254232768\n",
            "Iteration 22600: Training accuracy 0.8933, Test accuracy 0.8979 and Training loss 0.28088207897671175\n",
            "Iteration 22700: Training accuracy 0.89415, Test accuracy 0.898 and Training loss 0.2801378198266928\n",
            "Iteration 22800: Training accuracy 0.8946166666666666, Test accuracy 0.8978 and Training loss 0.27955541564743897\n",
            "Iteration 22900: Training accuracy 0.8946666666666667, Test accuracy 0.8973 and Training loss 0.2787242268531922\n",
            "Iteration 23000: Training accuracy 0.8949333333333334, Test accuracy 0.8983 and Training loss 0.2779525475561918\n",
            "Iteration 23100: Training accuracy 0.8956333333333333, Test accuracy 0.8982 and Training loss 0.27719959023682444\n",
            "Iteration 23200: Training accuracy 0.89565, Test accuracy 0.8978 and Training loss 0.27656159861621715\n",
            "Iteration 23300: Training accuracy 0.8955666666666666, Test accuracy 0.8966 and Training loss 0.27591367109935055\n",
            "Iteration 23400: Training accuracy 0.8958833333333334, Test accuracy 0.8943 and Training loss 0.2768504259853288\n",
            "Iteration 23500: Training accuracy 0.8962166666666667, Test accuracy 0.8987 and Training loss 0.27451245381640355\n",
            "Iteration 23600: Training accuracy 0.8968666666666667, Test accuracy 0.8991 and Training loss 0.2737669514288486\n",
            "Iteration 23700: Training accuracy 0.89705, Test accuracy 0.9001 and Training loss 0.272956815803019\n",
            "Iteration 23800: Training accuracy 0.8976666666666666, Test accuracy 0.8988 and Training loss 0.2725835495130632\n",
            "Iteration 23900: Training accuracy 0.8985166666666666, Test accuracy 0.8999 and Training loss 0.2717823449182286\n",
            "Iteration 24000: Training accuracy 0.8995833333333333, Test accuracy 0.9007 and Training loss 0.27114650705484\n",
            "Iteration 24100: Training accuracy 0.8994666666666666, Test accuracy 0.8992 and Training loss 0.2708612190942188\n",
            "Iteration 24200: Training accuracy 0.8997166666666667, Test accuracy 0.8984 and Training loss 0.2704514364353755\n",
            "Iteration 24300: Training accuracy 0.8994333333333333, Test accuracy 0.9017 and Training loss 0.26905697726546157\n",
            "Iteration 24400: Training accuracy 0.8990166666666667, Test accuracy 0.9031 and Training loss 0.2686375087925839\n",
            "Iteration 24500: Training accuracy 0.8996, Test accuracy 0.9024 and Training loss 0.26785423049366147\n",
            "Iteration 24600: Training accuracy 0.9000166666666667, Test accuracy 0.9019 and Training loss 0.26731116579887276\n",
            "Iteration 24700: Training accuracy 0.9007666666666667, Test accuracy 0.9033 and Training loss 0.2664945993310617\n",
            "Iteration 24800: Training accuracy 0.9011, Test accuracy 0.9013 and Training loss 0.26594683009411474\n",
            "Iteration 24900: Training accuracy 0.9015333333333333, Test accuracy 0.9024 and Training loss 0.26541771528024394\n",
            "Iteration 25000: Training accuracy 0.9019333333333334, Test accuracy 0.9036 and Training loss 0.26439174236535096\n",
            "Iteration 25100: Training accuracy 0.9019166666666667, Test accuracy 0.9002 and Training loss 0.2645651835919942\n",
            "Iteration 25200: Training accuracy 0.9019666666666667, Test accuracy 0.9017 and Training loss 0.26361369041431143\n",
            "Iteration 25300: Training accuracy 0.9024, Test accuracy 0.9035 and Training loss 0.26256005314369485\n",
            "Iteration 25400: Training accuracy 0.9029333333333334, Test accuracy 0.9035 and Training loss 0.26190948166327527\n",
            "Iteration 25500: Training accuracy 0.9027833333333334, Test accuracy 0.9066 and Training loss 0.26142471134986855\n",
            "Iteration 25600: Training accuracy 0.9027833333333334, Test accuracy 0.9063 and Training loss 0.2606323079377906\n",
            "Iteration 25700: Training accuracy 0.9037833333333334, Test accuracy 0.9062 and Training loss 0.25981627864747475\n",
            "Iteration 25800: Training accuracy 0.9041833333333333, Test accuracy 0.9051 and Training loss 0.25936179906182044\n",
            "Iteration 25900: Training accuracy 0.9044333333333333, Test accuracy 0.9061 and Training loss 0.25862866020809144\n",
            "Iteration 26000: Training accuracy 0.9034166666666666, Test accuracy 0.9073 and Training loss 0.2580280126535994\n",
            "Iteration 26100: Training accuracy 0.9037166666666666, Test accuracy 0.9069 and Training loss 0.25743391241896496\n",
            "Iteration 26200: Training accuracy 0.9041, Test accuracy 0.9075 and Training loss 0.2569270139459117\n",
            "Iteration 26300: Training accuracy 0.9045833333333333, Test accuracy 0.9071 and Training loss 0.25632469920336853\n",
            "Iteration 26400: Training accuracy 0.9041666666666667, Test accuracy 0.9086 and Training loss 0.2563724590955804\n",
            "Iteration 26500: Training accuracy 0.9045833333333333, Test accuracy 0.9095 and Training loss 0.25551284736008717\n",
            "Iteration 26600: Training accuracy 0.9053166666666667, Test accuracy 0.9079 and Training loss 0.2543582760350798\n",
            "Iteration 26700: Training accuracy 0.9052833333333333, Test accuracy 0.9096 and Training loss 0.2549563192913833\n",
            "Iteration 26800: Training accuracy 0.9057, Test accuracy 0.9098 and Training loss 0.25338688254947334\n",
            "Iteration 26900: Training accuracy 0.9072, Test accuracy 0.907 and Training loss 0.2525800978914047\n",
            "Iteration 27000: Training accuracy 0.90715, Test accuracy 0.9094 and Training loss 0.251941921203044\n",
            "Iteration 27100: Training accuracy 0.90785, Test accuracy 0.909 and Training loss 0.2513823047722576\n",
            "Iteration 27200: Training accuracy 0.9077833333333334, Test accuracy 0.9092 and Training loss 0.25080753863209376\n",
            "Iteration 27300: Training accuracy 0.9081166666666667, Test accuracy 0.9108 and Training loss 0.25022667341777505\n",
            "Iteration 27400: Training accuracy 0.9083333333333333, Test accuracy 0.9113 and Training loss 0.24974845231084428\n",
            "Iteration 27500: Training accuracy 0.9082833333333333, Test accuracy 0.911 and Training loss 0.24960627129342589\n",
            "Iteration 27600: Training accuracy 0.909, Test accuracy 0.9104 and Training loss 0.24860896360635223\n",
            "Iteration 27700: Training accuracy 0.90895, Test accuracy 0.9108 and Training loss 0.2479177012741422\n",
            "Iteration 27800: Training accuracy 0.9095833333333333, Test accuracy 0.9107 and Training loss 0.24738535087559113\n",
            "Iteration 27900: Training accuracy 0.90975, Test accuracy 0.9114 and Training loss 0.24680255729814957\n",
            "Iteration 28000: Training accuracy 0.9100333333333334, Test accuracy 0.9108 and Training loss 0.24643417396522196\n",
            "Iteration 28100: Training accuracy 0.91035, Test accuracy 0.9117 and Training loss 0.2457003115149288\n",
            "Iteration 28200: Training accuracy 0.9107666666666666, Test accuracy 0.9123 and Training loss 0.24509232208865225\n",
            "Iteration 28300: Training accuracy 0.9111333333333334, Test accuracy 0.9113 and Training loss 0.2448887665383524\n",
            "Iteration 28400: Training accuracy 0.9106833333333333, Test accuracy 0.9118 and Training loss 0.24394495428339935\n",
            "Iteration 28500: Training accuracy 0.9108333333333334, Test accuracy 0.9114 and Training loss 0.24360694981775424\n",
            "Iteration 28600: Training accuracy 0.9111333333333334, Test accuracy 0.9119 and Training loss 0.24299443783824354\n",
            "Iteration 28700: Training accuracy 0.9113, Test accuracy 0.9115 and Training loss 0.24229118691422094\n",
            "Iteration 28800: Training accuracy 0.91105, Test accuracy 0.912 and Training loss 0.24242916094479697\n",
            "Iteration 28900: Training accuracy 0.9122, Test accuracy 0.913 and Training loss 0.2411274890555163\n",
            "Iteration 29000: Training accuracy 0.9121333333333334, Test accuracy 0.9129 and Training loss 0.2407023205696502\n",
            "Iteration 29100: Training accuracy 0.9122666666666667, Test accuracy 0.9138 and Training loss 0.24006221731943672\n",
            "Iteration 29200: Training accuracy 0.9130166666666667, Test accuracy 0.9144 and Training loss 0.2398611070138526\n",
            "Iteration 29300: Training accuracy 0.9131, Test accuracy 0.9146 and Training loss 0.23903980684878237\n",
            "Iteration 29400: Training accuracy 0.91295, Test accuracy 0.9149 and Training loss 0.23945715614266397\n",
            "Iteration 29500: Training accuracy 0.91335, Test accuracy 0.9158 and Training loss 0.23831881140452343\n",
            "Iteration 29600: Training accuracy 0.9135666666666666, Test accuracy 0.9149 and Training loss 0.23745211985767725\n",
            "Iteration 29700: Training accuracy 0.9138833333333334, Test accuracy 0.9148 and Training loss 0.2369123723500109\n",
            "Iteration 29800: Training accuracy 0.91415, Test accuracy 0.9142 and Training loss 0.23625384521825857\n",
            "Iteration 29900: Training accuracy 0.91425, Test accuracy 0.9138 and Training loss 0.23580079615679816\n",
            "Iteration 30000: Training accuracy 0.9144833333333333, Test accuracy 0.9144 and Training loss 0.2354683188714636\n",
            "Iteration 30100: Training accuracy 0.9149, Test accuracy 0.9149 and Training loss 0.23479045032130344\n",
            "Iteration 30200: Training accuracy 0.9152166666666667, Test accuracy 0.9148 and Training loss 0.2344153070039865\n",
            "Iteration 30300: Training accuracy 0.91535, Test accuracy 0.9142 and Training loss 0.23397705484261155\n",
            "Iteration 30400: Training accuracy 0.9154333333333333, Test accuracy 0.9142 and Training loss 0.2333920154096375\n",
            "Iteration 30500: Training accuracy 0.9156666666666666, Test accuracy 0.9147 and Training loss 0.232786778078078\n",
            "Iteration 30600: Training accuracy 0.9151666666666667, Test accuracy 0.915 and Training loss 0.2326723795477662\n",
            "Iteration 30700: Training accuracy 0.91565, Test accuracy 0.914 and Training loss 0.233319306841191\n",
            "Iteration 30800: Training accuracy 0.9161166666666667, Test accuracy 0.9153 and Training loss 0.23156488223277025\n",
            "Iteration 30900: Training accuracy 0.9168666666666667, Test accuracy 0.9166 and Training loss 0.23108369595172135\n",
            "Iteration 31000: Training accuracy 0.9169833333333334, Test accuracy 0.9165 and Training loss 0.23030377212438724\n",
            "Iteration 31100: Training accuracy 0.9176833333333333, Test accuracy 0.9167 and Training loss 0.2304748540212623\n",
            "Iteration 31200: Training accuracy 0.9173166666666667, Test accuracy 0.9167 and Training loss 0.22930950688653307\n",
            "Iteration 31300: Training accuracy 0.9179, Test accuracy 0.9175 and Training loss 0.22881205235450114\n",
            "Iteration 31400: Training accuracy 0.9179333333333334, Test accuracy 0.9173 and Training loss 0.2283009455527753\n",
            "Iteration 31500: Training accuracy 0.9180166666666667, Test accuracy 0.9169 and Training loss 0.22809542289379478\n",
            "Iteration 31600: Training accuracy 0.9180333333333334, Test accuracy 0.9172 and Training loss 0.22762064041010463\n",
            "Iteration 31700: Training accuracy 0.91785, Test accuracy 0.9181 and Training loss 0.22715810513094642\n",
            "Iteration 31800: Training accuracy 0.9180833333333334, Test accuracy 0.9171 and Training loss 0.22701024254473715\n",
            "Iteration 31900: Training accuracy 0.91865, Test accuracy 0.9183 and Training loss 0.2259743093022662\n",
            "Iteration 32000: Training accuracy 0.9183, Test accuracy 0.916 and Training loss 0.2262405815582169\n",
            "Iteration 32100: Training accuracy 0.91875, Test accuracy 0.918 and Training loss 0.2250263498769725\n",
            "Iteration 32200: Training accuracy 0.9189666666666667, Test accuracy 0.9168 and Training loss 0.22488974352848673\n",
            "Iteration 32300: Training accuracy 0.9195, Test accuracy 0.918 and Training loss 0.22416072262997236\n",
            "Iteration 32400: Training accuracy 0.91905, Test accuracy 0.9164 and Training loss 0.22422518519091952\n",
            "Iteration 32500: Training accuracy 0.9193833333333333, Test accuracy 0.9177 and Training loss 0.2236904785729463\n",
            "Iteration 32600: Training accuracy 0.9196333333333333, Test accuracy 0.9172 and Training loss 0.22420232063014126\n",
            "Iteration 32700: Training accuracy 0.9206666666666666, Test accuracy 0.9191 and Training loss 0.2224589454965677\n",
            "Iteration 32800: Training accuracy 0.9205, Test accuracy 0.9182 and Training loss 0.22303212244724355\n",
            "Iteration 32900: Training accuracy 0.9207666666666666, Test accuracy 0.9193 and Training loss 0.22132284778262248\n",
            "Iteration 33000: Training accuracy 0.9211666666666667, Test accuracy 0.9196 and Training loss 0.22102464854937762\n",
            "Iteration 33100: Training accuracy 0.9210166666666667, Test accuracy 0.9204 and Training loss 0.22054034701104017\n",
            "Iteration 33200: Training accuracy 0.9213833333333333, Test accuracy 0.9206 and Training loss 0.2203771105956175\n",
            "Iteration 33300: Training accuracy 0.92195, Test accuracy 0.9207 and Training loss 0.21964990293697323\n",
            "Iteration 33400: Training accuracy 0.9222166666666667, Test accuracy 0.92 and Training loss 0.21900067491285932\n",
            "Iteration 33500: Training accuracy 0.9227833333333333, Test accuracy 0.9205 and Training loss 0.21842152736364542\n",
            "Iteration 33600: Training accuracy 0.9222333333333333, Test accuracy 0.9213 and Training loss 0.21813729366407317\n",
            "Iteration 33700: Training accuracy 0.9226166666666666, Test accuracy 0.9204 and Training loss 0.21769567889283625\n",
            "Iteration 33800: Training accuracy 0.9225166666666667, Test accuracy 0.9209 and Training loss 0.21717544338390335\n",
            "Iteration 33900: Training accuracy 0.9232333333333334, Test accuracy 0.9207 and Training loss 0.21667842409404642\n",
            "Iteration 34000: Training accuracy 0.92325, Test accuracy 0.9208 and Training loss 0.21639386979034061\n",
            "Iteration 34100: Training accuracy 0.9232166666666667, Test accuracy 0.9218 and Training loss 0.21665482737753616\n",
            "Iteration 34200: Training accuracy 0.9232666666666667, Test accuracy 0.9214 and Training loss 0.21569515830061428\n",
            "Iteration 34300: Training accuracy 0.9232333333333334, Test accuracy 0.9216 and Training loss 0.21531194064959164\n",
            "Iteration 34400: Training accuracy 0.9236166666666666, Test accuracy 0.922 and Training loss 0.21484639234368774\n",
            "Iteration 34500: Training accuracy 0.9238833333333333, Test accuracy 0.9205 and Training loss 0.21461779740965295\n",
            "Iteration 34600: Training accuracy 0.9241, Test accuracy 0.9208 and Training loss 0.2137107058846016\n",
            "Iteration 34700: Training accuracy 0.9241833333333334, Test accuracy 0.9212 and Training loss 0.21333922275433664\n",
            "Iteration 34800: Training accuracy 0.9243166666666667, Test accuracy 0.9211 and Training loss 0.21297166565152545\n",
            "Iteration 34900: Training accuracy 0.9245, Test accuracy 0.9212 and Training loss 0.21276222374513007\n",
            "Iteration 35000: Training accuracy 0.9246833333333333, Test accuracy 0.9218 and Training loss 0.2121290187971442\n",
            "Iteration 35100: Training accuracy 0.92515, Test accuracy 0.9225 and Training loss 0.21184100319872354\n",
            "Iteration 35200: Training accuracy 0.9255166666666667, Test accuracy 0.9226 and Training loss 0.2111609770928358\n",
            "Iteration 35300: Training accuracy 0.9254333333333333, Test accuracy 0.9233 and Training loss 0.21091939597096368\n",
            "Iteration 35400: Training accuracy 0.92565, Test accuracy 0.9231 and Training loss 0.2104923037859855\n",
            "Iteration 35500: Training accuracy 0.9259333333333334, Test accuracy 0.924 and Training loss 0.2102196887738696\n",
            "Iteration 35600: Training accuracy 0.9259666666666667, Test accuracy 0.9224 and Training loss 0.20991292221524493\n",
            "Iteration 35700: Training accuracy 0.9263833333333333, Test accuracy 0.9227 and Training loss 0.20922004008432038\n",
            "Iteration 35800: Training accuracy 0.9262, Test accuracy 0.9235 and Training loss 0.20905783312803367\n",
            "Iteration 35900: Training accuracy 0.92645, Test accuracy 0.9227 and Training loss 0.20849160278387138\n",
            "Iteration 36000: Training accuracy 0.9264166666666667, Test accuracy 0.9228 and Training loss 0.2081521329943409\n",
            "Iteration 36100: Training accuracy 0.9267, Test accuracy 0.9218 and Training loss 0.20755762189485433\n",
            "Iteration 36200: Training accuracy 0.9262333333333334, Test accuracy 0.9237 and Training loss 0.20775211180367062\n",
            "Iteration 36300: Training accuracy 0.9263833333333333, Test accuracy 0.9223 and Training loss 0.20761311403468286\n",
            "Iteration 36400: Training accuracy 0.9272, Test accuracy 0.9227 and Training loss 0.20656481580845096\n",
            "Iteration 36500: Training accuracy 0.9272166666666667, Test accuracy 0.9232 and Training loss 0.2061574509512058\n",
            "Iteration 36600: Training accuracy 0.9278166666666666, Test accuracy 0.9244 and Training loss 0.20556182355231128\n",
            "Iteration 36700: Training accuracy 0.9281833333333334, Test accuracy 0.9249 and Training loss 0.20520257605980383\n",
            "Iteration 36800: Training accuracy 0.9282666666666667, Test accuracy 0.9252 and Training loss 0.204978070690611\n",
            "Iteration 36900: Training accuracy 0.9283833333333333, Test accuracy 0.9242 and Training loss 0.2043753392173734\n",
            "Iteration 37000: Training accuracy 0.92835, Test accuracy 0.9238 and Training loss 0.2039117416236153\n",
            "Iteration 37100: Training accuracy 0.92845, Test accuracy 0.9256 and Training loss 0.20356730656555538\n",
            "Iteration 37200: Training accuracy 0.9288166666666666, Test accuracy 0.9245 and Training loss 0.20322824589366723\n",
            "Iteration 37300: Training accuracy 0.9290333333333334, Test accuracy 0.9248 and Training loss 0.20285671354583465\n",
            "Iteration 37400: Training accuracy 0.9297, Test accuracy 0.9255 and Training loss 0.2024113954341171\n",
            "Iteration 37500: Training accuracy 0.92985, Test accuracy 0.9257 and Training loss 0.2019519075692759\n",
            "Iteration 37600: Training accuracy 0.93005, Test accuracy 0.9262 and Training loss 0.20159083460341862\n",
            "Iteration 37700: Training accuracy 0.9294166666666667, Test accuracy 0.9255 and Training loss 0.2014977741795773\n",
            "Iteration 37800: Training accuracy 0.9296666666666666, Test accuracy 0.9235 and Training loss 0.20120511304587022\n",
            "Iteration 37900: Training accuracy 0.9298333333333333, Test accuracy 0.9244 and Training loss 0.20061701166428222\n",
            "Iteration 38000: Training accuracy 0.9303333333333333, Test accuracy 0.9251 and Training loss 0.19997181888474055\n",
            "Iteration 38100: Training accuracy 0.9306333333333333, Test accuracy 0.9248 and Training loss 0.19963725903252738\n",
            "Iteration 38200: Training accuracy 0.9312, Test accuracy 0.9257 and Training loss 0.19916719398973476\n",
            "Iteration 38300: Training accuracy 0.9311333333333334, Test accuracy 0.9272 and Training loss 0.19949159276123268\n",
            "Iteration 38400: Training accuracy 0.9308333333333333, Test accuracy 0.9269 and Training loss 0.19901069290919504\n",
            "Iteration 38500: Training accuracy 0.93095, Test accuracy 0.9267 and Training loss 0.1985826996221761\n",
            "Iteration 38600: Training accuracy 0.9312666666666667, Test accuracy 0.9263 and Training loss 0.19793693020686917\n",
            "Iteration 38700: Training accuracy 0.9312333333333334, Test accuracy 0.9266 and Training loss 0.19814664304823273\n",
            "Iteration 38800: Training accuracy 0.9317666666666666, Test accuracy 0.9259 and Training loss 0.1971595272300184\n",
            "Iteration 38900: Training accuracy 0.9312, Test accuracy 0.9229 and Training loss 0.19787954366180166\n",
            "Iteration 39000: Training accuracy 0.9323166666666667, Test accuracy 0.9266 and Training loss 0.1967870966833147\n",
            "Iteration 39100: Training accuracy 0.9321666666666667, Test accuracy 0.925 and Training loss 0.1964524067041392\n",
            "Iteration 39200: Training accuracy 0.9319666666666667, Test accuracy 0.9243 and Training loss 0.19615190496081053\n",
            "Iteration 39300: Training accuracy 0.9322333333333334, Test accuracy 0.9254 and Training loss 0.19543462918701918\n",
            "Iteration 39400: Training accuracy 0.9324666666666667, Test accuracy 0.9282 and Training loss 0.19502761470965152\n",
            "Iteration 39500: Training accuracy 0.9324833333333333, Test accuracy 0.9276 and Training loss 0.19464865151430305\n",
            "Iteration 39600: Training accuracy 0.9329166666666666, Test accuracy 0.928 and Training loss 0.19426352183590362\n",
            "Iteration 39700: Training accuracy 0.9329333333333333, Test accuracy 0.9283 and Training loss 0.19451987674831683\n",
            "Iteration 39800: Training accuracy 0.93255, Test accuracy 0.9292 and Training loss 0.1951073031901797\n",
            "Iteration 39900: Training accuracy 0.9328833333333333, Test accuracy 0.9264 and Training loss 0.19345152720306097\n",
            "Iteration 40000: Training accuracy 0.9328166666666666, Test accuracy 0.9276 and Training loss 0.19296734386672665\n",
            "Iteration 40100: Training accuracy 0.9328666666666666, Test accuracy 0.9272 and Training loss 0.19273449579446797\n",
            "Iteration 40200: Training accuracy 0.9330833333333334, Test accuracy 0.9282 and Training loss 0.19221022240758023\n",
            "Iteration 40300: Training accuracy 0.9330166666666667, Test accuracy 0.9304 and Training loss 0.1924141995250123\n",
            "Iteration 40400: Training accuracy 0.9332, Test accuracy 0.9303 and Training loss 0.19242983744142758\n",
            "Iteration 40500: Training accuracy 0.9337333333333333, Test accuracy 0.9285 and Training loss 0.1915009739041717\n",
            "Iteration 40600: Training accuracy 0.9339666666666666, Test accuracy 0.9293 and Training loss 0.19089251709464555\n",
            "Iteration 40700: Training accuracy 0.93375, Test accuracy 0.929 and Training loss 0.19091094640846398\n",
            "Iteration 40800: Training accuracy 0.9339666666666666, Test accuracy 0.9291 and Training loss 0.190608282206131\n",
            "Iteration 40900: Training accuracy 0.9338333333333333, Test accuracy 0.928 and Training loss 0.19008365151267395\n",
            "Iteration 41000: Training accuracy 0.9345666666666667, Test accuracy 0.9294 and Training loss 0.18952900328297248\n",
            "Iteration 41100: Training accuracy 0.9345, Test accuracy 0.93 and Training loss 0.18915262424896434\n",
            "Iteration 41200: Training accuracy 0.9347833333333333, Test accuracy 0.9292 and Training loss 0.1888928855764433\n",
            "Iteration 41300: Training accuracy 0.9352833333333334, Test accuracy 0.9289 and Training loss 0.18858573318111763\n",
            "Iteration 41400: Training accuracy 0.93555, Test accuracy 0.9296 and Training loss 0.18820174906358775\n",
            "Iteration 41500: Training accuracy 0.9354666666666667, Test accuracy 0.93 and Training loss 0.188066574127373\n",
            "Iteration 41600: Training accuracy 0.9355333333333333, Test accuracy 0.9308 and Training loss 0.18808333603728195\n",
            "Iteration 41700: Training accuracy 0.9348166666666666, Test accuracy 0.9291 and Training loss 0.18757581291286618\n",
            "Iteration 41800: Training accuracy 0.9347, Test accuracy 0.9277 and Training loss 0.18807573101654104\n",
            "Iteration 41900: Training accuracy 0.9356333333333333, Test accuracy 0.9322 and Training loss 0.18657361069832107\n",
            "Iteration 42000: Training accuracy 0.936, Test accuracy 0.9307 and Training loss 0.1861877799503096\n",
            "Iteration 42100: Training accuracy 0.9361666666666667, Test accuracy 0.9302 and Training loss 0.18585123668213202\n",
            "Iteration 42200: Training accuracy 0.9358333333333333, Test accuracy 0.9295 and Training loss 0.1860047384350956\n",
            "Iteration 42300: Training accuracy 0.9363166666666667, Test accuracy 0.93 and Training loss 0.18547263753618445\n",
            "Iteration 42400: Training accuracy 0.9361833333333334, Test accuracy 0.9288 and Training loss 0.18519359204993965\n",
            "Iteration 42500: Training accuracy 0.9366833333333333, Test accuracy 0.9302 and Training loss 0.18476182667266863\n",
            "Iteration 42600: Training accuracy 0.93675, Test accuracy 0.9292 and Training loss 0.18460121205174793\n",
            "Iteration 42700: Training accuracy 0.93725, Test accuracy 0.9295 and Training loss 0.1840093881359149\n",
            "Iteration 42800: Training accuracy 0.9372666666666667, Test accuracy 0.9315 and Training loss 0.18360827185914486\n",
            "Iteration 42900: Training accuracy 0.9376, Test accuracy 0.932 and Training loss 0.18337837596852855\n",
            "Iteration 43000: Training accuracy 0.9370666666666667, Test accuracy 0.9314 and Training loss 0.18333096204452962\n",
            "Iteration 43100: Training accuracy 0.9374, Test accuracy 0.9328 and Training loss 0.1828944004603404\n",
            "Iteration 43200: Training accuracy 0.93745, Test accuracy 0.932 and Training loss 0.18276438676039405\n",
            "Iteration 43300: Training accuracy 0.9368, Test accuracy 0.9327 and Training loss 0.1837599628246606\n",
            "Iteration 43400: Training accuracy 0.93775, Test accuracy 0.9333 and Training loss 0.181870403095161\n",
            "Iteration 43500: Training accuracy 0.938, Test accuracy 0.9328 and Training loss 0.1817212926849649\n",
            "Iteration 43600: Training accuracy 0.9375666666666667, Test accuracy 0.932 and Training loss 0.18192756420659206\n",
            "Iteration 43700: Training accuracy 0.9377166666666666, Test accuracy 0.9322 and Training loss 0.18123798916455988\n",
            "Iteration 43800: Training accuracy 0.9381333333333334, Test accuracy 0.9325 and Training loss 0.18079077175322875\n",
            "Iteration 43900: Training accuracy 0.9379666666666666, Test accuracy 0.9337 and Training loss 0.18049003206702674\n",
            "Iteration 44000: Training accuracy 0.93795, Test accuracy 0.9343 and Training loss 0.18050157510848033\n",
            "Iteration 44100: Training accuracy 0.9387333333333333, Test accuracy 0.9343 and Training loss 0.17995693073974406\n",
            "Iteration 44200: Training accuracy 0.9391166666666667, Test accuracy 0.9348 and Training loss 0.1795218724569178\n",
            "Iteration 44300: Training accuracy 0.9395666666666667, Test accuracy 0.9346 and Training loss 0.1793480730622724\n",
            "Iteration 44400: Training accuracy 0.9396, Test accuracy 0.9349 and Training loss 0.17920840456517664\n",
            "Iteration 44500: Training accuracy 0.9395, Test accuracy 0.934 and Training loss 0.17899990689190146\n",
            "Iteration 44600: Training accuracy 0.939, Test accuracy 0.9344 and Training loss 0.17882698883445128\n",
            "Iteration 44700: Training accuracy 0.9391333333333334, Test accuracy 0.9343 and Training loss 0.17847825501131892\n",
            "Iteration 44800: Training accuracy 0.9393833333333333, Test accuracy 0.9342 and Training loss 0.17791494336813696\n",
            "Iteration 44900: Training accuracy 0.9397333333333333, Test accuracy 0.9337 and Training loss 0.17754259680689166\n",
            "Iteration 45000: Training accuracy 0.9397833333333333, Test accuracy 0.9333 and Training loss 0.17751897853479243\n",
            "Iteration 45100: Training accuracy 0.9397166666666666, Test accuracy 0.9325 and Training loss 0.17743268489572755\n",
            "Iteration 45200: Training accuracy 0.9399166666666666, Test accuracy 0.9332 and Training loss 0.1767715386312942\n",
            "Iteration 45300: Training accuracy 0.9399666666666666, Test accuracy 0.9333 and Training loss 0.17633070513956337\n",
            "Iteration 45400: Training accuracy 0.9401166666666667, Test accuracy 0.9334 and Training loss 0.17603804194539371\n",
            "Iteration 45500: Training accuracy 0.9403, Test accuracy 0.9342 and Training loss 0.17591663502812727\n",
            "Iteration 45600: Training accuracy 0.9406666666666667, Test accuracy 0.9324 and Training loss 0.17539632887944917\n",
            "Iteration 45700: Training accuracy 0.9406333333333333, Test accuracy 0.933 and Training loss 0.17507055139895175\n",
            "Iteration 45800: Training accuracy 0.9406833333333333, Test accuracy 0.9323 and Training loss 0.17493783797612664\n",
            "Iteration 45900: Training accuracy 0.9410166666666666, Test accuracy 0.9328 and Training loss 0.17459125690407828\n",
            "Iteration 46000: Training accuracy 0.9402, Test accuracy 0.9336 and Training loss 0.1744025363721411\n",
            "Iteration 46100: Training accuracy 0.9403666666666667, Test accuracy 0.9347 and Training loss 0.17448402197244386\n",
            "Iteration 46200: Training accuracy 0.9406333333333333, Test accuracy 0.9336 and Training loss 0.17383296141039467\n",
            "Iteration 46300: Training accuracy 0.94085, Test accuracy 0.9348 and Training loss 0.17363358754886007\n",
            "Iteration 46400: Training accuracy 0.941, Test accuracy 0.9352 and Training loss 0.17323464363494798\n",
            "Iteration 46500: Training accuracy 0.9412833333333334, Test accuracy 0.9348 and Training loss 0.17315126344219361\n",
            "Iteration 46600: Training accuracy 0.9404833333333333, Test accuracy 0.9317 and Training loss 0.17360793927546006\n",
            "Iteration 46700: Training accuracy 0.9417, Test accuracy 0.9361 and Training loss 0.1726679432183758\n",
            "Iteration 46800: Training accuracy 0.9414833333333333, Test accuracy 0.9331 and Training loss 0.17249823987655014\n",
            "Iteration 46900: Training accuracy 0.9417166666666666, Test accuracy 0.9345 and Training loss 0.1720981999431568\n",
            "Iteration 47000: Training accuracy 0.9418333333333333, Test accuracy 0.9332 and Training loss 0.17195615295721955\n",
            "Iteration 47100: Training accuracy 0.9419, Test accuracy 0.932 and Training loss 0.17190829486544154\n",
            "Iteration 47200: Training accuracy 0.9421333333333334, Test accuracy 0.9328 and Training loss 0.17137872120357292\n",
            "Iteration 47300: Training accuracy 0.9414166666666667, Test accuracy 0.9338 and Training loss 0.17116144183641416\n",
            "Iteration 47400: Training accuracy 0.94155, Test accuracy 0.9334 and Training loss 0.1708254927328822\n",
            "Iteration 47500: Training accuracy 0.9420666666666667, Test accuracy 0.9334 and Training loss 0.17062136491935914\n",
            "Iteration 47600: Training accuracy 0.9424333333333333, Test accuracy 0.9329 and Training loss 0.1702914289877596\n",
            "Iteration 47700: Training accuracy 0.94245, Test accuracy 0.9347 and Training loss 0.16994666618143583\n",
            "Iteration 47800: Training accuracy 0.9425333333333333, Test accuracy 0.9342 and Training loss 0.1697475876426628\n",
            "Iteration 47900: Training accuracy 0.94275, Test accuracy 0.9352 and Training loss 0.1695679097677231\n",
            "Iteration 48000: Training accuracy 0.9426, Test accuracy 0.9354 and Training loss 0.16962943756295132\n",
            "Iteration 48100: Training accuracy 0.9424333333333333, Test accuracy 0.9348 and Training loss 0.169109091037507\n",
            "Iteration 48200: Training accuracy 0.94265, Test accuracy 0.9348 and Training loss 0.16883883703332123\n",
            "Iteration 48300: Training accuracy 0.9422666666666667, Test accuracy 0.9323 and Training loss 0.17002880978782953\n",
            "Iteration 48400: Training accuracy 0.9429166666666666, Test accuracy 0.9344 and Training loss 0.16837037182104464\n",
            "Iteration 48500: Training accuracy 0.9428666666666666, Test accuracy 0.9342 and Training loss 0.16822989940920713\n",
            "Iteration 48600: Training accuracy 0.9429166666666666, Test accuracy 0.9346 and Training loss 0.16805589303030122\n",
            "Iteration 48700: Training accuracy 0.94305, Test accuracy 0.9342 and Training loss 0.16769637153358427\n",
            "Iteration 48800: Training accuracy 0.9432333333333334, Test accuracy 0.9341 and Training loss 0.1675818441021158\n",
            "Iteration 48900: Training accuracy 0.9433333333333334, Test accuracy 0.9322 and Training loss 0.16769988143269293\n",
            "Iteration 49000: Training accuracy 0.9435333333333333, Test accuracy 0.9344 and Training loss 0.16688531783531826\n",
            "Iteration 49100: Training accuracy 0.9437833333333333, Test accuracy 0.9329 and Training loss 0.16683561475217581\n",
            "Iteration 49200: Training accuracy 0.9430166666666666, Test accuracy 0.9357 and Training loss 0.16708277150566325\n",
            "Iteration 49300: Training accuracy 0.94385, Test accuracy 0.9349 and Training loss 0.16627121222777774\n",
            "Iteration 49400: Training accuracy 0.9437833333333333, Test accuracy 0.9335 and Training loss 0.16620375940057533\n",
            "Iteration 49500: Training accuracy 0.9436, Test accuracy 0.9361 and Training loss 0.16580782003374045\n",
            "Iteration 49600: Training accuracy 0.9442333333333334, Test accuracy 0.9351 and Training loss 0.16570941600726447\n",
            "Iteration 49700: Training accuracy 0.9443166666666667, Test accuracy 0.9371 and Training loss 0.16563863801313633\n",
            "Iteration 49800: Training accuracy 0.94455, Test accuracy 0.935 and Training loss 0.16535378736915632\n",
            "Iteration 49900: Training accuracy 0.9442166666666667, Test accuracy 0.9364 and Training loss 0.16513410632142\n",
            "Iteration 50000: Training accuracy 0.94465, Test accuracy 0.9346 and Training loss 0.1647977943616191\n",
            "Iteration 50100: Training accuracy 0.9445166666666667, Test accuracy 0.9341 and Training loss 0.16469978593443566\n",
            "Iteration 50200: Training accuracy 0.9447166666666666, Test accuracy 0.9355 and Training loss 0.16425857686067463\n",
            "Iteration 50300: Training accuracy 0.94505, Test accuracy 0.9358 and Training loss 0.16397359170836068\n",
            "Iteration 50400: Training accuracy 0.9445833333333333, Test accuracy 0.937 and Training loss 0.16375834821496013\n",
            "Iteration 50500: Training accuracy 0.94475, Test accuracy 0.9379 and Training loss 0.16391066777310648\n",
            "Iteration 50600: Training accuracy 0.9450833333333334, Test accuracy 0.9345 and Training loss 0.1635221548223366\n",
            "Iteration 50700: Training accuracy 0.9451333333333334, Test accuracy 0.9361 and Training loss 0.16305869285234148\n",
            "Iteration 50800: Training accuracy 0.9453166666666667, Test accuracy 0.9385 and Training loss 0.16302120102080872\n",
            "Iteration 50900: Training accuracy 0.94585, Test accuracy 0.9353 and Training loss 0.1629780845366094\n",
            "Iteration 51000: Training accuracy 0.9459333333333333, Test accuracy 0.9374 and Training loss 0.16258073238562748\n",
            "Iteration 51100: Training accuracy 0.9459, Test accuracy 0.9385 and Training loss 0.1623542853007647\n",
            "Iteration 51200: Training accuracy 0.9459833333333333, Test accuracy 0.9371 and Training loss 0.1621658299398156\n",
            "Iteration 51300: Training accuracy 0.9458666666666666, Test accuracy 0.9362 and Training loss 0.16193302857076836\n",
            "Iteration 51400: Training accuracy 0.9458666666666666, Test accuracy 0.9383 and Training loss 0.16181059231113074\n",
            "Iteration 51500: Training accuracy 0.9465666666666667, Test accuracy 0.9373 and Training loss 0.1613539449303357\n",
            "Iteration 51600: Training accuracy 0.9459666666666666, Test accuracy 0.9381 and Training loss 0.16127393355545588\n",
            "Iteration 51700: Training accuracy 0.94635, Test accuracy 0.9396 and Training loss 0.1620381957751996\n",
            "Iteration 51800: Training accuracy 0.9464333333333333, Test accuracy 0.9357 and Training loss 0.16078365378938195\n",
            "Iteration 51900: Training accuracy 0.94625, Test accuracy 0.938 and Training loss 0.16059846254311233\n",
            "Iteration 52000: Training accuracy 0.9461, Test accuracy 0.938 and Training loss 0.16019558349516616\n",
            "Iteration 52100: Training accuracy 0.9457333333333333, Test accuracy 0.9381 and Training loss 0.16036651633767987\n",
            "Iteration 52200: Training accuracy 0.9461833333333334, Test accuracy 0.9342 and Training loss 0.16001189761473886\n",
            "Iteration 52300: Training accuracy 0.9459666666666666, Test accuracy 0.9342 and Training loss 0.15975314460144285\n",
            "Iteration 52400: Training accuracy 0.9460666666666666, Test accuracy 0.9361 and Training loss 0.15941907399342664\n",
            "Iteration 52500: Training accuracy 0.9457166666666666, Test accuracy 0.9391 and Training loss 0.1602099809907238\n",
            "Iteration 52600: Training accuracy 0.9459333333333333, Test accuracy 0.9363 and Training loss 0.15898745359294442\n",
            "Iteration 52700: Training accuracy 0.9464166666666667, Test accuracy 0.935 and Training loss 0.15920458353837724\n",
            "Iteration 52800: Training accuracy 0.9462, Test accuracy 0.9346 and Training loss 0.158877592076916\n",
            "Iteration 52900: Training accuracy 0.9467833333333333, Test accuracy 0.9377 and Training loss 0.15839218182525275\n",
            "Iteration 53000: Training accuracy 0.9465333333333333, Test accuracy 0.9365 and Training loss 0.15834990476498711\n",
            "Iteration 53100: Training accuracy 0.9471666666666667, Test accuracy 0.9393 and Training loss 0.15868127329123674\n",
            "Iteration 53200: Training accuracy 0.9469833333333333, Test accuracy 0.9377 and Training loss 0.1581049134958866\n",
            "Iteration 53300: Training accuracy 0.9468666666666666, Test accuracy 0.9355 and Training loss 0.1584476973377356\n",
            "Iteration 53400: Training accuracy 0.9474666666666667, Test accuracy 0.9396 and Training loss 0.15737988152107255\n",
            "Iteration 53500: Training accuracy 0.9471333333333334, Test accuracy 0.9364 and Training loss 0.1577744279077056\n",
            "Iteration 53600: Training accuracy 0.94675, Test accuracy 0.9348 and Training loss 0.15810691053278708\n",
            "Iteration 53700: Training accuracy 0.9470333333333333, Test accuracy 0.9398 and Training loss 0.15671845752683003\n",
            "Iteration 53800: Training accuracy 0.9472, Test accuracy 0.9401 and Training loss 0.15650370427661855\n",
            "Iteration 53900: Training accuracy 0.9471166666666667, Test accuracy 0.9434 and Training loss 0.15770561745549483\n",
            "Iteration 54000: Training accuracy 0.9470833333333334, Test accuracy 0.9414 and Training loss 0.1564741715048953\n",
            "Iteration 54100: Training accuracy 0.9473333333333334, Test accuracy 0.9402 and Training loss 0.1563347983163221\n",
            "Iteration 54200: Training accuracy 0.9472, Test accuracy 0.9396 and Training loss 0.15582905503285963\n",
            "Iteration 54300: Training accuracy 0.94725, Test accuracy 0.9375 and Training loss 0.15600677616949382\n",
            "Iteration 54400: Training accuracy 0.9464333333333333, Test accuracy 0.9432 and Training loss 0.15833905380924468\n",
            "Iteration 54500: Training accuracy 0.9481666666666667, Test accuracy 0.9392 and Training loss 0.1553394018922061\n",
            "Iteration 54600: Training accuracy 0.9474833333333333, Test accuracy 0.936 and Training loss 0.1556182075567692\n",
            "Iteration 54700: Training accuracy 0.94805, Test accuracy 0.9356 and Training loss 0.15521969890677834\n",
            "Iteration 54800: Training accuracy 0.9480333333333333, Test accuracy 0.9355 and Training loss 0.1551760611307882\n",
            "Iteration 54900: Training accuracy 0.9485, Test accuracy 0.9387 and Training loss 0.1545399608555184\n",
            "Iteration 55000: Training accuracy 0.94865, Test accuracy 0.9405 and Training loss 0.15428747092411177\n",
            "Iteration 55100: Training accuracy 0.94815, Test accuracy 0.9374 and Training loss 0.15435872097122927\n",
            "Iteration 55200: Training accuracy 0.9483333333333334, Test accuracy 0.9388 and Training loss 0.15396359132448084\n",
            "Iteration 55300: Training accuracy 0.9482166666666667, Test accuracy 0.9402 and Training loss 0.1536876968155721\n",
            "Iteration 55400: Training accuracy 0.9481833333333334, Test accuracy 0.9429 and Training loss 0.15423663996866\n",
            "Iteration 55500: Training accuracy 0.9484166666666667, Test accuracy 0.943 and Training loss 0.1537783297588401\n",
            "Iteration 55600: Training accuracy 0.9484166666666667, Test accuracy 0.9435 and Training loss 0.1533755770248136\n",
            "Iteration 55700: Training accuracy 0.9490333333333333, Test accuracy 0.9431 and Training loss 0.15341761022073377\n",
            "Iteration 55800: Training accuracy 0.9488666666666666, Test accuracy 0.9392 and Training loss 0.15295591009205167\n",
            "Iteration 55900: Training accuracy 0.9487833333333333, Test accuracy 0.9393 and Training loss 0.15269170364320245\n",
            "Iteration 56000: Training accuracy 0.9485, Test accuracy 0.9394 and Training loss 0.152629153851868\n",
            "Iteration 56100: Training accuracy 0.9486666666666667, Test accuracy 0.9396 and Training loss 0.15243482338697978\n",
            "Iteration 56200: Training accuracy 0.9484, Test accuracy 0.9388 and Training loss 0.1522862059064548\n",
            "Iteration 56300: Training accuracy 0.9489, Test accuracy 0.9386 and Training loss 0.1520711621426532\n",
            "Iteration 56400: Training accuracy 0.9488333333333333, Test accuracy 0.9407 and Training loss 0.15185561271852\n",
            "Iteration 56500: Training accuracy 0.9490833333333333, Test accuracy 0.9404 and Training loss 0.15164449261297394\n",
            "Iteration 56600: Training accuracy 0.9492666666666667, Test accuracy 0.9406 and Training loss 0.15150292801387322\n",
            "Iteration 56700: Training accuracy 0.9488833333333333, Test accuracy 0.9432 and Training loss 0.15200339304133403\n",
            "Iteration 56800: Training accuracy 0.9491166666666667, Test accuracy 0.9422 and Training loss 0.15160456446240647\n",
            "Iteration 56900: Training accuracy 0.9494833333333333, Test accuracy 0.9399 and Training loss 0.1508767909034625\n",
            "Iteration 57000: Training accuracy 0.9495333333333333, Test accuracy 0.9375 and Training loss 0.15084615281687977\n",
            "Iteration 57100: Training accuracy 0.94945, Test accuracy 0.9393 and Training loss 0.15052781627020376\n",
            "Iteration 57200: Training accuracy 0.94935, Test accuracy 0.9419 and Training loss 0.15065989798168883\n",
            "Iteration 57300: Training accuracy 0.9489333333333333, Test accuracy 0.942 and Training loss 0.15015277665414936\n",
            "Iteration 57400: Training accuracy 0.9494333333333334, Test accuracy 0.9411 and Training loss 0.14999385220911568\n",
            "Iteration 57500: Training accuracy 0.94955, Test accuracy 0.9418 and Training loss 0.1500113529485509\n",
            "Iteration 57600: Training accuracy 0.9496333333333333, Test accuracy 0.9416 and Training loss 0.14969758419514365\n",
            "Iteration 57700: Training accuracy 0.95005, Test accuracy 0.9432 and Training loss 0.14979248988160135\n",
            "Iteration 57800: Training accuracy 0.9496833333333333, Test accuracy 0.9388 and Training loss 0.1497546951767166\n",
            "Iteration 57900: Training accuracy 0.9500333333333333, Test accuracy 0.9397 and Training loss 0.1491572459795194\n",
            "Iteration 58000: Training accuracy 0.9502, Test accuracy 0.941 and Training loss 0.14893935216029627\n",
            "Iteration 58100: Training accuracy 0.9504166666666667, Test accuracy 0.9398 and Training loss 0.14878726940292086\n",
            "Iteration 58200: Training accuracy 0.9499166666666666, Test accuracy 0.941 and Training loss 0.14873866199009556\n",
            "Iteration 58300: Training accuracy 0.9501666666666667, Test accuracy 0.9393 and Training loss 0.148841937226036\n",
            "Iteration 58400: Training accuracy 0.9501333333333334, Test accuracy 0.9383 and Training loss 0.14873593179172082\n",
            "Iteration 58500: Training accuracy 0.9499833333333333, Test accuracy 0.941 and Training loss 0.14835386016610871\n",
            "Iteration 58600: Training accuracy 0.9499, Test accuracy 0.936 and Training loss 0.14850288844459797\n",
            "Iteration 58700: Training accuracy 0.95, Test accuracy 0.9353 and Training loss 0.14829401636872108\n",
            "Iteration 58800: Training accuracy 0.9500666666666666, Test accuracy 0.9375 and Training loss 0.14779292702673247\n",
            "Iteration 58900: Training accuracy 0.9502666666666667, Test accuracy 0.9372 and Training loss 0.14777457348340858\n",
            "Iteration 59000: Training accuracy 0.9502333333333334, Test accuracy 0.9392 and Training loss 0.14736079983607087\n",
            "Iteration 59100: Training accuracy 0.9503833333333334, Test accuracy 0.94 and Training loss 0.1471961099596848\n",
            "Iteration 59200: Training accuracy 0.9508666666666666, Test accuracy 0.9391 and Training loss 0.14698143462890423\n",
            "Iteration 59300: Training accuracy 0.9501166666666667, Test accuracy 0.9379 and Training loss 0.14723567191975775\n",
            "Iteration 59400: Training accuracy 0.9498833333333333, Test accuracy 0.9382 and Training loss 0.14698595099551592\n",
            "Iteration 59500: Training accuracy 0.9497666666666666, Test accuracy 0.9396 and Training loss 0.1468159402069346\n",
            "Iteration 59600: Training accuracy 0.9492333333333334, Test accuracy 0.9375 and Training loss 0.14755657050938656\n",
            "Iteration 59700: Training accuracy 0.9499333333333333, Test accuracy 0.9385 and Training loss 0.1465869175824102\n",
            "Iteration 59800: Training accuracy 0.9502666666666667, Test accuracy 0.9429 and Training loss 0.14686832742359923\n",
            "Iteration 59900: Training accuracy 0.9501333333333334, Test accuracy 0.9442 and Training loss 0.14706893671394272\n",
            "Iteration 60000: Training accuracy 0.9504666666666667, Test accuracy 0.9438 and Training loss 0.14665602934488967\n",
            "Final test accuracy for k = 200: 0.9438\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Asnwer4) The number of nodes in a neural network can have a significant impact on its accuracy. In general, more nodes will lead to higher accuracy, but it is important to note that there is a point of diminishing returns.\n",
        "\n",
        "In the above output, we can see that the final test accuracy for K=5 is 91%, for K=40 is 93%, and for K=200 is 94.3%. This shows that there is a significant increase in accuracy from K=5 to K=40, but the increase in accuracy from K=40 to K=200 is much smaller.\n",
        "\n",
        "This is because the neural network has already learned most of the patterns in the data with 40 nodes. Adding more nodes does not significantly improve the accuracy of the model, but it does increase the training time.\n",
        "\n",
        "It is important to note that the number of nodes that is optimal for a particular problem will vary depending on the complexity of the problem and the size of the dataset."
      ],
      "metadata": {
        "id": "4XejAzS_7Adp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question5) 2 pts) Comment on the difference between linear model and neural net. Comment on the differences\n",
        "between logistic and quadratic loss in terms of optimization and test/train accuracy.**"
      ],
      "metadata": {
        "id": "-n3JFlx-f_Ie"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer5) The difference between a linear model and a neural net:\n",
        "\n",
        "Linear models are simpler models that involve a direct relationship between input features and output. They perform well for simple models where the data is linearly separable, but they fail for complex models where the data is not linearly separable. Neural networks are more powerful models that can learn complex patterns in data. They perform well for data that is not linearly separable.\n",
        "\n",
        "In our assignment, we can see that the maximum accuracy for the linear model is 80%, while the accuracy for the neural network is 94%. However, neural networks require more time to train because of the increased number of parameters and the complexity of the optimization process, which involves backpropagation and gradient descent.\n",
        "\n",
        "The difference between a Logistic and quadratic loss:\n",
        "\n",
        "Logistic loss and quadratic loss are two different loss functions that can be used for classification problems. Logistic loss converges faster than quadratic loss for classification problems, as it penalizes misclassified instances more heavily. This drives the model to focus on correctly classifying those instances. Logistic loss also gives better performance in terms of test/train accuracy for classification tasks. Quadratic loss is more suitable for regression problems.\n",
        "\n",
        "In our assignment, we can see that logistic loss performs better than quadratic loss for both training and test data. Quadratic loss accuracy is not consistent and changes a lot for each iteration."
      ],
      "metadata": {
        "id": "4D-n3ndggGaT"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qMHvVgiUmBjn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}